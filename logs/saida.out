compute-1-0.localdomain
compute-1-0.localdomain
compute-1-0.localdomain
compute-1-0.localdomain
GPU 0: NVIDIA A100 80GB PCIe (UUID: GPU-8c36d9dd-4315-583f-c95d-c0e7575f3433)
  No MIG instances found.
GPU 1: NVIDIA A100 80GB PCIe (UUID: GPU-3abe7f07-d793-14fa-a218-bf805e641e63)
  No MIG instances found.
Wed May 22 03:10:34 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100 80GB PCIe          On  | 00000000:21:00.0 Off |                    0 |
| N/A   31C    P0              44W / 300W |      4MiB / 81920MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA A100 80GB PCIe          On  | 00000000:81:00.0 Off |                    0 |
| N/A   32C    P0              43W / 300W |      4MiB / 81920MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
3
4
1
4
Simulation 1: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 32), (<class 'torch.nn.modules.activation.ELU'>, 64))}}
Simulation 2: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 64), (<class 'torch.nn.modules.activation.ELU'>, 64))}}
Simulation 3: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 32), (<class 'torch.nn.modules.activation.ELU'>, 32))}}
Simulation 4: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 64), (<class 'torch.nn.modules.activation.ELU'>, 32))}}
Simulation 5: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 32), (<class 'torch.nn.modules.activation.SiLU'>, 64))}}
Simulation 6: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 64), (<class 'torch.nn.modules.activation.SiLU'>, 64))}}
Simulation 7: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 32), (<class 'torch.nn.modules.activation.SiLU'>, 32))}}
Simulation 8: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 64), (<class 'torch.nn.modules.activation.SiLU'>, 32))}}
2
4
Simulation 9: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 32), (<class 'torch.nn.modules.activation.ELU'>, 64))}}
Simulation 10: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 64), (<class 'torch.nn.modules.activation.ELU'>, 64))}}
Simulation 11: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 32), (<class 'torch.nn.modules.activation.ELU'>, 32))}}
Simulation 12: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 64), (<class 'torch.nn.modules.activation.ELU'>, 32))}}
0
4
Simulation 13: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 64), (<class 'torch.nn.modules.activation.SiLU'>, 64))}}
Simulation 14: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 32), (<class 'torch.nn.modules.activation.SiLU'>, 32))}}
Simulation 15: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 64), (<class 'torch.nn.modules.activation.SiLU'>, 32))}}
Simulation 16: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 32), (<class 'torch.nn.modules.activation.SiLU'>, 64))}}
Simulation 1: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 32), (<class 'torch.nn.modules.activation.ELU'>, 64))}}
Simulation 1: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 32), (<class 'torch.nn.modules.activation.ELU'>, 32))}}
Simulation 2: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 64), (<class 'torch.nn.modules.activation.ELU'>, 32))}}
Simulation 3: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 64), (<class 'torch.nn.modules.activation.ELU'>, 64))}}
Simulation 2: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 64), (<class 'torch.nn.modules.activation.ELU'>, 32))}}
Simulation 4: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 32), (<class 'torch.nn.modules.activation.ELU'>, 32))}}
Simulation 3: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 64), (<class 'torch.nn.modules.activation.ELU'>, 64))}}
Simulation 5: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 32), (<class 'torch.nn.modules.activation.SiLU'>, 32))}}
Simulation 4: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 32), (<class 'torch.nn.modules.activation.ELU'>, 64))}}
Simulation 5: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 32), (<class 'torch.nn.modules.activation.SiLU'>, 64))}}
Simulation 6: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 32), (<class 'torch.nn.modules.activation.SiLU'>, 64))}}
Simulation 7: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 64), (<class 'torch.nn.modules.activation.SiLU'>, 64))}}
Simulation 8: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 64), (<class 'torch.nn.modules.activation.SiLU'>, 32))}}
Simulation 6: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 64), (<class 'torch.nn.modules.activation.SiLU'>, 32))}}
Simulation 7: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 32), (<class 'torch.nn.modules.activation.SiLU'>, 32))}}
Simulation 8: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 64), (<class 'torch.nn.modules.activation.SiLU'>, 64))}}
Simulation 9: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 64), (<class 'torch.nn.modules.activation.ELU'>, 64))}}
Simulation 10: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 32), (<class 'torch.nn.modules.activation.ELU'>, 32))}}
Simulation 1: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 32), (<class 'torch.nn.modules.activation.ELU'>, 32))}}
Simulation 2: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 64), (<class 'torch.nn.modules.activation.ELU'>, 32))}}
Simulation 9: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 32), (<class 'torch.nn.modules.activation.ELU'>, 64))}}
Simulation 11: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 32), (<class 'torch.nn.modules.activation.ELU'>, 64))}}
Simulation 10: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 64), (<class 'torch.nn.modules.activation.ELU'>, 32))}}
Simulation 11: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 32), (<class 'torch.nn.modules.activation.ELU'>, 32))}}
Simulation 3: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 32), (<class 'torch.nn.modules.activation.ELU'>, 64))}}
Simulation 4: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 64), (<class 'torch.nn.modules.activation.ELU'>, 64))}}
Simulation 12: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 64), (<class 'torch.nn.modules.activation.ELU'>, 32))}}
Simulation 13: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 32), (<class 'torch.nn.modules.activation.SiLU'>, 64))}}
Simulation 5: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 32), (<class 'torch.nn.modules.activation.SiLU'>, 64))}}
Simulation 12: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 64), (<class 'torch.nn.modules.activation.ELU'>, 64))}}
Simulation 14: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 32), (<class 'torch.nn.modules.activation.SiLU'>, 32))}}
Simulation 15: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 64), (<class 'torch.nn.modules.activation.SiLU'>, 64))}}
Simulation 16: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 64), (<class 'torch.nn.modules.activation.SiLU'>, 32))}}
Simulation 13: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 32), (<class 'torch.nn.modules.activation.SiLU'>, 64))}}
Simulation 14: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 64), (<class 'torch.nn.modules.activation.SiLU'>, 32))}}
Simulation 15: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 32), (<class 'torch.nn.modules.activation.SiLU'>, 32))}}
Simulation 16: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 64), (<class 'torch.nn.modules.activation.SiLU'>, 64))}}
Simulation 6: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 64), (<class 'torch.nn.modules.activation.SiLU'>, 64))}}
Simulation 7: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 32), (<class 'torch.nn.modules.activation.SiLU'>, 32))}}
Simulation 8: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.ELU'>, 64), (<class 'torch.nn.modules.activation.SiLU'>, 32))}}
Simulation 9: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 64), (<class 'torch.nn.modules.activation.ELU'>, 32))}}
Simulation 10: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 32), (<class 'torch.nn.modules.activation.ELU'>, 64))}}
Simulation 11: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 32), (<class 'torch.nn.modules.activation.ELU'>, 32))}}
Simulation 12: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 64), (<class 'torch.nn.modules.activation.ELU'>, 64))}}
Simulation 13: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 64), (<class 'torch.nn.modules.activation.SiLU'>, 64))}}
Simulation 14: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 32), (<class 'torch.nn.modules.activation.SiLU'>, 32))}}
Simulation 15: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 64), (<class 'torch.nn.modules.activation.SiLU'>, 32))}}
Simulation 16: {'model_params': {'hidden_layers': ((<class 'torch.nn.modules.activation.SiLU'>, 32), (<class 'torch.nn.modules.activation.SiLU'>, 64))}}
[1716358238.395661] [compute-1-0:892697:0]           ib_md.c:1232 UCX  WARN  IB: ibv_fork_init() was disabled or failed, yet a fork() has been issued.
[1716358238.395689] [compute-1-0:892697:0]           ib_md.c:1233 UCX  WARN  IB: data corruption might occur when using registered memory.
[1716358238.396357] [compute-1-0:892699:0]           ib_md.c:1232 UCX  WARN  IB: ibv_fork_init() was disabled or failed, yet a fork() has been issued.
[1716358238.396374] [compute-1-0:892699:0]           ib_md.c:1233 UCX  WARN  IB: data corruption might occur when using registered memory.
[1716358238.396412] [compute-1-0:892700:0]           ib_md.c:1232 UCX  WARN  IB: ibv_fork_init() was disabled or failed, yet a fork() has been issued.
[1716358238.396427] [compute-1-0:892700:0]           ib_md.c:1233 UCX  WARN  IB: data corruption might occur when using registered memory.
[1716358238.396458] [compute-1-0:892698:0]           ib_md.c:1232 UCX  WARN  IB: ibv_fork_init() was disabled or failed, yet a fork() has been issued.
[1716358238.396472] [compute-1-0:892698:0]           ib_md.c:1233 UCX  WARN  IB: data corruption might occur when using registered memory.
[1716358238.408947] [compute-1-0:892700:0]           ib_md.c:1232 UCX  WARN  IB: ibv_fork_init() was disabled or failed, yet a fork() has been issued.
[1716358238.408964] [compute-1-0:892700:0]           ib_md.c:1233 UCX  WARN  IB: data corruption might occur when using registered memory.
[1716358238.408959] [compute-1-0:892699:0]           ib_md.c:1232 UCX  WARN  IB: ibv_fork_init() was disabled or failed, yet a fork() has been issued.
[1716358238.408969] [compute-1-0:892699:0]           ib_md.c:1233 UCX  WARN  IB: data corruption might occur when using registered memory.
[1716358238.408960] [compute-1-0:892697:0]           ib_md.c:1232 UCX  WARN  IB: ibv_fork_init() was disabled or failed, yet a fork() has been issued.
[1716358238.408956] [compute-1-0:892698:0]           ib_md.c:1232 UCX  WARN  IB: ibv_fork_init() was disabled or failed, yet a fork() has been issued.
[1716358238.408969] [compute-1-0:892698:0]           ib_md.c:1233 UCX  WARN  IB: data corruption might occur when using registered memory.
[1716358238.408972] [compute-1-0:892697:0]           ib_md.c:1233 UCX  WARN  IB: data corruption might occur when using registered memory.
cuda:1
cuda:1
cuda:0
cuda:0
Folder already there
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=64, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=64, out_features=32, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=32, out_features=2, bias=True)
  )
)
Folder already there
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=32, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=32, out_features=32, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=32, out_features=2, bias=True)
  )
)
Folder already there
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=64, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=64, out_features=32, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=32, out_features=2, bias=True)
  )
)
Folder already there
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=64, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=64, out_features=2, bias=True)
  )
)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
Iteration 0: total loss 2.6536, losses: [2.653571605682373], learning rate: 0.0100000000
Iteration 0: total loss 2.4568, losses: [2.4568257331848145], learning rate: 0.0100000000
Iteration 0: total loss 2.8151, losses: [2.8151040077209473], learning rate: 0.0100000000
Iteration 0: total loss 2.6758, losses: [2.675790309906006], learning rate: 0.0100000000
Val loss  tensor(1.4972)
Val loss  tensor(1.0333)
Val loss  tensor(1.1708)
Val loss  tensor(1.2133)
Iteration 5000: total loss 0.2455, losses: [0.24545341730117798], learning rate: 0.0100000000
Iteration 5000: total loss 0.2525, losses: [0.2524877190589905], learning rate: 0.0100000000
Iteration 5000: total loss 0.2629, losses: [0.2628514766693115], learning rate: 0.0100000000
Iteration 5000: total loss 0.2678, losses: [0.2677982747554779], learning rate: 0.0100000000
Iteration 10000: total loss 0.2370, losses: [0.23695534467697144], learning rate: 0.0100000000
Iteration 10000: total loss 0.2473, losses: [0.2472512573003769], learning rate: 0.0100000000
Val loss  tensor(1.6264)
Val loss  tensor(1.7826)
Iteration 10000: total loss 0.1685, losses: [0.16853010654449463], learning rate: 0.0100000000
Iteration 10000: total loss 0.2571, losses: [0.25708550214767456], learning rate: 0.0100000000
Val loss  tensor(1.7947)
Val loss  tensor(1.6783)
Iteration 15000: total loss 0.1648, losses: [0.1648440808057785], learning rate: 0.0100000000
Iteration 15000: total loss 0.1868, losses: [0.18681806325912476], learning rate: 0.0100000000
Iteration 15000: total loss 0.2107, losses: [0.21073704957962036], learning rate: 0.0100000000
Iteration 15000: total loss 0.2003, losses: [0.20027759671211243], learning rate: 0.0100000000
Iteration 20000: total loss 0.1890, losses: [0.1889532208442688], learning rate: 0.0100000000
Iteration 20000: total loss 0.1831, losses: [0.18312013149261475], learning rate: 0.0100000000
Val loss  tensor(1.6113)
Val loss  tensor(1.7399)
Iteration 20000: total loss 0.1751, losses: [0.17507486045360565], learning rate: 0.0100000000
Iteration 20000: total loss 0.2145, losses: [0.21451735496520996], learning rate: 0.0100000000
Val loss  tensor(1.7483)
Val loss  tensor(1.6868)
Iteration 25000: total loss 0.1769, losses: [0.17694152891635895], learning rate: 0.0100000000
Iteration 25000: total loss 0.1723, losses: [0.17233268916606903], learning rate: 0.0100000000
Iteration 25000: total loss 0.2110, losses: [0.2110372930765152], learning rate: 0.0100000000
Iteration 25000: total loss 0.1792, losses: [0.1791507601737976], learning rate: 0.0100000000
Iteration 30000: total loss 0.1273, losses: [0.12730199098587036], learning rate: 0.0100000000
Iteration 30000: total loss 0.1749, losses: [0.17490559816360474], learning rate: 0.0100000000
Val loss  tensor(1.3343)
Val loss  tensor(1.5706)
Iteration 30000: total loss 0.1853, losses: [0.1853000372648239], learning rate: 0.0100000000
Iteration 30000: total loss 0.1551, losses: [0.15506064891815186], learning rate: 0.0100000000
Iteration 35000: total loss 0.1826, losses: [0.1825518012046814], learning rate: 0.0100000000
Iteration 35000: total loss 0.1986, losses: [0.19862425327301025], learning rate: 0.0100000000
Val loss  tensor(1.2433)
Val loss  tensor(1.2273)
Iteration 40000: total loss 0.1209, losses: [0.12092098593711853], learning rate: 0.0100000000
Iteration 40000: total loss 0.1978, losses: [0.19780008494853973], learning rate: 0.0100000000
Val loss  tensor(1.2178)
Val loss  tensor(1.7084)
Iteration 35000: total loss 0.1834, losses: [0.18337532877922058], learning rate: 0.0100000000
Iteration 35000: total loss 0.1950, losses: [0.19500568509101868], learning rate: 0.0100000000
Iteration 45000: total loss 0.1607, losses: [0.16068622469902039], learning rate: 0.0100000000
Iteration 45000: total loss 0.1615, losses: [0.16153477132320404], learning rate: 0.0100000000
Iteration 40000: total loss 0.1947, losses: [0.19470198452472687], learning rate: 0.0100000000
Iteration 40000: total loss 0.1545, losses: [0.15449586510658264], learning rate: 0.0100000000
Val loss  tensor(1.4422)
Val loss  tensor(1.0956)
Iteration 50000: total loss 0.1198, losses: [0.11977408826351166], learning rate: 0.0100000000
Iteration 50000: total loss 0.1542, losses: [0.15417705476284027], learning rate: 0.0100000000
Val loss  tensor(1.1812)
Val loss  tensor(1.6748)
Iteration 45000: total loss 0.1467, losses: [0.14671309292316437], learning rate: 0.0100000000
Iteration 45000: total loss 0.1899, losses: [0.18989601731300354], learning rate: 0.0100000000
Iteration 55000: total loss 0.1328, losses: [0.13278774917125702], learning rate: 0.0100000000
Iteration 55000: total loss 0.1312, losses: [0.1312379688024521], learning rate: 0.0100000000
Iteration 50000: total loss 0.1775, losses: [0.17749717831611633], learning rate: 0.0100000000
Iteration 50000: total loss 0.1499, losses: [0.1498757004737854], learning rate: 0.0100000000
Val loss  tensor(1.2013)
Val loss  tensor(1.4019)
Iteration 60000: total loss 0.1461, losses: [0.14609842002391815], learning rate: 0.0100000000
Iteration 60000: total loss 0.1597, losses: [0.15967750549316406], learning rate: 0.0100000000
Val loss  tensor(1.2152)
Val loss  tensor(1.6264)
Iteration 55000: total loss 0.1329, losses: [0.13293597102165222], learning rate: 0.0100000000
Iteration 55000: total loss 0.2022, losses: [0.2021908164024353], learning rate: 0.0100000000
Iteration 65000: total loss 0.0994, losses: [0.09937524050474167], learning rate: 0.0100000000
Iteration 65000: total loss 0.1541, losses: [0.15413178503513336], learning rate: 0.0100000000
Iteration 60000: total loss 0.1227, losses: [0.12267284095287323], learning rate: 0.0100000000
Iteration 60000: total loss 0.1907, losses: [0.1907311975955963], learning rate: 0.0100000000
Iteration 70000: total loss 0.1183, losses: [0.11830296367406845], learning rate: 0.0100000000
Iteration 70000: total loss 0.1569, losses: [0.15694600343704224], learning rate: 0.0100000000
Val loss  tensor(1.3458)
Val loss  tensor(1.2848)
Val loss  tensor(1.3072)
Val loss  tensor(1.5113)
Iteration 75000: total loss 0.1341, losses: [0.13409185409545898], learning rate: 0.0100000000
Iteration 75000: total loss 0.1472, losses: [0.14715346693992615], learning rate: 0.0100000000
Iteration 65000: total loss 0.1298, losses: [0.1297992467880249], learning rate: 0.0100000000
Iteration 65000: total loss 0.1955, losses: [0.19554004073143005], learning rate: 0.0100000000
Iteration 80000: total loss 0.1250, losses: [0.12502208352088928], learning rate: 0.0100000000
Iteration 80000: total loss 0.1381, losses: [0.13805519044399261], learning rate: 0.0100000000
Val loss  tensor(1.2511)
Val loss  tensor(1.5117)
Iteration 70000: total loss 0.1957, losses: [0.19565919041633606], learning rate: 0.0100000000
Iteration 70000: total loss 0.1601, losses: [0.16010412573814392], learning rate: 0.0100000000
Val loss  tensor(1.2166)
Val loss  tensor(1.1973)
Iteration 85000: total loss 0.1270, losses: [0.12698417901992798], learning rate: 0.0100000000
Iteration 85000: total loss 0.1454, losses: [0.14536072313785553], learning rate: 0.0100000000
Iteration 75000: total loss 0.1361, losses: [0.1360980123281479], learning rate: 0.0100000000
Iteration 75000: total loss 0.1730, losses: [0.1730300486087799], learning rate: 0.0100000000
Iteration 90000: total loss 0.1261, losses: [0.1260690987110138], learning rate: 0.0100000000
Iteration 90000: total loss 0.1300, losses: [0.1300348937511444], learning rate: 0.0100000000
Val loss  tensor(1.3135)
Val loss  tensor(1.6769)
Iteration 80000: total loss 0.1413, losses: [0.14134764671325684], learning rate: 0.0100000000
Iteration 80000: total loss 0.1603, losses: [0.16033485531806946], learning rate: 0.0100000000
Val loss  tensor(1.1165)
Val loss  tensor(1.1430)
Iteration 95000: total loss 0.1213, losses: [0.12128905951976776], learning rate: 0.0100000000
Iteration 95000: total loss 0.1187, losses: [0.11866305768489838], learning rate: 0.0100000000
Iteration 85000: total loss 0.1461, losses: [0.14612272381782532], learning rate: 0.0100000000
Iteration 85000: total loss 0.1629, losses: [0.16290128231048584], learning rate: 0.0100000000
Iteration 100000: total loss 0.0998, losses: [0.09975609183311462], learning rate: 0.0100000000
Iteration 100000: total loss 0.1398, losses: [0.1398448646068573], learning rate: 0.0100000000
Val loss  tensor(1.2147)
Val loss  tensor(1.5870)
Iteration 90000: total loss 0.1534, losses: [0.15340891480445862], learning rate: 0.0100000000
Iteration 90000: total loss 0.1477, losses: [0.14774705469608307], learning rate: 0.0100000000
Val loss  tensor(1.3861)
Val loss  tensor(1.0835)
Iteration 105000: total loss 0.1341, losses: [0.13413184881210327], learning rate: 0.0100000000
Iteration 105000: total loss 0.1437, losses: [0.14372146129608154], learning rate: 0.0100000000
Iteration 110000: total loss 0.1170, losses: [0.11698566377162933], learning rate: 0.0100000000
Iteration 110000: total loss 0.0950, losses: [0.09497763216495514], learning rate: 0.0100000000
Val loss  tensor(1.2065)
Val loss  tensor(1.5106)
Iteration 95000: total loss 0.2107, losses: [0.2107280194759369], learning rate: 0.0100000000
Iteration 95000: total loss 0.1473, losses: [0.1473301500082016], learning rate: 0.0100000000
Iteration 115000: total loss 0.1120, losses: [0.11202062666416168], learning rate: 0.0099000000
Iteration 115000: total loss 0.1338, losses: [0.13381370902061462], learning rate: 0.0099000000
Iteration 100000: total loss 0.1498, losses: [0.1498032808303833], learning rate: 0.0100000000
Iteration 100000: total loss 0.1203, losses: [0.12028180062770844], learning rate: 0.0100000000
Val loss  tensor(1.1340)
Val loss  tensor(0.9932)
Iteration 120000: total loss 0.1131, losses: [0.11309255659580231], learning rate: 0.0099000000
Iteration 120000: total loss 0.1136, losses: [0.1136198416352272], learning rate: 0.0099000000
Val loss  tensor(1.2422)
Val loss  tensor(1.3782)
Iteration 105000: total loss 0.1260, losses: [0.1259932518005371], learning rate: 0.0100000000
Iteration 105000: total loss 0.1196, losses: [0.11964049935340881], learning rate: 0.0100000000
Iteration 125000: total loss 0.1028, losses: [0.10283806174993515], learning rate: 0.0099000000
Iteration 125000: total loss 0.1482, losses: [0.14815224707126617], learning rate: 0.0099000000
Iteration 110000: total loss 0.1041, losses: [0.10407115519046783], learning rate: 0.0100000000
Iteration 110000: total loss 0.1267, losses: [0.12674769759178162], learning rate: 0.0100000000
Val loss  tensor(1.1305)
Val loss  tensor(1.0535)
Iteration 130000: total loss 0.1199, losses: [0.11985594034194946], learning rate: 0.0099000000
Iteration 130000: total loss 0.1360, losses: [0.1359548717737198], learning rate: 0.0099000000
Val loss  tensor(1.0713)
Val loss  tensor(1.3038)
Iteration 115000: total loss 0.1419, losses: [0.14193232357501984], learning rate: 0.0100000000
Iteration 115000: total loss 0.1606, losses: [0.16055916249752045], learning rate: 0.0100000000
Iteration 135000: total loss 0.1018, losses: [0.10180952399969101], learning rate: 0.0099000000
Iteration 135000: total loss 0.1264, losses: [0.12643375992774963], learning rate: 0.0099000000
Iteration 120000: total loss 0.1311, losses: [0.1310863494873047], learning rate: 0.0100000000
Iteration 120000: total loss 0.1282, losses: [0.12821948528289795], learning rate: 0.0100000000
Val loss  tensor(1.0680)
Val loss  tensor(0.9052)
Iteration 140000: total loss 0.1164, losses: [0.11643047630786896], learning rate: 0.0099000000
Iteration 140000: total loss 0.1254, losses: [0.1253577470779419], learning rate: 0.0099000000
Val loss  tensor(1.0665)
Val loss  tensor(1.3319)
Iteration 145000: total loss 0.0983, losses: [0.09831087291240692], learning rate: 0.0099000000
Iteration 145000: total loss 0.1408, losses: [0.14081773161888123], learning rate: 0.0099000000
Iteration 125000: total loss 0.1278, losses: [0.1278088390827179], learning rate: 0.0100000000
Iteration 125000: total loss 0.1444, losses: [0.14436081051826477], learning rate: 0.0100000000
Iteration 150000: total loss 0.1104, losses: [0.11044941842556], learning rate: 0.0099000000
Iteration 150000: total loss 0.1496, losses: [0.14956575632095337], learning rate: 0.0099000000
Val loss  tensor(1.0678)
Val loss  tensor(1.3962)
Iteration 130000: total loss 0.1509, losses: [0.15091896057128906], learning rate: 0.0100000000
Iteration 130000: total loss 0.1280, losses: [0.12797580659389496], learning rate: 0.0100000000
Val loss  tensor(0.8636)
Val loss  tensor(1.1727)
Iteration 155000: total loss 0.0969, losses: [0.0969361960887909], learning rate: 0.0099000000
Iteration 155000: total loss 0.1140, losses: [0.11398730427026749], learning rate: 0.0099000000
Iteration 135000: total loss 0.1049, losses: [0.1048775464296341], learning rate: 0.0100000000
Iteration 135000: total loss 0.1495, losses: [0.14945098757743835], learning rate: 0.0100000000
Iteration 160000: total loss 0.0868, losses: [0.08681932836771011], learning rate: 0.0099000000
Iteration 160000: total loss 0.1267, losses: [0.1266997903585434], learning rate: 0.0099000000
Val loss  tensor(1.0728)
Val loss  tensor(1.2133)
Iteration 140000: total loss 0.1369, losses: [0.13690005242824554], learning rate: 0.0100000000
Iteration 140000: total loss 0.2817, losses: [0.28168773651123047], learning rate: 0.0100000000
Val loss  tensor(0.8562)
Val loss  tensor(1.2113)
Iteration 165000: total loss 0.0928, losses: [0.09275919198989868], learning rate: 0.0099000000
Iteration 165000: total loss 0.1236, losses: [0.12358509004116058], learning rate: 0.0099000000
Iteration 145000: total loss 0.1204, losses: [0.12043061852455139], learning rate: 0.0100000000
Iteration 145000: total loss 0.1474, losses: [0.14741456508636475], learning rate: 0.0100000000
Iteration 170000: total loss 0.0929, losses: [0.09294005483388901], learning rate: 0.0099000000
Iteration 170000: total loss 0.1196, losses: [0.1195794865489006], learning rate: 0.0099000000
Val loss  tensor(1.0773)
Val loss  tensor(1.2817)
Iteration 150000: total loss 0.1162, losses: [0.1161842793226242], learning rate: 0.0100000000
Iteration 150000: total loss 0.1338, losses: [0.13380707800388336], learning rate: 0.0100000000
Val loss  tensor(1.2283)
Val loss  tensor(0.8829)
Iteration 175000: total loss 0.0956, losses: [0.0956496149301529], learning rate: 0.0099000000
Iteration 175000: total loss 0.1345, losses: [0.13453605771064758], learning rate: 0.0099000000
Iteration 180000: total loss 0.1107, losses: [0.11066266894340515], learning rate: 0.0099000000
Iteration 180000: total loss 0.1488, losses: [0.14884692430496216], learning rate: 0.0099000000
Val loss  tensor(1.1632)
Val loss  tensor(1.0790)
Iteration 155000: total loss 0.1239, losses: [0.12393268197774887], learning rate: 0.0100000000
Iteration 155000: total loss 0.1540, losses: [0.15395748615264893], learning rate: 0.0100000000
Iteration 185000: total loss 0.0862, losses: [0.08616526424884796], learning rate: 0.0099000000
Iteration 185000: total loss 0.1386, losses: [0.13863623142242432], learning rate: 0.0099000000
Iteration 160000: total loss 0.1057, losses: [0.10573999583721161], learning rate: 0.0100000000
Iteration 160000: total loss 0.1266, losses: [0.12661868333816528], learning rate: 0.0100000000
Val loss  tensor(1.0397)
Val loss  tensor(0.9381)
Iteration 190000: total loss 0.1072, losses: [0.10720312595367432], learning rate: 0.0099000000
Iteration 190000: total loss 0.1180, losses: [0.11795403063297272], learning rate: 0.0099000000
Val loss  tensor(1.0921)
Val loss  tensor(1.1778)
Iteration 165000: total loss 0.1061, losses: [0.1060994565486908], learning rate: 0.0100000000
Iteration 165000: total loss 0.1270, losses: [0.1270453929901123], learning rate: 0.0100000000
Iteration 195000: total loss 0.0995, losses: [0.09948103874921799], learning rate: 0.0099000000
Iteration 195000: total loss 0.1374, losses: [0.1374204456806183], learning rate: 0.0099000000
Iteration 170000: total loss 0.1098, losses: [0.10976733267307281], learning rate: 0.0100000000
Iteration 170000: total loss 0.1451, losses: [0.14513282477855682], learning rate: 0.0100000000
Val loss  tensor(1.0564)
Val loss  tensor(1.1525)
Iteration 200000: total loss 0.1097, losses: [0.10969875752925873], learning rate: 0.0099000000
Iteration 200000: total loss 0.1009, losses: [0.10087928175926208], learning rate: 0.0099000000
Val loss  tensor(1.0813)
Val loss  tensor(1.2826)
Iteration 175000: total loss 0.1199, losses: [0.11990641057491302], learning rate: 0.0100000000
Iteration 175000: total loss 0.1370, losses: [0.13701000809669495], learning rate: 0.0100000000
Iteration 205000: total loss 0.1283, losses: [0.12832847237586975], learning rate: 0.0099000000
Iteration 205000: total loss 0.1339, losses: [0.1339287906885147], learning rate: 0.0099000000
Iteration 180000: total loss 0.1371, losses: [0.137061208486557], learning rate: 0.0100000000
Iteration 180000: total loss 0.1106, losses: [0.1106434166431427], learning rate: 0.0100000000
Val loss  tensor(1.0463)
Val loss  tensor(1.0309)
Iteration 210000: total loss 0.1407, losses: [0.14070424437522888], learning rate: 0.0099000000
Iteration 210000: total loss 0.1352, losses: [0.13517677783966064], learning rate: 0.0099000000
Val loss  tensor(1.0601)
Val loss  tensor(1.1619)
Iteration 215000: total loss 0.0899, losses: [0.08994883298873901], learning rate: 0.0099000000
Iteration 215000: total loss 0.1240, losses: [0.12402445077896118], learning rate: 0.0099000000
Iteration 185000: total loss 0.1427, losses: [0.1426989734172821], learning rate: 0.0100000000
Iteration 185000: total loss 0.1117, losses: [0.11166740208864212], learning rate: 0.0100000000
Iteration 220000: total loss 0.1145, losses: [0.11446822434663773], learning rate: 0.0099000000
Iteration 220000: total loss 0.1140, losses: [0.11402946710586548], learning rate: 0.0099000000
Val loss  tensor(1.0905)
Val loss  tensor(1.2564)
Iteration 190000: total loss 0.0922, losses: [0.0922444760799408], learning rate: 0.0100000000
Iteration 190000: total loss 0.1409, losses: [0.14090867340564728], learning rate: 0.0100000000
Val loss  tensor(1.0905)
Val loss  tensor(1.0302)
Iteration 225000: total loss 0.1095, losses: [0.10951663553714752], learning rate: 0.0098010000
Iteration 225000: total loss 0.1042, losses: [0.10418418049812317], learning rate: 0.0099000000
Iteration 195000: total loss 0.1199, losses: [0.1198773980140686], learning rate: 0.0100000000
Iteration 195000: total loss 0.1202, losses: [0.12018510699272156], learning rate: 0.0100000000
Iteration 230000: total loss 0.0828, losses: [0.08277004212141037], learning rate: 0.0098010000
Iteration 230000: total loss 0.1150, losses: [0.11501030623912811], learning rate: 0.0099000000
Val loss  tensor(1.0835)
Val loss  tensor(1.1499)
Iteration 200000: total loss 0.1389, losses: [0.13894768059253693], learning rate: 0.0100000000
Iteration 200000: total loss 0.1449, losses: [0.14492875337600708], learning rate: 0.0100000000
Val loss  tensor(1.0170)
Val loss  tensor(1.0608)
Iteration 235000: total loss 0.1156, losses: [0.11555491387844086], learning rate: 0.0098010000
Iteration 235000: total loss 0.1154, losses: [0.11538225412368774], learning rate: 0.0099000000
Iteration 205000: total loss 0.1022, losses: [0.10218353569507599], learning rate: 0.0100000000
Iteration 205000: total loss 0.1170, losses: [0.11698552966117859], learning rate: 0.0100000000
Iteration 240000: total loss 0.1076, losses: [0.10763515532016754], learning rate: 0.0098010000
Iteration 240000: total loss 0.1051, losses: [0.10511107742786407], learning rate: 0.0099000000
Val loss  tensor(1.0919)
Val loss  tensor(1.1409)
Iteration 210000: total loss 0.1180, losses: [0.11795222014188766], learning rate: 0.0100000000
Iteration 210000: total loss 0.1470, losses: [0.14696210622787476], learning rate: 0.0100000000
Val loss  tensor(1.0522)
Val loss  tensor(1.0019)
Iteration 245000: total loss 0.0865, losses: [0.08653556555509567], learning rate: 0.0098010000
Iteration 245000: total loss 0.1118, losses: [0.11180439591407776], learning rate: 0.0099000000
Iteration 250000: total loss 0.0872, losses: [0.08715015649795532], learning rate: 0.0098010000
Iteration 250000: total loss 0.1100, losses: [0.1099637970328331], learning rate: 0.0099000000
Iteration 215000: total loss 0.1138, losses: [0.11376692354679108], learning rate: 0.0100000000
Iteration 215000: total loss 0.1454, losses: [0.1453612744808197], learning rate: 0.0100000000
Val loss  tensor(1.0712)
Val loss  tensor(1.1591)
Iteration 255000: total loss 0.1077, losses: [0.10774094611406326], learning rate: 0.0098010000
Iteration 255000: total loss 0.1334, losses: [0.13342155516147614], learning rate: 0.0099000000
Iteration 220000: total loss 0.1297, losses: [0.1297382116317749], learning rate: 0.0100000000
Iteration 220000: total loss 0.1108, losses: [0.11084750294685364], learning rate: 0.0100000000
Val loss  tensor(1.0894)
Val loss  tensor(1.0687)
Iteration 260000: total loss 0.0922, losses: [0.09220656007528305], learning rate: 0.0098010000
Iteration 260000: total loss 0.1262, losses: [0.1261626034975052], learning rate: 0.0099000000
Val loss  tensor(1.0701)
Val loss  tensor(1.1438)
Iteration 225000: total loss 0.1317, losses: [0.13166125118732452], learning rate: 0.0100000000
Iteration 225000: total loss 0.1121, losses: [0.11207129061222076], learning rate: 0.0100000000
Iteration 265000: total loss 0.0860, losses: [0.08596370369195938], learning rate: 0.0098010000
Iteration 265000: total loss 0.1024, losses: [0.10236117988824844], learning rate: 0.0099000000
Iteration 230000: total loss 0.0995, losses: [0.0994991883635521], learning rate: 0.0100000000
Iteration 230000: total loss 0.1205, losses: [0.12054353952407837], learning rate: 0.0100000000
Val loss  tensor(1.0917)
Val loss  tensor(1.0301)
Iteration 270000: total loss 0.1062, losses: [0.10621270537376404], learning rate: 0.0098010000
Iteration 270000: total loss 0.0900, losses: [0.08997026830911636], learning rate: 0.0099000000
Val loss  tensor(1.1053)
Val loss  tensor(1.1786)
Iteration 235000: total loss 0.0955, losses: [0.09549917280673981], learning rate: 0.0100000000
Iteration 235000: total loss 0.1208, losses: [0.12084470689296722], learning rate: 0.0100000000
Iteration 275000: total loss 0.0931, losses: [0.09311771392822266], learning rate: 0.0098010000
Iteration 275000: total loss 0.1067, losses: [0.10673205554485321], learning rate: 0.0099000000
Iteration 240000: total loss 0.0967, losses: [0.09668523073196411], learning rate: 0.0100000000
Iteration 240000: total loss 0.0954, losses: [0.09543411433696747], learning rate: 0.0100000000
Val loss  tensor(1.0525)
Val loss  tensor(1.2296)
Iteration 280000: total loss 0.0867, losses: [0.0867457389831543], learning rate: 0.0098010000
Iteration 280000: total loss 0.1132, losses: [0.11315103620290756], learning rate: 0.0099000000
Val loss  tensor(1.1084)
Val loss  tensor(1.2155)
Iteration 245000: total loss 0.1246, losses: [0.12456466257572174], learning rate: 0.0100000000
Iteration 245000: total loss 0.1129, losses: [0.11288110911846161], learning rate: 0.0100000000
Iteration 285000: total loss 0.0919, losses: [0.09190081059932709], learning rate: 0.0098010000
Iteration 285000: total loss 0.1378, losses: [0.13782085478305817], learning rate: 0.0099000000
Iteration 290000: total loss 0.0744, losses: [0.07444114238023758], learning rate: 0.0098010000
Iteration 290000: total loss 0.1201, losses: [0.1201343908905983], learning rate: 0.0099000000
Val loss  tensor(1.1086)
Val loss  tensor(1.2996)
Iteration 250000: total loss 0.1076, losses: [0.10760355740785599], learning rate: 0.0100000000
Iteration 250000: total loss 0.1032, losses: [0.10320936143398285], learning rate: 0.0100000000
Val loss  tensor(1.1548)
Val loss  tensor(1.2421)
Iteration 295000: total loss 0.1162, losses: [0.11615435779094696], learning rate: 0.0098010000
Iteration 295000: total loss 0.1174, losses: [0.1173882782459259], learning rate: 0.0099000000
Iteration 255000: total loss 0.1128, losses: [0.1127978265285492], learning rate: 0.0100000000
Iteration 255000: total loss 0.1251, losses: [0.12512609362602234], learning rate: 0.0099000000
Iteration 300000: total loss 0.1053, losses: [0.1052703857421875], learning rate: 0.0098010000
Iteration 300000: total loss 0.1199, losses: [0.11987311393022537], learning rate: 0.0099000000
Val loss  tensor(1.1279)
Val loss  tensor(1.3500)
Iteration 260000: total loss 0.1179, losses: [0.11786237359046936], learning rate: 0.0099000000
Iteration 260000: total loss 0.0958, losses: [0.09578024595975876], learning rate: 0.0100000000
Val loss  tensor(1.2512)
Val loss  tensor(1.0309)
Iteration 305000: total loss 0.1171, losses: [0.11712558567523956], learning rate: 0.0098010000
Iteration 305000: total loss 0.1048, losses: [0.10484494268894196], learning rate: 0.0099000000
Iteration 265000: total loss 0.1280, losses: [0.12802736461162567], learning rate: 0.0099000000
Iteration 265000: total loss 0.1053, losses: [0.10531151294708252], learning rate: 0.0100000000
Iteration 310000: total loss 0.1209, losses: [0.12087490409612656], learning rate: 0.0098010000
Iteration 310000: total loss 0.1028, losses: [0.10283467173576355], learning rate: 0.0099000000
Val loss  tensor(1.1257)
Val loss  tensor(1.4008)
Iteration 270000: total loss 0.2061, losses: [0.2060532122850418], learning rate: 0.0099000000
Iteration 270000: total loss 0.1067, losses: [0.10671450942754745], learning rate: 0.0100000000
Val loss  tensor(1.0448)
Val loss  tensor(1.2778)
Iteration 315000: total loss 0.1165, losses: [0.11652129888534546], learning rate: 0.0098010000
Iteration 315000: total loss 0.1027, losses: [0.10267294943332672], learning rate: 0.0099000000
Iteration 275000: total loss 0.1300, losses: [0.13001343607902527], learning rate: 0.0099000000
Iteration 275000: total loss 0.0944, losses: [0.09438712149858475], learning rate: 0.0100000000
Iteration 320000: total loss 0.0732, losses: [0.07315219193696976], learning rate: 0.0098010000
Iteration 320000: total loss 0.1284, losses: [0.12835906445980072], learning rate: 0.0099000000
Val loss  tensor(1.1301)
Val loss  tensor(1.3043)
Iteration 325000: total loss 0.1033, losses: [0.1032903790473938], learning rate: 0.0098010000
Iteration 325000: total loss 0.1037, losses: [0.10365895181894302], learning rate: 0.0099000000
Iteration 280000: total loss 0.1027, losses: [0.10269656032323837], learning rate: 0.0100000000
Iteration 280000: total loss 0.1439, losses: [0.14392337203025818], learning rate: 0.0099000000
Val loss  tensor(1.2048)
Val loss  tensor(1.3781)
Iteration 330000: total loss 0.0971, losses: [0.0970512181520462], learning rate: 0.0098010000
Iteration 330000: total loss 0.1263, losses: [0.12633953988552094], learning rate: 0.0099000000
Val loss  tensor(1.1149)
Val loss  tensor(1.3395)
Iteration 285000: total loss 0.1007, losses: [0.10068890452384949], learning rate: 0.0100000000
Iteration 285000: total loss 0.1577, losses: [0.1576692909002304], learning rate: 0.0099000000
Iteration 335000: total loss 0.0913, losses: [0.0912509337067604], learning rate: 0.0097029900
Iteration 335000: total loss 0.1176, losses: [0.11757080256938934], learning rate: 0.0099000000
Iteration 290000: total loss 0.0996, losses: [0.09962334483861923], learning rate: 0.0100000000
Iteration 290000: total loss 0.2287, losses: [0.22869381308555603], learning rate: 0.0099000000
Val loss  tensor(1.0957)
Val loss  tensor(1.3680)
Iteration 340000: total loss 0.1201, losses: [0.12007355690002441], learning rate: 0.0097029900
Iteration 340000: total loss 0.1215, losses: [0.12152303755283356], learning rate: 0.0099000000
Val loss  tensor(1.1376)
Val loss  tensor(1.3447)
Iteration 295000: total loss 0.1545, losses: [0.15445247292518616], learning rate: 0.0099000000
Iteration 295000: total loss 0.0965, losses: [0.0964922159910202], learning rate: 0.0100000000
Iteration 345000: total loss 0.1058, losses: [0.10579748451709747], learning rate: 0.0097029900
Iteration 345000: total loss 0.1290, losses: [0.12896133959293365], learning rate: 0.0099000000
Iteration 300000: total loss 0.1178, losses: [0.11781591922044754], learning rate: 0.0099000000
Iteration 300000: total loss 0.0961, losses: [0.09610592573881149], learning rate: 0.0100000000
Val loss  tensor(1.2367)
Val loss  tensor(1.1139)
Iteration 350000: total loss 0.0950, losses: [0.09499986469745636], learning rate: 0.0097029900
Iteration 350000: total loss 0.1105, losses: [0.11051948368549347], learning rate: 0.0099000000
Val loss  tensor(1.1179)
Val loss  tensor(1.2701)
Iteration 305000: total loss 0.0898, losses: [0.08976956456899643], learning rate: 0.0100000000
Iteration 305000: total loss 0.0933, losses: [0.09327378123998642], learning rate: 0.0099000000
Iteration 355000: total loss 0.0841, losses: [0.08410847187042236], learning rate: 0.0097029900
Iteration 355000: total loss 0.1091, losses: [0.10914748907089233], learning rate: 0.0098010000
Iteration 360000: total loss 0.1105, losses: [0.11050140112638474], learning rate: 0.0097029900
Iteration 360000: total loss 0.1041, losses: [0.10405680537223816], learning rate: 0.0098010000
Val loss  tensor(1.1304)
Val loss  tensor(1.3236)
Iteration 310000: total loss 0.1016, losses: [0.1015918180346489], learning rate: 0.0100000000
Iteration 310000: total loss 0.1295, losses: [0.12954802811145782], learning rate: 0.0099000000
Val loss  tensor(1.1025)
Val loss  tensor(1.4197)
Iteration 365000: total loss 0.0974, losses: [0.09743379056453705], learning rate: 0.0097029900
Iteration 365000: total loss 0.0988, losses: [0.0987541526556015], learning rate: 0.0098010000
Iteration 315000: total loss 0.1270, losses: [0.12695544958114624], learning rate: 0.0100000000
Iteration 315000: total loss 0.0941, losses: [0.09408576786518097], learning rate: 0.0099000000
Iteration 370000: total loss 0.0893, losses: [0.08930608630180359], learning rate: 0.0097029900
Iteration 370000: total loss 0.1136, losses: [0.11357521265745163], learning rate: 0.0098010000
Val loss  tensor(1.1362)
Val loss  tensor(1.2833)
Iteration 320000: total loss 0.1225, losses: [0.1225491538643837], learning rate: 0.0100000000
Iteration 320000: total loss 0.0906, losses: [0.09055369347333908], learning rate: 0.0099000000
Val loss  tensor(1.0891)
Val loss  tensor(1.3686)
Iteration 375000: total loss 0.0804, losses: [0.08042685687541962], learning rate: 0.0097029900
Iteration 375000: total loss 0.1045, losses: [0.10452726483345032], learning rate: 0.0098010000
Iteration 325000: total loss 0.0924, losses: [0.09238828718662262], learning rate: 0.0099000000
Iteration 325000: total loss 0.1265, losses: [0.12650427222251892], learning rate: 0.0099000000
Iteration 380000: total loss 0.0856, losses: [0.08556261658668518], learning rate: 0.0097029900
Iteration 380000: total loss 0.1023, losses: [0.10229101032018661], learning rate: 0.0098010000
Val loss  tensor(1.1406)
Val loss  tensor(1.3481)
Iteration 330000: total loss 0.1118, losses: [0.11179296672344208], learning rate: 0.0099000000
Iteration 330000: total loss 0.0941, losses: [0.09414854645729065], learning rate: 0.0099000000
Val loss  tensor(1.4199)
Val loss  tensor(1.1249)
Iteration 385000: total loss 0.0860, losses: [0.08601216971874237], learning rate: 0.0097029900
Iteration 385000: total loss 0.1264, losses: [0.12635502219200134], learning rate: 0.0098010000
Iteration 335000: total loss 0.1223, losses: [0.12229208648204803], learning rate: 0.0099000000
Iteration 335000: total loss 0.0851, losses: [0.08513447642326355], learning rate: 0.0099000000
Iteration 390000: total loss 0.1153, losses: [0.1153239831328392], learning rate: 0.0097029900
Iteration 390000: total loss 0.1151, losses: [0.11509110033512115], learning rate: 0.0098010000
Val loss  tensor(1.1279)
Val loss  tensor(1.3990)
Iteration 395000: total loss 0.0858, losses: [0.08580586314201355], learning rate: 0.0097029900
Iteration 395000: total loss 0.1047, losses: [0.10466225445270538], learning rate: 0.0098010000
Iteration 340000: total loss 0.1078, losses: [0.10778839141130447], learning rate: 0.0099000000
Iteration 340000: total loss 0.0961, losses: [0.09609635174274445], learning rate: 0.0099000000
Val loss  tensor(1.3675)
Val loss  tensor(1.0664)
Iteration 400000: total loss 0.0985, losses: [0.09854035824537277], learning rate: 0.0097029900
Iteration 400000: total loss 0.1136, losses: [0.11357469111680984], learning rate: 0.0098010000
Val loss  tensor(1.1444)
Val loss  tensor(1.3666)
Iteration 345000: total loss 0.0980, losses: [0.09796325117349625], learning rate: 0.0099000000
Iteration 345000: total loss 0.1253, losses: [0.12531988322734833], learning rate: 0.0099000000
Iteration 405000: total loss 0.1151, losses: [0.11512023955583572], learning rate: 0.0097029900
Iteration 405000: total loss 0.1317, losses: [0.13168957829475403], learning rate: 0.0098010000
Iteration 350000: total loss 0.1060, losses: [0.10599833726882935], learning rate: 0.0099000000
Iteration 350000: total loss 0.1104, losses: [0.11036732792854309], learning rate: 0.0099000000
Val loss  tensor(1.1050)
Val loss  tensor(1.4286)
Iteration 410000: total loss 0.0800, losses: [0.08000447601079941], learning rate: 0.0097029900
Iteration 410000: total loss 0.1035, losses: [0.1034729927778244], learning rate: 0.0098010000
Val loss  tensor(1.1368)
Val loss  tensor(1.3157)
Iteration 355000: total loss 0.1155, losses: [0.11549800634384155], learning rate: 0.0099000000
Iteration 355000: total loss 0.0845, losses: [0.08452410995960236], learning rate: 0.0099000000
Iteration 415000: total loss 0.1142, losses: [0.11419492959976196], learning rate: 0.0097029900
Iteration 415000: total loss 0.1163, losses: [0.11629028618335724], learning rate: 0.0098010000
Iteration 360000: total loss 0.0979, losses: [0.09787564724683762], learning rate: 0.0099000000
Iteration 360000: total loss 0.1174, losses: [0.11744710803031921], learning rate: 0.0099000000
Val loss  tensor(1.1038)
Val loss  tensor(1.3928)
Iteration 420000: total loss 0.1140, losses: [0.11403150856494904], learning rate: 0.0097029900
Iteration 420000: total loss 0.1300, losses: [0.13002893328666687], learning rate: 0.0098010000
Val loss  tensor(1.1541)
Val loss  tensor(1.3162)
Iteration 365000: total loss 0.0806, losses: [0.08062425255775452], learning rate: 0.0099000000
Iteration 365000: total loss 0.1097, losses: [0.10971653461456299], learning rate: 0.0098010000
Iteration 425000: total loss 0.0976, losses: [0.09756480902433395], learning rate: 0.0097029900
Iteration 425000: total loss 0.1073, losses: [0.10727875679731369], learning rate: 0.0098010000
Iteration 430000: total loss 0.1089, losses: [0.10889162123203278], learning rate: 0.0097029900
Iteration 430000: total loss 0.1152, losses: [0.11524403840303421], learning rate: 0.0098010000
Val loss  tensor(1.1503)
Val loss  tensor(1.3894)
Iteration 370000: total loss 0.0976, losses: [0.09759365767240524], learning rate: 0.0099000000
Iteration 370000: total loss 0.0876, losses: [0.08764272183179855], learning rate: 0.0098010000
Val loss  tensor(1.0469)
Val loss  tensor(1.2989)
Iteration 435000: total loss 0.0919, losses: [0.09187967330217361], learning rate: 0.0097029900
Iteration 435000: total loss 0.1080, losses: [0.10804548114538193], learning rate: 0.0098010000
Iteration 375000: total loss 0.0866, losses: [0.08662454038858414], learning rate: 0.0099000000
Iteration 375000: total loss 0.0965, losses: [0.09645255655050278], learning rate: 0.0098010000
Iteration 440000: total loss 0.1007, losses: [0.10073015093803406], learning rate: 0.0097029900
Iteration 440000: total loss 0.1156, losses: [0.11563092470169067], learning rate: 0.0098010000
Val loss  tensor(1.1554)
Val loss  tensor(1.3467)
Iteration 380000: total loss 0.1118, losses: [0.1117548793554306], learning rate: 0.0098010000
Iteration 380000: total loss 0.0989, losses: [0.0988892912864685], learning rate: 0.0099000000
Val loss  tensor(1.4797)
Val loss  tensor(1.2077)
Iteration 445000: total loss 0.0925, losses: [0.09250292181968689], learning rate: 0.0096059601
Iteration 445000: total loss 0.1132, losses: [0.11323711276054382], learning rate: 0.0098010000
Iteration 385000: total loss 0.1019, losses: [0.10189151763916016], learning rate: 0.0098010000
Iteration 385000: total loss 0.1184, losses: [0.11835126578807831], learning rate: 0.0099000000
Iteration 450000: total loss 0.0974, losses: [0.09738855063915253], learning rate: 0.0096059601
Iteration 450000: total loss 0.1018, losses: [0.10183130204677582], learning rate: 0.0098010000
Val loss  tensor(1.1413)
Val loss  tensor(1.2998)
Iteration 390000: total loss 0.1017, losses: [0.1016964316368103], learning rate: 0.0099000000
Iteration 390000: total loss 0.1132, losses: [0.11316400021314621], learning rate: 0.0098010000
Val loss  tensor(1.4318)
Val loss  tensor(1.1153)
Iteration 455000: total loss 0.1011, losses: [0.10110480338335037], learning rate: 0.0096059601
Iteration 455000: total loss 0.1122, losses: [0.11217032372951508], learning rate: 0.0098010000
Iteration 395000: total loss 0.1026, losses: [0.10258668661117554], learning rate: 0.0099000000
Iteration 395000: total loss 0.1036, losses: [0.10357475280761719], learning rate: 0.0098010000
Iteration 460000: total loss 0.1022, losses: [0.10215814411640167], learning rate: 0.0096059601
Iteration 460000: total loss 0.1311, losses: [0.13113610446453094], learning rate: 0.0098010000
Val loss  tensor(1.1314)
Val loss  tensor(1.4473)
Iteration 465000: total loss 0.0928, losses: [0.09275205433368683], learning rate: 0.0096059601
Iteration 465000: total loss 0.1190, losses: [0.118974469602108], learning rate: 0.0097029900
Iteration 400000: total loss 0.0938, losses: [0.09382634609937668], learning rate: 0.0099000000
Iteration 400000: total loss 0.1079, losses: [0.10792014747858047], learning rate: 0.0098010000
Val loss  tensor(1.1831)
Val loss  tensor(1.3765)
Iteration 470000: total loss 0.1019, losses: [0.10192495584487915], learning rate: 0.0096059601
Iteration 470000: total loss 0.0920, losses: [0.09204075485467911], learning rate: 0.0097029900
Val loss  tensor(1.1949)
Val loss  tensor(1.3657)
Iteration 405000: total loss 0.1255, losses: [0.12547728419303894], learning rate: 0.0098010000
Iteration 405000: total loss 0.0890, losses: [0.08900398015975952], learning rate: 0.0099000000
Iteration 475000: total loss 0.0845, losses: [0.08454678952693939], learning rate: 0.0096059601
Iteration 475000: total loss 0.1166, losses: [0.1165839284658432], learning rate: 0.0097029900
Iteration 410000: total loss 0.0881, losses: [0.08805456757545471], learning rate: 0.0099000000
Iteration 410000: total loss 0.1071, losses: [0.10714995861053467], learning rate: 0.0098010000
Val loss  tensor(1.0430)
Val loss  tensor(1.2335)
Iteration 480000: total loss 0.0866, losses: [0.08658158034086227], learning rate: 0.0096059601
Iteration 480000: total loss 0.1080, losses: [0.10803680121898651], learning rate: 0.0097029900
Val loss  tensor(1.1407)
Val loss  tensor(1.3276)
Iteration 415000: total loss 0.0863, losses: [0.0862717479467392], learning rate: 0.0099000000
Iteration 415000: total loss 0.0931, losses: [0.09305459260940552], learning rate: 0.0098010000
Iteration 485000: total loss 0.1006, losses: [0.10056846588850021], learning rate: 0.0096059601
Iteration 485000: total loss 0.1170, losses: [0.11698700487613678], learning rate: 0.0097029900
Iteration 420000: total loss 0.1137, losses: [0.11374644935131073], learning rate: 0.0099000000
Iteration 420000: total loss 0.0986, losses: [0.09855091571807861], learning rate: 0.0098010000
Val loss  tensor(0.9915)
Val loss  tensor(1.2610)
Iteration 490000: total loss 0.0955, losses: [0.09549175202846527], learning rate: 0.0096059601
Iteration 490000: total loss 0.1048, losses: [0.1047566682100296], learning rate: 0.0097029900
Val loss  tensor(1.1343)
Val loss  tensor(1.4666)
Iteration 425000: total loss 0.0988, losses: [0.09883256256580353], learning rate: 0.0098010000
Iteration 425000: total loss 0.0857, losses: [0.08572156727313995], learning rate: 0.0099000000
Iteration 495000: total loss 0.0865, losses: [0.08654316514730453], learning rate: 0.0096059601
Iteration 495000: total loss 0.1055, losses: [0.10550566017627716], learning rate: 0.0097029900
Iteration 500000: total loss 0.0922, losses: [0.09224799275398254], learning rate: 0.0096059601
Iteration 500000: total loss 0.1380, losses: [0.13799692690372467], learning rate: 0.0097029900
Val loss  tensor(1.1270)
Val loss  tensor(1.4041)
Iteration 430000: total loss 0.1024, losses: [0.10237502306699753], learning rate: 0.0098010000
Iteration 430000: total loss 0.0845, losses: [0.08450955152511597], learning rate: 0.0099000000
Val loss  tensor(1.4067)
Val loss  tensor(0.9903)
Iteration 505000: total loss 0.0935, losses: [0.09352444112300873], learning rate: 0.0096059601
Iteration 505000: total loss 0.1067, losses: [0.10668642818927765], learning rate: 0.0097029900
Iteration 435000: total loss 0.1119, losses: [0.11189350485801697], learning rate: 0.0098010000
Iteration 435000: total loss 0.0840, losses: [0.08402229100465775], learning rate: 0.0099000000
Iteration 510000: total loss 0.1081, losses: [0.10807725787162781], learning rate: 0.0096059601
Iteration 510000: total loss 0.1113, losses: [0.11133093386888504], learning rate: 0.0097029900
Val loss  tensor(1.1398)
Val loss  tensor(1.3957)
Iteration 440000: total loss 0.0988, losses: [0.09882304072380066], learning rate: 0.0098010000
Iteration 440000: total loss 0.0940, losses: [0.09399393200874329], learning rate: 0.0099000000
Val loss  tensor(1.0710)
Val loss  tensor(1.3761)
Iteration 515000: total loss 0.1037, losses: [0.10370384156703949], learning rate: 0.0096059601
Iteration 515000: total loss 0.0889, losses: [0.08887235820293427], learning rate: 0.0097029900
Iteration 445000: total loss 0.0960, losses: [0.0960036963224411], learning rate: 0.0099000000
Iteration 445000: total loss 0.1043, losses: [0.10426858067512512], learning rate: 0.0098010000
Iteration 520000: total loss 0.0850, losses: [0.08501695841550827], learning rate: 0.0096059601
Iteration 520000: total loss 0.1198, losses: [0.11976532638072968], learning rate: 0.0097029900
Val loss  tensor(1.1478)
Val loss  tensor(1.4059)
Iteration 450000: total loss 0.1019, losses: [0.10185210406780243], learning rate: 0.0098010000
Iteration 450000: total loss 0.0987, losses: [0.09870128333568573], learning rate: 0.0099000000
Val loss  tensor(1.4172)
Val loss  tensor(1.0288)
Iteration 525000: total loss 0.0875, losses: [0.08748126775026321], learning rate: 0.0096059601
Iteration 525000: total loss 0.0997, losses: [0.09971435368061066], learning rate: 0.0097029900
Iteration 455000: total loss 0.0997, losses: [0.09966707974672318], learning rate: 0.0098010000
Iteration 455000: total loss 0.0865, losses: [0.08654311299324036], learning rate: 0.0099000000
Iteration 530000: total loss 0.0972, losses: [0.0971985012292862], learning rate: 0.0096059601
Iteration 530000: total loss 0.1219, losses: [0.12188149243593216], learning rate: 0.0097029900
Val loss  tensor(1.1504)
Val loss  tensor(1.3595)
Iteration 535000: total loss 0.0896, losses: [0.08962968736886978], learning rate: 0.0096059601
Iteration 535000: total loss 0.0972, losses: [0.09720011055469513], learning rate: 0.0097029900
Iteration 460000: total loss 0.1074, losses: [0.10742215812206268], learning rate: 0.0099000000
Iteration 460000: total loss 0.1000, losses: [0.10000702738761902], learning rate: 0.0098010000
Val loss  tensor(1.0106)
Val loss  tensor(1.3813)
Iteration 540000: total loss 0.1149, losses: [0.11494803428649902], learning rate: 0.0096059601
Iteration 540000: total loss 0.1134, losses: [0.11336913704872131], learning rate: 0.0097029900
Val loss  tensor(1.1758)
Val loss  tensor(1.3965)
Iteration 465000: total loss 0.0976, losses: [0.09758683294057846], learning rate: 0.0098010000
Iteration 465000: total loss 0.0920, losses: [0.09202097356319427], learning rate: 0.0099000000
Iteration 545000: total loss 0.0998, losses: [0.09975101798772812], learning rate: 0.0096059601
Iteration 545000: total loss 0.1164, losses: [0.11641490459442139], learning rate: 0.0097029900
Iteration 470000: total loss 0.0988, losses: [0.0987938940525055], learning rate: 0.0099000000
Iteration 470000: total loss 0.0872, losses: [0.08718404173851013], learning rate: 0.0098010000
Val loss  tensor(1.3499)
Val loss  tensor(1.0096)
Iteration 550000: total loss 0.0964, losses: [0.09644376486539841], learning rate: 0.0096059601
Iteration 550000: total loss 0.1155, losses: [0.11547661572694778], learning rate: 0.0097029900
Val loss  tensor(1.1527)
Val loss  tensor(1.4341)
Iteration 475000: total loss 0.0841, losses: [0.0840756744146347], learning rate: 0.0097029900
Iteration 475000: total loss 0.0976, losses: [0.09756546467542648], learning rate: 0.0099000000
Iteration 555000: total loss 0.1096, losses: [0.10956326127052307], learning rate: 0.0095099005
Iteration 555000: total loss 0.1251, losses: [0.1251056045293808], learning rate: 0.0097029900
Iteration 480000: total loss 0.0826, losses: [0.0825728327035904], learning rate: 0.0097029900
Iteration 480000: total loss 0.0954, losses: [0.09538531303405762], learning rate: 0.0099000000
Val loss  tensor(1.4336)
Val loss  tensor(1.0377)
Iteration 560000: total loss 0.0946, losses: [0.09462148696184158], learning rate: 0.0095099005
Iteration 560000: total loss 0.0755, losses: [0.07545864582061768], learning rate: 0.0097029900
Val loss  tensor(1.1445)
Val loss  tensor(1.4526)
Iteration 485000: total loss 0.0890, losses: [0.08904124796390533], learning rate: 0.0099000000
Iteration 485000: total loss 0.0940, losses: [0.0939965471625328], learning rate: 0.0097029900
Iteration 565000: total loss 0.1086, losses: [0.10863938182592392], learning rate: 0.0095099005
Iteration 565000: total loss 0.1071, losses: [0.10709279775619507], learning rate: 0.0097029900
Iteration 570000: total loss 0.0959, losses: [0.0959402322769165], learning rate: 0.0095099005
Iteration 570000: total loss 0.0989, losses: [0.09885216504335403], learning rate: 0.0097029900
Iteration 490000: total loss 0.1028, losses: [0.10282096266746521], learning rate: 0.0099000000
Iteration 490000: total loss 0.0863, losses: [0.0862945020198822], learning rate: 0.0097029900
Val loss  tensor(1.1448)
Val loss  tensor(1.3363)
Val loss  tensor(0.9913)
Val loss  tensor(1.4543)
Iteration 575000: total loss 0.0999, losses: [0.0999288409948349], learning rate: 0.0095099005
Iteration 575000: total loss 0.1045, losses: [0.1045060008764267], learning rate: 0.0096059601
Iteration 495000: total loss 0.0903, losses: [0.09026378393173218], learning rate: 0.0099000000
Iteration 495000: total loss 0.1109, losses: [0.1108836978673935], learning rate: 0.0097029900
Iteration 580000: total loss 0.1025, losses: [0.10247137397527695], learning rate: 0.0095099005
Iteration 580000: total loss 0.1073, losses: [0.10733552277088165], learning rate: 0.0096059601
Val loss  tensor(1.1547)
Val loss  tensor(1.4085)
Iteration 500000: total loss 0.0993, losses: [0.0993255227804184], learning rate: 0.0099000000
Iteration 500000: total loss 0.0933, losses: [0.09328565746545792], learning rate: 0.0097029900
Val loss  tensor(1.0497)
Val loss  tensor(1.4510)
Iteration 585000: total loss 0.1183, losses: [0.11833435297012329], learning rate: 0.0095099005
Iteration 585000: total loss 0.0885, losses: [0.08845130354166031], learning rate: 0.0096059601
Iteration 505000: total loss 0.0955, losses: [0.09545521438121796], learning rate: 0.0099000000
Iteration 505000: total loss 0.0926, losses: [0.09264817833900452], learning rate: 0.0097029900
Iteration 590000: total loss 0.0771, losses: [0.07709662616252899], learning rate: 0.0095099005
Iteration 590000: total loss 0.0919, losses: [0.09188060462474823], learning rate: 0.0096059601
Val loss  tensor(1.1322)
Val loss  tensor(1.4156)
Iteration 510000: total loss 0.0938, losses: [0.09382052719593048], learning rate: 0.0099000000
Iteration 510000: total loss 0.0916, losses: [0.09156595170497894], learning rate: 0.0097029900
Val loss  tensor(1.4100)
Val loss  tensor(1.0963)
Iteration 595000: total loss 0.0777, losses: [0.07767283916473389], learning rate: 0.0095099005
Iteration 595000: total loss 0.1251, losses: [0.12505203485488892], learning rate: 0.0096059601
Iteration 515000: total loss 0.0954, losses: [0.09536194801330566], learning rate: 0.0097029900
Iteration 515000: total loss 0.0998, losses: [0.09979218244552612], learning rate: 0.0099000000
Iteration 600000: total loss 0.0819, losses: [0.0819365531206131], learning rate: 0.0095099005
Iteration 600000: total loss 0.1035, losses: [0.10348868370056152], learning rate: 0.0096059601
Val loss  tensor(1.1422)
Val loss  tensor(1.3761)
Iteration 520000: total loss 0.0873, losses: [0.08728843927383423], learning rate: 0.0097029900
Iteration 520000: total loss 0.0939, losses: [0.09387622773647308], learning rate: 0.0099000000
Iteration 605000: total loss 0.0946, losses: [0.09456686675548553], learning rate: 0.0095099005
Iteration 605000: total loss 0.1238, losses: [0.12381820380687714], learning rate: 0.0096059601
Val loss  tensor(1.4983)
Val loss  tensor(1.0647)
Iteration 610000: total loss 0.0929, losses: [0.09285750985145569], learning rate: 0.0095099005
Iteration 610000: total loss 0.0991, losses: [0.09912417829036713], learning rate: 0.0096059601
Val loss  tensor(1.1413)
Val loss  tensor(1.4207)
Iteration 525000: total loss 0.1136, losses: [0.11363352835178375], learning rate: 0.0097029900
Iteration 525000: total loss 0.0945, losses: [0.09454821795225143], learning rate: 0.0099000000
Iteration 615000: total loss 0.0964, losses: [0.09636645019054413], learning rate: 0.0095099005
Iteration 615000: total loss 0.1085, losses: [0.10847814381122589], learning rate: 0.0096059601
Iteration 530000: total loss 0.0910, losses: [0.09104593098163605], learning rate: 0.0099000000
Iteration 530000: total loss 0.1006, losses: [0.10056646168231964], learning rate: 0.0097029900
Val loss  tensor(1.4709)
Val loss  tensor(1.0216)
Iteration 620000: total loss 0.0813, losses: [0.08125149458646774], learning rate: 0.0095099005
Iteration 620000: total loss 0.1081, losses: [0.10814335197210312], learning rate: 0.0096059601
Val loss  tensor(1.1395)
Val loss  tensor(1.3596)
Iteration 535000: total loss 0.0933, losses: [0.09325506538152695], learning rate: 0.0099000000
Iteration 535000: total loss 0.1000, losses: [0.10003329813480377], learning rate: 0.0097029900
Iteration 625000: total loss 0.1053, losses: [0.10526806116104126], learning rate: 0.0096059601
Iteration 625000: total loss 0.0995, losses: [0.09949596226215363], learning rate: 0.0095099005
Iteration 540000: total loss 0.1011, losses: [0.10114532709121704], learning rate: 0.0099000000
Iteration 540000: total loss 0.0868, losses: [0.08676396310329437], learning rate: 0.0097029900
Val loss  tensor(1.0056)
Val loss  tensor(1.4502)
Iteration 630000: total loss 0.0846, losses: [0.08461792767047882], learning rate: 0.0095099005
Iteration 630000: total loss 0.1132, losses: [0.11324937641620636], learning rate: 0.0096059601
Val loss  tensor(1.1523)
Val loss  tensor(1.4580)
Iteration 545000: total loss 0.0803, losses: [0.08028938621282578], learning rate: 0.0098010000
Iteration 545000: total loss 0.1032, losses: [0.1032370775938034], learning rate: 0.0097029900
Iteration 635000: total loss 0.0841, losses: [0.08413344621658325], learning rate: 0.0095099005
Iteration 635000: total loss 0.0977, losses: [0.0977117046713829], learning rate: 0.0096059601
Iteration 550000: total loss 0.1038, losses: [0.10375311970710754], learning rate: 0.0098010000
Iteration 550000: total loss 0.0903, losses: [0.09032388031482697], learning rate: 0.0097029900
Iteration 640000: total loss 0.1102, losses: [0.11016464233398438], learning rate: 0.0095099005
Iteration 640000: total loss 0.1066, losses: [0.10664474964141846], learning rate: 0.0096059601
Val loss  tensor(1.0279)
Val loss  tensor(1.4109)
Val loss  tensor(1.1544)
Val loss  tensor(1.3142)
Iteration 645000: total loss 0.0947, losses: [0.09474779665470123], learning rate: 0.0095099005
Iteration 645000: total loss 0.0930, losses: [0.09300433099269867], learning rate: 0.0096059601
Iteration 555000: total loss 0.1098, losses: [0.10981068015098572], learning rate: 0.0097029900
Iteration 555000: total loss 0.1109, losses: [0.11085204780101776], learning rate: 0.0098010000
Iteration 650000: total loss 0.0924, losses: [0.09238090366125107], learning rate: 0.0095099005
Iteration 650000: total loss 0.1109, losses: [0.11089720577001572], learning rate: 0.0096059601
Val loss  tensor(1.1476)
Val loss  tensor(1.3265)
Iteration 560000: total loss 0.0961, losses: [0.09613543748855591], learning rate: 0.0097029900
Iteration 560000: total loss 0.0905, losses: [0.09048640727996826], learning rate: 0.0098010000
Val loss  tensor(1.5014)
Val loss  tensor(0.9493)
Iteration 655000: total loss 0.1054, losses: [0.10542194545269012], learning rate: 0.0095099005
Iteration 655000: total loss 0.0828, losses: [0.08278115838766098], learning rate: 0.0096059601
Iteration 565000: total loss 0.0938, losses: [0.09381841123104095], learning rate: 0.0097029900
Iteration 565000: total loss 0.0790, losses: [0.07898689061403275], learning rate: 0.0098010000
Iteration 660000: total loss 0.1073, losses: [0.10727080702781677], learning rate: 0.0095099005
Iteration 660000: total loss 0.0998, losses: [0.09984178841114044], learning rate: 0.0096059601
Val loss  tensor(1.1463)
Val loss  tensor(1.3128)
Iteration 570000: total loss 0.0929, losses: [0.09290565550327301], learning rate: 0.0097029900
Iteration 570000: total loss 0.0890, losses: [0.08901936560869217], learning rate: 0.0098010000
Val loss  tensor(1.5110)
Val loss  tensor(1.0236)
Iteration 665000: total loss 0.1127, losses: [0.11271736025810242], learning rate: 0.0094148015
Iteration 665000: total loss 0.0952, losses: [0.09516693651676178], learning rate: 0.0096059601
Iteration 575000: total loss 0.0938, losses: [0.09379743039608002], learning rate: 0.0097029900
Iteration 575000: total loss 0.0946, losses: [0.09460194408893585], learning rate: 0.0098010000
Iteration 670000: total loss 0.0896, losses: [0.08956389129161835], learning rate: 0.0094148015
Iteration 670000: total loss 0.0937, losses: [0.09370462596416473], learning rate: 0.0096059601
Val loss  tensor(1.1363)
Val loss  tensor(1.3230)
Iteration 580000: total loss 0.0950, losses: [0.09501197934150696], learning rate: 0.0097029900
Iteration 580000: total loss 0.0868, losses: [0.08683662116527557], learning rate: 0.0098010000
Val loss  tensor(1.3622)
Val loss  tensor(0.9971)
Iteration 675000: total loss 0.1066, losses: [0.10659204423427582], learning rate: 0.0094148015
Iteration 675000: total loss 0.1097, losses: [0.1096922904253006], learning rate: 0.0096059601
Iteration 680000: total loss 0.0810, losses: [0.08097915351390839], learning rate: 0.0094148015
Iteration 680000: total loss 0.1053, losses: [0.10529621690511703], learning rate: 0.0096059601
Val loss  tensor(1.2789)
Val loss  tensor(1.1423)
Iteration 585000: total loss 0.0973, losses: [0.09731288254261017], learning rate: 0.0096059601
Iteration 585000: total loss 0.0865, losses: [0.08651657402515411], learning rate: 0.0098010000
Iteration 685000: total loss 0.0864, losses: [0.08635656535625458], learning rate: 0.0094148015
Iteration 685000: total loss 0.1107, losses: [0.11067134141921997], learning rate: 0.0095099005
Iteration 590000: total loss 0.0859, losses: [0.08593030273914337], learning rate: 0.0096059601
Iteration 590000: total loss 0.0879, losses: [0.08794005215167999], learning rate: 0.0098010000
Val loss  tensor(1.4365)
Val loss  tensor(1.0709)
Iteration 690000: total loss 0.0985, losses: [0.09854508936405182], learning rate: 0.0094148015
Iteration 690000: total loss 0.0930, losses: [0.09299838542938232], learning rate: 0.0095099005
Val loss  tensor(1.1353)
Val loss  tensor(1.3290)
Iteration 595000: total loss 0.0860, losses: [0.08604264259338379], learning rate: 0.0098010000
Iteration 595000: total loss 0.0937, losses: [0.0936577245593071], learning rate: 0.0096059601
Iteration 695000: total loss 0.1104, losses: [0.11044187843799591], learning rate: 0.0095099005
Iteration 695000: total loss 0.0934, losses: [0.09336084127426147], learning rate: 0.0094148015
Iteration 600000: total loss 0.0975, losses: [0.09754832088947296], learning rate: 0.0096059601
Iteration 600000: total loss 0.1078, losses: [0.10779860615730286], learning rate: 0.0098010000
Val loss  tensor(1.0175)
Val loss  tensor(1.4529)
Iteration 700000: total loss 0.0838, losses: [0.0838034525513649], learning rate: 0.0094148015
Iteration 700000: total loss 0.1108, losses: [0.11081182956695557], learning rate: 0.0095099005
Val loss  tensor(1.1324)
Val loss  tensor(1.2972)
Iteration 605000: total loss 0.0933, losses: [0.09328269958496094], learning rate: 0.0096059601
Iteration 605000: total loss 0.0864, losses: [0.08644653856754303], learning rate: 0.0098010000
Iteration 705000: total loss 0.1078, losses: [0.10779553651809692], learning rate: 0.0095099005
Iteration 705000: total loss 0.0911, losses: [0.09109994769096375], learning rate: 0.0094148015
Iteration 610000: total loss 0.0863, losses: [0.08634550869464874], learning rate: 0.0096059601
Iteration 610000: total loss 0.0959, losses: [0.0958787053823471], learning rate: 0.0098010000
Iteration 710000: total loss 0.0971, losses: [0.0971459299325943], learning rate: 0.0094148015
Iteration 710000: total loss 0.1137, losses: [0.11370411515235901], learning rate: 0.0095099005
Val loss  tensor(1.3625)
Val loss  tensor(1.0433)
Val loss  tensor(1.1474)
Val loss  tensor(1.3528)
Iteration 715000: total loss 0.0826, losses: [0.08261145651340485], learning rate: 0.0094148015
Iteration 715000: total loss 0.0992, losses: [0.09920573234558105], learning rate: 0.0095099005
Iteration 615000: total loss 0.1002, losses: [0.1001882255077362], learning rate: 0.0096059601
Iteration 615000: total loss 0.0842, losses: [0.08420237898826599], learning rate: 0.0098010000
Iteration 720000: total loss 0.0894, losses: [0.08943354338407516], learning rate: 0.0094148015
Iteration 720000: total loss 0.1065, losses: [0.10653641819953918], learning rate: 0.0095099005
Val loss  tensor(1.1495)
Val loss  tensor(1.2581)
Iteration 620000: total loss 0.0789, losses: [0.0788654237985611], learning rate: 0.0096059601
Iteration 620000: total loss 0.1127, losses: [0.11274074763059616], learning rate: 0.0098010000
Val loss  tensor(1.4270)
Val loss  tensor(1.0150)
Iteration 725000: total loss 0.1034, losses: [0.10338763147592545], learning rate: 0.0094148015
Iteration 725000: total loss 0.0941, losses: [0.0940973311662674], learning rate: 0.0095099005
Iteration 625000: total loss 0.1038, losses: [0.10379201918840408], learning rate: 0.0096059601
Iteration 625000: total loss 0.0909, losses: [0.09087547659873962], learning rate: 0.0098010000
Iteration 730000: total loss 0.0936, losses: [0.09360016882419586], learning rate: 0.0094148015
Iteration 730000: total loss 0.0973, losses: [0.09725994616746902], learning rate: 0.0095099005
Val loss  tensor(1.1529)
Val loss  tensor(1.3842)
Iteration 630000: total loss 0.0971, losses: [0.09713257104158401], learning rate: 0.0096059601
Iteration 630000: total loss 0.0874, losses: [0.08740032464265823], learning rate: 0.0098010000
Val loss  tensor(1.4038)
Val loss  tensor(0.9743)
Iteration 735000: total loss 0.0742, losses: [0.074197918176651], learning rate: 0.0094148015
Iteration 735000: total loss 0.1116, losses: [0.11159896850585938], learning rate: 0.0095099005
Iteration 635000: total loss 0.0819, losses: [0.08189807087182999], learning rate: 0.0098010000
Iteration 635000: total loss 0.0936, losses: [0.09361615031957626], learning rate: 0.0096059601
Iteration 740000: total loss 0.0991, losses: [0.09907402098178864], learning rate: 0.0094148015
Iteration 740000: total loss 0.1080, losses: [0.10798376798629761], learning rate: 0.0095099005
Val loss  tensor(1.4222)
Val loss  tensor(1.1576)
Iteration 640000: total loss 0.0837, losses: [0.08374408632516861], learning rate: 0.0098010000
Iteration 640000: total loss 0.1063, losses: [0.10634402930736542], learning rate: 0.0096059601
Val loss  tensor(0.9236)
Val loss  tensor(1.3620)
Iteration 745000: total loss 0.1047, losses: [0.10468244552612305], learning rate: 0.0094148015
Iteration 745000: total loss 0.1171, losses: [0.11712054908275604], learning rate: 0.0095099005
Iteration 750000: total loss 0.0978, losses: [0.09776119142770767], learning rate: 0.0095099005
Iteration 750000: total loss 0.1020, losses: [0.10203616321086884], learning rate: 0.0094148015
Val loss  tensor(1.1439)
Val loss  tensor(1.4042)
Iteration 645000: total loss 0.1044, losses: [0.1044391617178917], learning rate: 0.0096059601
Iteration 645000: total loss 0.0949, losses: [0.09488384425640106], learning rate: 0.0098010000
Iteration 755000: total loss 0.1171, losses: [0.1170894056558609], learning rate: 0.0095099005
Iteration 755000: total loss 0.0751, losses: [0.07505491375923157], learning rate: 0.0094148015
Iteration 650000: total loss 0.0947, losses: [0.09469123184680939], learning rate: 0.0096059601
Iteration 650000: total loss 0.0991, losses: [0.09907063096761703], learning rate: 0.0098010000
Val loss  tensor(1.4016)
Val loss  tensor(1.0382)
Iteration 760000: total loss 0.1028, losses: [0.1027875691652298], learning rate: 0.0094148015
Iteration 760000: total loss 0.1016, losses: [0.10157175362110138], learning rate: 0.0095099005
Val loss  tensor(1.1558)
Val loss  tensor(1.4115)
Iteration 655000: total loss 0.0890, losses: [0.08904863148927689], learning rate: 0.0096059601
Iteration 655000: total loss 0.1012, losses: [0.10117896646261215], learning rate: 0.0098010000
Iteration 765000: total loss 0.0871, losses: [0.08707831799983978], learning rate: 0.0094148015
Iteration 765000: total loss 0.0943, losses: [0.09428831934928894], learning rate: 0.0095099005
Iteration 660000: total loss 0.0900, losses: [0.08996012806892395], learning rate: 0.0098010000
Iteration 660000: total loss 0.0937, losses: [0.09369757771492004], learning rate: 0.0096059601
Val loss  tensor(1.4073)
Val loss  tensor(1.0019)
Iteration 770000: total loss 0.0991, losses: [0.09910658001899719], learning rate: 0.0094148015
Iteration 770000: total loss 0.1002, losses: [0.10022792220115662], learning rate: 0.0095099005
Val loss  tensor(1.1624)
Val loss  tensor(1.3907)
Iteration 665000: total loss 0.0976, losses: [0.09755154699087143], learning rate: 0.0096059601
Iteration 665000: total loss 0.0956, losses: [0.09556221216917038], learning rate: 0.0098010000
Iteration 775000: total loss 0.1050, losses: [0.10503672808408737], learning rate: 0.0095099005
Iteration 775000: total loss 0.1080, losses: [0.10803835093975067], learning rate: 0.0093206535
Iteration 670000: total loss 0.0950, losses: [0.09504091739654541], learning rate: 0.0096059601
Iteration 670000: total loss 0.0813, losses: [0.08128722012042999], learning rate: 0.0098010000
Val loss  tensor(1.3704)
Val loss  tensor(1.0594)
Iteration 780000: total loss 0.1045, losses: [0.104508176445961], learning rate: 0.0093206535
Iteration 780000: total loss 0.0978, losses: [0.09775662422180176], learning rate: 0.0095099005
Val loss  tensor(1.1482)
Val loss  tensor(1.3836)
Iteration 785000: total loss 0.0924, losses: [0.09237565100193024], learning rate: 0.0095099005
Iteration 785000: total loss 0.0869, losses: [0.08693821728229523], learning rate: 0.0093206535
Iteration 675000: total loss 0.0862, losses: [0.08617940545082092], learning rate: 0.0098010000
Iteration 675000: total loss 0.0866, losses: [0.0865805596113205], learning rate: 0.0096059601
Iteration 790000: total loss 0.0865, losses: [0.08653907477855682], learning rate: 0.0095099005
Iteration 790000: total loss 0.1129, losses: [0.1128869503736496], learning rate: 0.0093206535
Val loss  tensor(1.3517)
Val loss  tensor(1.1308)
Iteration 680000: total loss 0.0863, losses: [0.08627912402153015], learning rate: 0.0096059601
Iteration 680000: total loss 0.0893, losses: [0.08926394581794739], learning rate: 0.0098010000
Val loss  tensor(1.4033)
Val loss  tensor(1.1055)
Iteration 795000: total loss 0.1005, losses: [0.10054248571395874], learning rate: 0.0094148015
Iteration 795000: total loss 0.1009, losses: [0.10087960213422775], learning rate: 0.0093206535
Iteration 685000: total loss 0.1097, losses: [0.10966901481151581], learning rate: 0.0098010000
Iteration 685000: total loss 0.1004, losses: [0.10038988292217255], learning rate: 0.0096059601
Iteration 800000: total loss 0.0831, losses: [0.08308931440114975], learning rate: 0.0093206535
Iteration 800000: total loss 0.0879, losses: [0.08790430426597595], learning rate: 0.0094148015
Val loss  tensor(1.3817)
Val loss  tensor(1.1424)
Iteration 690000: total loss 0.0994, losses: [0.09936676174402237], learning rate: 0.0098010000
Iteration 690000: total loss 0.0977, losses: [0.09769417345523834], learning rate: 0.0096059601
Val loss  tensor(1.0008)
Val loss  tensor(1.4133)
Iteration 805000: total loss 0.0899, losses: [0.0898536667227745], learning rate: 0.0093206535
Iteration 805000: total loss 0.1040, losses: [0.10402055829763412], learning rate: 0.0094148015
Iteration 695000: total loss 0.0913, losses: [0.0913057029247284], learning rate: 0.0095099005
Iteration 695000: total loss 0.0896, losses: [0.08958945423364639], learning rate: 0.0098010000
Iteration 810000: total loss 0.0930, losses: [0.0930112674832344], learning rate: 0.0093206535
Iteration 810000: total loss 0.0993, losses: [0.09925980865955353], learning rate: 0.0094148015
Val loss  tensor(1.1366)
Val loss  tensor(1.4077)
Iteration 700000: total loss 0.0908, losses: [0.09075434505939484], learning rate: 0.0098010000
Iteration 700000: total loss 0.1027, losses: [0.10273154079914093], learning rate: 0.0095099005
Val loss  tensor(1.3471)
Val loss  tensor(0.9992)
Iteration 815000: total loss 0.0947, losses: [0.0947425365447998], learning rate: 0.0093206535
Iteration 815000: total loss 0.0948, losses: [0.09475447237491608], learning rate: 0.0094148015
Iteration 820000: total loss 0.0805, losses: [0.08045296370983124], learning rate: 0.0093206535
Iteration 820000: total loss 0.0965, losses: [0.0965355783700943], learning rate: 0.0094148015
Val loss  tensor(1.1445)
Val loss  tensor(1.3556)
Iteration 705000: total loss 0.0939, losses: [0.09389689564704895], learning rate: 0.0098010000
Iteration 705000: total loss 0.0917, losses: [0.09168655425310135], learning rate: 0.0095099005
Iteration 825000: total loss 0.0973, losses: [0.09732580184936523], learning rate: 0.0093206535
Iteration 825000: total loss 0.1143, losses: [0.11426200717687607], learning rate: 0.0094148015
Iteration 710000: total loss 0.0821, losses: [0.0820547491312027], learning rate: 0.0098010000
Iteration 710000: total loss 0.0819, losses: [0.08185864984989166], learning rate: 0.0095099005
Val loss  tensor(1.4133)
Val loss  tensor(1.0236)
Iteration 830000: total loss 0.0922, losses: [0.09222713112831116], learning rate: 0.0093206535
Iteration 830000: total loss 0.0845, losses: [0.08447614312171936], learning rate: 0.0094148015
Val loss  tensor(1.1444)
Val loss  tensor(1.4330)
Iteration 715000: total loss 0.0904, losses: [0.0904386043548584], learning rate: 0.0098010000
Iteration 715000: total loss 0.0929, losses: [0.09293892979621887], learning rate: 0.0095099005
Iteration 835000: total loss 0.1450, losses: [0.1449775993824005], learning rate: 0.0093206535
Iteration 835000: total loss 0.0962, losses: [0.09619957953691483], learning rate: 0.0094148015
Iteration 720000: total loss 0.0887, losses: [0.08870051801204681], learning rate: 0.0098010000
Iteration 720000: total loss 0.0878, losses: [0.08779890090227127], learning rate: 0.0095099005
Val loss  tensor(1.4273)
Val loss  tensor(1.0121)
Iteration 840000: total loss 0.0897, losses: [0.0896632969379425], learning rate: 0.0093206535
Iteration 840000: total loss 0.1026, losses: [0.10263771563768387], learning rate: 0.0094148015
Val loss  tensor(1.1468)
Val loss  tensor(1.4394)
Iteration 725000: total loss 0.0689, losses: [0.06885318458080292], learning rate: 0.0095099005
Iteration 725000: total loss 0.0975, losses: [0.0974913090467453], learning rate: 0.0098010000
Iteration 845000: total loss 0.1023, losses: [0.10228924453258514], learning rate: 0.0094148015
Iteration 845000: total loss 0.1018, losses: [0.10177266597747803], learning rate: 0.0093206535
Iteration 730000: total loss 0.0868, losses: [0.08675067871809006], learning rate: 0.0095099005
Iteration 730000: total loss 0.0870, losses: [0.08701454102993011], learning rate: 0.0098010000
Val loss  tensor(1.5708)
Val loss  tensor(0.9742)
Iteration 850000: total loss 0.0744, losses: [0.07441180944442749], learning rate: 0.0093206535
Iteration 850000: total loss 0.1087, losses: [0.10872051864862442], learning rate: 0.0094148015
Val loss  tensor(1.3375)
Val loss  tensor(1.1455)
Iteration 735000: total loss 0.0954, losses: [0.09540817886590958], learning rate: 0.0095099005
Iteration 735000: total loss 0.0964, losses: [0.09638257324695587], learning rate: 0.0098010000
Iteration 855000: total loss 0.0987, losses: [0.09870947897434235], learning rate: 0.0093206535
Iteration 855000: total loss 0.0966, losses: [0.09655700623989105], learning rate: 0.0094148015
Iteration 860000: total loss 0.1382, losses: [0.138185054063797], learning rate: 0.0094148015
Iteration 860000: total loss 0.0850, losses: [0.08500971645116806], learning rate: 0.0093206535
Val loss  tensor(1.1438)
Val loss  tensor(1.3473)
Iteration 740000: total loss 0.0916, losses: [0.09156177937984467], learning rate: 0.0095099005
Iteration 740000: total loss 0.0936, losses: [0.09363609552383423], learning rate: 0.0098010000
Val loss  tensor(1.0734)
Val loss  tensor(1.3836)
Iteration 865000: total loss 0.1082, losses: [0.10823994874954224], learning rate: 0.0093206535
Iteration 865000: total loss 0.1071, losses: [0.10712428390979767], learning rate: 0.0094148015
Iteration 745000: total loss 0.0893, losses: [0.08932234346866608], learning rate: 0.0095099005
Iteration 745000: total loss 0.0900, losses: [0.08999130129814148], learning rate: 0.0098010000
Iteration 870000: total loss 0.1105, losses: [0.11054922640323639], learning rate: 0.0094148015
Iteration 870000: total loss 0.0866, losses: [0.08664979040622711], learning rate: 0.0093206535
Val loss  tensor(1.3930)
Val loss  tensor(1.1391)
Iteration 750000: total loss 0.0941, losses: [0.09407299757003784], learning rate: 0.0095099005
Iteration 750000: total loss 0.0780, losses: [0.07803080230951309], learning rate: 0.0098010000
Val loss  tensor(1.3405)
Val loss  tensor(0.9540)
Iteration 875000: total loss 0.1094, losses: [0.10936757922172546], learning rate: 0.0093206535
Iteration 875000: total loss 0.1002, losses: [0.10016395151615143], learning rate: 0.0094148015
Iteration 755000: total loss 0.0862, losses: [0.08615262806415558], learning rate: 0.0095099005
Iteration 755000: total loss 0.1004, losses: [0.10043559223413467], learning rate: 0.0097029900
Iteration 880000: total loss 0.1048, losses: [0.10480443388223648], learning rate: 0.0093206535
Iteration 880000: total loss 0.0954, losses: [0.09537691622972488], learning rate: 0.0094148015
Val loss  tensor(1.1433)
Val loss  tensor(1.4052)
Iteration 760000: total loss 0.0740, losses: [0.07398991286754608], learning rate: 0.0095099005
Iteration 760000: total loss 0.1048, losses: [0.10475119948387146], learning rate: 0.0097029900
Val loss  tensor(1.3770)
Val loss  tensor(0.9832)
Iteration 885000: total loss 0.1124, losses: [0.11237066984176636], learning rate: 0.0094148015
Iteration 885000: total loss 0.0839, losses: [0.08387486636638641], learning rate: 0.0092274469
Iteration 765000: total loss 0.0862, losses: [0.08620898425579071], learning rate: 0.0095099005
Iteration 765000: total loss 0.1086, losses: [0.10857240110635757], learning rate: 0.0097029900
Iteration 890000: total loss 0.0809, losses: [0.0808895155787468], learning rate: 0.0094148015
Iteration 890000: total loss 0.0810, losses: [0.08100248128175735], learning rate: 0.0092274469
Val loss  tensor(1.1496)
Val loss  tensor(1.4123)
Iteration 895000: total loss 0.0931, losses: [0.09307820349931717], learning rate: 0.0092274469
Iteration 895000: total loss 0.1152, losses: [0.11520123481750488], learning rate: 0.0094148015
Iteration 770000: total loss 0.0833, losses: [0.08326654136180878], learning rate: 0.0095099005
Iteration 770000: total loss 0.1000, losses: [0.10002236068248749], learning rate: 0.0097029900
Val loss  tensor(1.4584)
Val loss  tensor(0.9566)
Iteration 900000: total loss 0.1090, losses: [0.10904769599437714], learning rate: 0.0092274469
Iteration 900000: total loss 0.0980, losses: [0.0980379581451416], learning rate: 0.0094148015
Val loss  tensor(1.1609)
Val loss  tensor(1.4065)
Iteration 775000: total loss 0.0583, losses: [0.05825724080204964], learning rate: 0.0095099005
Iteration 775000: total loss 0.0945, losses: [0.09450986236333847], learning rate: 0.0097029900
Iteration 905000: total loss 0.0715, losses: [0.07148730754852295], learning rate: 0.0092274469
Iteration 905000: total loss 0.1125, losses: [0.11248328536748886], learning rate: 0.0093206535
Iteration 780000: total loss 0.0822, losses: [0.08220312744379044], learning rate: 0.0095099005
Iteration 780000: total loss 0.0846, losses: [0.08457355201244354], learning rate: 0.0097029900
Val loss  tensor(1.4732)
Val loss  tensor(1.0273)
Iteration 910000: total loss 0.0833, losses: [0.08326775580644608], learning rate: 0.0093206535
Iteration 910000: total loss 0.1001, losses: [0.10011707991361618], learning rate: 0.0092274469
Val loss  tensor(1.1412)
Val loss  tensor(1.3321)
Iteration 785000: total loss 0.0946, losses: [0.09464658051729202], learning rate: 0.0097029900
Iteration 785000: total loss 0.0894, losses: [0.08942557126283646], learning rate: 0.0095099005
Iteration 915000: total loss 0.0891, losses: [0.08911862969398499], learning rate: 0.0093206535
Iteration 915000: total loss 0.0713, losses: [0.07125838100910187], learning rate: 0.0092274469
Iteration 790000: total loss 0.0681, losses: [0.06805745512247086], learning rate: 0.0097029900
Iteration 790000: total loss 0.0694, losses: [0.06937424838542938], learning rate: 0.0095099005
Val loss  tensor(0.9269)
Val loss  tensor(1.3408)
Iteration 920000: total loss 0.0970, losses: [0.09699119627475739], learning rate: 0.0092274469
Iteration 920000: total loss 0.1139, losses: [0.11385113000869751], learning rate: 0.0093206535
Val loss  tensor(1.4205)
Val loss  tensor(1.1407)
Iteration 795000: total loss 0.0849, losses: [0.0849253237247467], learning rate: 0.0095099005
Iteration 795000: total loss 0.0875, losses: [0.08746540546417236], learning rate: 0.0097029900
Iteration 925000: total loss 0.1000, losses: [0.10000554472208023], learning rate: 0.0093206535
Iteration 925000: total loss 0.0700, losses: [0.06998392939567566], learning rate: 0.0092274469
Iteration 930000: total loss 0.0786, losses: [0.07857784628868103], learning rate: 0.0093206535
Iteration 930000: total loss 0.0839, losses: [0.08388892561197281], learning rate: 0.0092274469
Val loss  tensor(1.1530)
Val loss  tensor(1.3662)
Iteration 800000: total loss 0.0811, losses: [0.08114798367023468], learning rate: 0.0095099005
Iteration 800000: total loss 0.0988, losses: [0.09879035502672195], learning rate: 0.0097029900
Val loss  tensor(1.4344)
Val loss  tensor(0.9241)
Iteration 935000: total loss 0.1034, losses: [0.10335494577884674], learning rate: 0.0092274469
Iteration 935000: total loss 0.1183, losses: [0.11825469136238098], learning rate: 0.0093206535
Iteration 805000: total loss 0.0831, losses: [0.08309768885374069], learning rate: 0.0094148015
Iteration 805000: total loss 0.0872, losses: [0.08723537623882294], learning rate: 0.0097029900
Iteration 940000: total loss 0.0863, losses: [0.08628492057323456], learning rate: 0.0092274469
Iteration 940000: total loss 0.0965, losses: [0.0964905172586441], learning rate: 0.0093206535
Val loss  tensor(1.1551)
Val loss  tensor(1.4405)
Iteration 810000: total loss 0.0914, losses: [0.09139004349708557], learning rate: 0.0094148015
Iteration 810000: total loss 0.0999, losses: [0.09994058310985565], learning rate: 0.0097029900
Val loss  tensor(1.5641)
Val loss  tensor(1.0110)
Iteration 945000: total loss 0.0855, losses: [0.08548278361558914], learning rate: 0.0092274469
Iteration 945000: total loss 0.0974, losses: [0.09742266684770584], learning rate: 0.0093206535
Iteration 815000: total loss 0.0747, losses: [0.07473768293857574], learning rate: 0.0094148015
Iteration 815000: total loss 0.0936, losses: [0.09360004961490631], learning rate: 0.0097029900
Iteration 950000: total loss 0.0861, losses: [0.08613483607769012], learning rate: 0.0092274469
Iteration 950000: total loss 0.0848, losses: [0.08476849645376205], learning rate: 0.0093206535
Val loss  tensor(1.1544)
Val loss  tensor(1.4373)
Iteration 820000: total loss 0.0945, losses: [0.09448598325252533], learning rate: 0.0094148015
Iteration 820000: total loss 0.0800, losses: [0.08003942668437958], learning rate: 0.0097029900
Val loss  tensor(1.4909)
Val loss  tensor(0.8911)
Iteration 955000: total loss 0.0905, losses: [0.09046398103237152], learning rate: 0.0093206535
Iteration 955000: total loss 0.0913, losses: [0.09131064265966415], learning rate: 0.0092274469
Iteration 825000: total loss 0.1085, losses: [0.10854219645261765], learning rate: 0.0094148015
Iteration 825000: total loss 0.0930, losses: [0.0929872989654541], learning rate: 0.0097029900
Iteration 960000: total loss 0.0934, losses: [0.0933849960565567], learning rate: 0.0093206535
Iteration 960000: total loss 0.1024, losses: [0.10235951095819473], learning rate: 0.0092274469
Val loss  tensor(1.1536)
Val loss  tensor(1.4211)
Iteration 965000: total loss 0.0952, losses: [0.0952262356877327], learning rate: 0.0093206535
Iteration 965000: total loss 0.0959, losses: [0.09585370123386383], learning rate: 0.0092274469
Iteration 830000: total loss 0.0763, losses: [0.07626082748174667], learning rate: 0.0094148015
Iteration 830000: total loss 0.1058, losses: [0.10583939403295517], learning rate: 0.0097029900
Val loss  tensor(1.4384)
Val loss  tensor(1.0163)
Iteration 970000: total loss 0.0959, losses: [0.09589093923568726], learning rate: 0.0093206535
Iteration 970000: total loss 0.0919, losses: [0.09187515079975128], learning rate: 0.0092274469
Val loss  tensor(1.4272)
Val loss  tensor(1.1592)
Iteration 835000: total loss 0.0739, losses: [0.07392597943544388], learning rate: 0.0094148015
Iteration 835000: total loss 0.0927, losses: [0.09265662729740143], learning rate: 0.0097029900
Iteration 975000: total loss 0.0898, losses: [0.08983709663152695], learning rate: 0.0093206535
Iteration 975000: total loss 0.0863, losses: [0.08633950352668762], learning rate: 0.0092274469
Iteration 840000: total loss 0.0966, losses: [0.09661833941936493], learning rate: 0.0094148015
Iteration 840000: total loss 0.0893, losses: [0.08931311964988708], learning rate: 0.0097029900
Val loss  tensor(1.3705)
Val loss  tensor(0.9876)
Iteration 980000: total loss 0.1025, losses: [0.10245318710803986], learning rate: 0.0093206535
Iteration 980000: total loss 0.1433, losses: [0.1432766318321228], learning rate: 0.0092274469
Val loss  tensor(1.3577)
Val loss  tensor(1.1545)
Iteration 845000: total loss 0.0766, losses: [0.0766223818063736], learning rate: 0.0094148015
Iteration 845000: total loss 0.0978, losses: [0.09778003394603729], learning rate: 0.0097029900
Iteration 985000: total loss 0.1083, losses: [0.10826382040977478], learning rate: 0.0093206535
Iteration 985000: total loss 0.1025, losses: [0.10253573954105377], learning rate: 0.0092274469
Iteration 850000: total loss 0.0909, losses: [0.09094918519258499], learning rate: 0.0094148015
Iteration 850000: total loss 0.1198, losses: [0.11980361491441727], learning rate: 0.0097029900
Val loss  tensor(1.4200)
Val loss  tensor(0.9455)
Iteration 990000: total loss 0.1055, losses: [0.10547254979610443], learning rate: 0.0092274469
Iteration 990000: total loss 0.0823, losses: [0.08226156234741211], learning rate: 0.0093206535
Val loss  tensor(1.4682)
Val loss  tensor(1.1389)
Iteration 855000: total loss 0.0936, losses: [0.09364095330238342], learning rate: 0.0094148015
Iteration 855000: total loss 0.0995, losses: [0.0995243713259697], learning rate: 0.0097029900
Iteration 995000: total loss 0.1149, losses: [0.11485937982797623], learning rate: 0.0093206535
Iteration 995000: total loss 0.0843, losses: [0.08427821844816208], learning rate: 0.0091351725
Iteration 860000: total loss 0.0823, losses: [0.08233994245529175], learning rate: 0.0094148015
Iteration 860000: total loss 0.0993, losses: [0.09934376180171967], learning rate: 0.0097029900
Val loss  tensor(1.3848)
Val loss  tensor(0.9325)
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=64, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=64, out_features=2, bias=True)
  )
)
cuda:0
Folder already there
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=32, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=32, out_features=32, bias=True)
    (3): SiLU()
    (4): Linear(in_features=32, out_features=2, bias=True)
  )
)
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=32, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=32, out_features=32, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=32, out_features=2, bias=True)
  )
)
cuda:0
Folder already there
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=32, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=32, out_features=64, bias=True)
    (3): SiLU()
    (4): Linear(in_features=64, out_features=2, bias=True)
  )
)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
Iteration 0: total loss 2.2422, losses: [2.2422146797180176], learning rate: 0.0100000000
Iteration 0: total loss 2.5928, losses: [2.5927813053131104], learning rate: 0.0100000000
Val loss  tensor(1.3427)
Val loss  tensor(1.3373)
Iteration 865000: total loss 0.1114, losses: [0.11142491549253464], learning rate: 0.0094148015
Iteration 865000: total loss 0.0963, losses: [0.09625761210918427], learning rate: 0.0097029900
Iteration 5000: total loss 0.2391, losses: [0.23908953368663788], learning rate: 0.0100000000
Iteration 5000: total loss 0.2163, losses: [0.21626651287078857], learning rate: 0.0100000000
Iteration 870000: total loss 0.0787, losses: [0.07866055518388748], learning rate: 0.0094148015
Iteration 870000: total loss 0.0992, losses: [0.09921637177467346], learning rate: 0.0097029900
Val loss  tensor(1.2007)
Val loss  tensor(0.9409)
Iteration 10000: total loss 0.1830, losses: [0.18300886452198029], learning rate: 0.0100000000
Iteration 10000: total loss 0.2241, losses: [0.22413815557956696], learning rate: 0.0100000000
Val loss  tensor(1.3353)
Val loss  tensor(1.5527)
Iteration 875000: total loss 0.1017, losses: [0.10166141390800476], learning rate: 0.0094148015
Iteration 875000: total loss 0.0892, losses: [0.08916793018579483], learning rate: 0.0097029900
Iteration 15000: total loss 0.1832, losses: [0.18318331241607666], learning rate: 0.0100000000
Iteration 15000: total loss 0.1992, losses: [0.19915834069252014], learning rate: 0.0100000000
Iteration 880000: total loss 0.0738, losses: [0.07379085570573807], learning rate: 0.0094148015
Iteration 880000: total loss 0.0955, losses: [0.09550457447767258], learning rate: 0.0097029900
Val loss  tensor(1.1921)
Val loss  tensor(0.9823)
Iteration 20000: total loss 0.1401, losses: [0.1400526762008667], learning rate: 0.0100000000
Iteration 20000: total loss 0.1730, losses: [0.17299345135688782], learning rate: 0.0100000000
Val loss  tensor(1.1539)
Val loss  tensor(1.0537)
Iteration 885000: total loss 0.0718, losses: [0.0717780590057373], learning rate: 0.0094148015
Iteration 885000: total loss 0.0988, losses: [0.09879182279109955], learning rate: 0.0097029900
Iteration 25000: total loss 0.1357, losses: [0.13567642867565155], learning rate: 0.0100000000
Iteration 25000: total loss 0.1456, losses: [0.14556638896465302], learning rate: 0.0100000000
Iteration 30000: total loss 0.1258, losses: [0.1257983148097992], learning rate: 0.0100000000
Iteration 30000: total loss 0.1186, losses: [0.11860445886850357], learning rate: 0.0100000000
Val loss  tensor(0.9162)
Val loss  tensor(1.0717)
Iteration 890000: total loss 0.0741, losses: [0.07411906868219376], learning rate: 0.0094148015
Iteration 890000: total loss 0.0966, losses: [0.09656013548374176], learning rate: 0.0097029900
Val loss  tensor(1.1890)
Val loss  tensor(0.9825)
Iteration 35000: total loss 0.1181, losses: [0.1180608719587326], learning rate: 0.0100000000
Iteration 35000: total loss 0.1217, losses: [0.12174001336097717], learning rate: 0.0100000000
Iteration 895000: total loss 0.0820, losses: [0.08202020823955536], learning rate: 0.0094148015
Iteration 895000: total loss 0.0883, losses: [0.08830870687961578], learning rate: 0.0097029900
Iteration 40000: total loss 0.1440, losses: [0.1440308541059494], learning rate: 0.0100000000
Iteration 40000: total loss 0.1192, losses: [0.11920376121997833], learning rate: 0.0100000000
Val loss  tensor(0.7446)
Val loss  tensor(1.0225)
Iteration 900000: total loss 0.0808, losses: [0.08084072172641754], learning rate: 0.0094148015
Iteration 900000: total loss 0.0875, losses: [0.08747465908527374], learning rate: 0.0097029900
Val loss  tensor(1.2593)
Val loss  tensor(0.9432)
Iteration 45000: total loss 0.1033, losses: [0.10332126170396805], learning rate: 0.0100000000
Iteration 45000: total loss 0.1143, losses: [0.11425971984863281], learning rate: 0.0100000000
Iteration 905000: total loss 0.0777, losses: [0.07771865278482437], learning rate: 0.0094148015
Iteration 905000: total loss 0.0963, losses: [0.09625513106584549], learning rate: 0.0097029900
Iteration 50000: total loss 0.0938, losses: [0.09382639825344086], learning rate: 0.0100000000
Iteration 50000: total loss 0.1284, losses: [0.12835203111171722], learning rate: 0.0100000000
Val loss  tensor(0.7950)
Val loss  tensor(1.0592)
Iteration 910000: total loss 0.0916, losses: [0.09159243106842041], learning rate: 0.0094148015
Iteration 910000: total loss 0.0959, losses: [0.09592102468013763], learning rate: 0.0097029900
Val loss  tensor(1.1172)
Val loss  tensor(0.9320)
Iteration 55000: total loss 0.0969, losses: [0.09687141329050064], learning rate: 0.0100000000
Iteration 55000: total loss 0.0843, losses: [0.08430060744285583], learning rate: 0.0100000000
Iteration 60000: total loss 0.1211, losses: [0.12110059708356857], learning rate: 0.0100000000
Iteration 60000: total loss 0.1249, losses: [0.1248936802148819], learning rate: 0.0100000000
Val loss  tensor(0.8595)
Val loss  tensor(1.0017)
Iteration 915000: total loss 0.0672, losses: [0.06722810119390488], learning rate: 0.0093206535
Iteration 915000: total loss 0.0838, losses: [0.08379388600587845], learning rate: 0.0097029900
Iteration 65000: total loss 0.1085, losses: [0.10851045697927475], learning rate: 0.0100000000
Iteration 65000: total loss 0.1083, losses: [0.10827600955963135], learning rate: 0.0100000000
Iteration 920000: total loss 0.0631, losses: [0.06308028101921082], learning rate: 0.0093206535
Iteration 920000: total loss 0.0965, losses: [0.09648828953504562], learning rate: 0.0097029900
Val loss  tensor(1.1553)
Val loss  tensor(1.0090)
Iteration 70000: total loss 0.1295, losses: [0.1294831782579422], learning rate: 0.0100000000
Iteration 70000: total loss 0.0905, losses: [0.09047894179821014], learning rate: 0.0100000000
Val loss  tensor(0.9043)
Val loss  tensor(1.0167)
Iteration 925000: total loss 0.0702, losses: [0.07024186104536057], learning rate: 0.0093206535
Iteration 925000: total loss 0.1033, losses: [0.10331863164901733], learning rate: 0.0097029900
Iteration 75000: total loss 0.0981, losses: [0.0981483981013298], learning rate: 0.0100000000
Iteration 75000: total loss 0.1086, losses: [0.10856976360082626], learning rate: 0.0100000000
Iteration 930000: total loss 0.0590, losses: [0.05902053415775299], learning rate: 0.0093206535
Iteration 930000: total loss 0.0770, losses: [0.07702653110027313], learning rate: 0.0097029900
Val loss  tensor(1.2418)
Val loss  tensor(0.9193)
Iteration 80000: total loss 0.1161, losses: [0.11611176282167435], learning rate: 0.0100000000
Iteration 80000: total loss 0.1153, losses: [0.1153026670217514], learning rate: 0.0100000000
Val loss  tensor(0.9361)
Val loss  tensor(0.9833)
Iteration 935000: total loss 0.0692, losses: [0.06916383653879166], learning rate: 0.0093206535
Iteration 935000: total loss 0.0893, losses: [0.08933459222316742], learning rate: 0.0096059601
Iteration 85000: total loss 0.0871, losses: [0.08713944256305695], learning rate: 0.0100000000
Iteration 85000: total loss 0.0876, losses: [0.08755940943956375], learning rate: 0.0100000000
Iteration 940000: total loss 0.0833, losses: [0.08329558372497559], learning rate: 0.0093206535
Iteration 940000: total loss 0.0919, losses: [0.09187456220388412], learning rate: 0.0096059601
Val loss  tensor(1.2514)
Val loss  tensor(0.9903)
Iteration 90000: total loss 0.0897, losses: [0.0897148847579956], learning rate: 0.0100000000
Iteration 90000: total loss 0.1019, losses: [0.10185454785823822], learning rate: 0.0100000000
Val loss  tensor(0.7825)
Val loss  tensor(1.0163)
Iteration 95000: total loss 0.0909, losses: [0.09094387292861938], learning rate: 0.0100000000
Iteration 95000: total loss 0.0979, losses: [0.09793264418840408], learning rate: 0.0100000000
Iteration 945000: total loss 0.0794, losses: [0.07936087995767593], learning rate: 0.0093206535
Iteration 945000: total loss 0.0874, losses: [0.08744688332080841], learning rate: 0.0096059601
Iteration 100000: total loss 0.0893, losses: [0.08925698697566986], learning rate: 0.0100000000
Iteration 100000: total loss 0.1105, losses: [0.11048288643360138], learning rate: 0.0100000000
Val loss  tensor(0.8913)
Val loss  tensor(0.9706)
Iteration 950000: total loss 0.0625, losses: [0.06253618001937866], learning rate: 0.0093206535
Iteration 950000: total loss 0.0774, losses: [0.07736264169216156], learning rate: 0.0096059601
Val loss  tensor(1.1949)
Val loss  tensor(1.0149)
Iteration 105000: total loss 0.0993, losses: [0.0992957353591919], learning rate: 0.0100000000
Iteration 105000: total loss 0.0920, losses: [0.09199845790863037], learning rate: 0.0100000000
Iteration 955000: total loss 0.0756, losses: [0.0756421610713005], learning rate: 0.0093206535
Iteration 955000: total loss 0.0872, losses: [0.08724968135356903], learning rate: 0.0096059601
Iteration 110000: total loss 0.1034, losses: [0.10341699421405792], learning rate: 0.0100000000
Iteration 110000: total loss 0.0957, losses: [0.09569808840751648], learning rate: 0.0100000000
Val loss  tensor(0.9693)
Val loss  tensor(0.9538)
Iteration 960000: total loss 0.0688, losses: [0.06880928575992584], learning rate: 0.0093206535
Iteration 960000: total loss 0.0933, losses: [0.09334641695022583], learning rate: 0.0096059601
Val loss  tensor(1.3298)
Val loss  tensor(0.9750)
Iteration 115000: total loss 0.0658, losses: [0.0658102035522461], learning rate: 0.0100000000
Iteration 115000: total loss 0.0967, losses: [0.09665167331695557], learning rate: 0.0100000000
Iteration 965000: total loss 0.0741, losses: [0.0741221085190773], learning rate: 0.0093206535
Iteration 965000: total loss 0.0837, losses: [0.0836767703294754], learning rate: 0.0096059601
Iteration 120000: total loss 0.0807, losses: [0.08068429678678513], learning rate: 0.0100000000
Iteration 120000: total loss 0.0893, losses: [0.0893000066280365], learning rate: 0.0100000000
Val loss  tensor(0.9925)
Val loss  tensor(0.9971)
Iteration 970000: total loss 0.0859, losses: [0.08590299636125565], learning rate: 0.0093206535
Iteration 970000: total loss 0.0710, losses: [0.07099143415689468], learning rate: 0.0096059601
Val loss  tensor(1.2227)
Val loss  tensor(0.9970)
Iteration 125000: total loss 0.0766, losses: [0.0766403079032898], learning rate: 0.0100000000
Iteration 125000: total loss 0.0771, losses: [0.07706482708454132], learning rate: 0.0100000000
Iteration 130000: total loss 0.1047, losses: [0.10470236092805862], learning rate: 0.0100000000
Iteration 130000: total loss 0.0942, losses: [0.09423847496509552], learning rate: 0.0100000000
Val loss  tensor(0.9008)
Val loss  tensor(0.9528)
Iteration 975000: total loss 0.0727, losses: [0.07267342507839203], learning rate: 0.0093206535
Iteration 975000: total loss 0.0893, losses: [0.08931916952133179], learning rate: 0.0096059601
Iteration 135000: total loss 0.0918, losses: [0.09182415157556534], learning rate: 0.0100000000
Iteration 135000: total loss 0.1016, losses: [0.10160206258296967], learning rate: 0.0100000000
Iteration 980000: total loss 0.0720, losses: [0.07203648239374161], learning rate: 0.0093206535
Iteration 980000: total loss 0.0827, losses: [0.08272144943475723], learning rate: 0.0096059601
Val loss  tensor(1.2233)
Val loss  tensor(0.9718)
Iteration 140000: total loss 0.0949, losses: [0.09486629068851471], learning rate: 0.0100000000
Iteration 140000: total loss 0.1068, losses: [0.1068204939365387], learning rate: 0.0100000000
Val loss  tensor(0.7670)
Val loss  tensor(0.9595)
Iteration 985000: total loss 0.0763, losses: [0.07633580267429352], learning rate: 0.0093206535
Iteration 985000: total loss 0.0921, losses: [0.09212720394134521], learning rate: 0.0096059601
Iteration 145000: total loss 0.0806, losses: [0.08058683574199677], learning rate: 0.0100000000
Iteration 145000: total loss 0.0827, losses: [0.08272729068994522], learning rate: 0.0100000000
Iteration 990000: total loss 0.0801, losses: [0.0800759345293045], learning rate: 0.0093206535
Iteration 990000: total loss 0.0983, losses: [0.0983332172036171], learning rate: 0.0096059601
Val loss  tensor(1.2890)
Val loss  tensor(0.9662)
Iteration 150000: total loss 0.0744, losses: [0.07440857589244843], learning rate: 0.0100000000
Iteration 150000: total loss 0.0727, losses: [0.07269494235515594], learning rate: 0.0100000000
Val loss  tensor(0.7453)
Val loss  tensor(0.9655)
Iteration 995000: total loss 0.0724, losses: [0.07243700325489044], learning rate: 0.0093206535
Iteration 995000: total loss 0.0884, losses: [0.08844108134508133], learning rate: 0.0096059601
Iteration 155000: total loss 0.0768, losses: [0.07679958641529083], learning rate: 0.0099000000
Iteration 155000: total loss 0.0884, losses: [0.08840858936309814], learning rate: 0.0100000000
Iteration 160000: total loss 0.0788, losses: [0.0787770003080368], learning rate: 0.0099000000
Iteration 160000: total loss 0.0983, losses: [0.09829750657081604], learning rate: 0.0100000000
Val loss  tensor(0.7987)
Val loss  tensor(0.9730)
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=64, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=64, out_features=32, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=32, out_features=2, bias=True)
  )
)
cuda:1
Folder already there
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=64, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=64, out_features=32, bias=True)
    (3): SiLU()
    (4): Linear(in_features=32, out_features=2, bias=True)
  )
)
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=64, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=64, out_features=32, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=32, out_features=2, bias=True)
  )
)
cuda:1
Folder already there
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=32, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=32, out_features=64, bias=True)
    (3): SiLU()
    (4): Linear(in_features=64, out_features=2, bias=True)
  )
)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
Iteration 0: total loss 2.7339, losses: [2.7338786125183105], learning rate: 0.0100000000
Iteration 0: total loss 2.7071, losses: [2.707146167755127], learning rate: 0.0100000000
Val loss  tensor(1.3742)
Val loss  tensor(1.3345)
Iteration 165000: total loss 0.0781, losses: [0.07806415110826492], learning rate: 0.0099000000
Iteration 165000: total loss 0.0879, losses: [0.08788132667541504], learning rate: 0.0100000000
Iteration 5000: total loss 0.2167, losses: [0.21672549843788147], learning rate: 0.0100000000
Iteration 5000: total loss 0.2759, losses: [0.2758530080318451], learning rate: 0.0100000000
Iteration 170000: total loss 0.0919, losses: [0.09191961586475372], learning rate: 0.0099000000
Iteration 170000: total loss 0.0816, losses: [0.08161622285842896], learning rate: 0.0100000000
Val loss  tensor(0.7163)
Val loss  tensor(1.0014)
Iteration 10000: total loss 0.1598, losses: [0.15980583429336548], learning rate: 0.0100000000
Iteration 10000: total loss 0.2072, losses: [0.2072148621082306], learning rate: 0.0100000000
Val loss  tensor(1.2898)
Val loss  tensor(1.8253)
Iteration 175000: total loss 0.0751, losses: [0.07514895498752594], learning rate: 0.0099000000
Iteration 175000: total loss 0.0979, losses: [0.09790794551372528], learning rate: 0.0100000000
Iteration 15000: total loss 0.1483, losses: [0.14831915497779846], learning rate: 0.0100000000
Iteration 15000: total loss 0.1664, losses: [0.16635099053382874], learning rate: 0.0100000000
Iteration 180000: total loss 0.0691, losses: [0.06912152469158173], learning rate: 0.0099000000
Iteration 180000: total loss 0.0952, losses: [0.09517666697502136], learning rate: 0.0100000000
Val loss  tensor(0.7220)
Val loss  tensor(1.0146)
Iteration 20000: total loss 0.1292, losses: [0.12918496131896973], learning rate: 0.0100000000
Iteration 20000: total loss 0.1695, losses: [0.16953322291374207], learning rate: 0.0100000000
Val loss  tensor(1.3038)
Val loss  tensor(1.2193)
Iteration 185000: total loss 0.0806, losses: [0.08056250214576721], learning rate: 0.0099000000
Iteration 185000: total loss 0.0752, losses: [0.0752047598361969], learning rate: 0.0100000000
Iteration 25000: total loss 0.1334, losses: [0.13336731493473053], learning rate: 0.0100000000
Iteration 25000: total loss 0.1193, losses: [0.11931967735290527], learning rate: 0.0100000000
Iteration 190000: total loss 0.0699, losses: [0.06985214352607727], learning rate: 0.0099000000
Iteration 190000: total loss 0.0836, losses: [0.0835890918970108], learning rate: 0.0100000000
Val loss  tensor(0.7137)
Val loss  tensor(1.0206)
Iteration 30000: total loss 0.1197, losses: [0.1197294145822525], learning rate: 0.0100000000
Iteration 30000: total loss 0.1051, losses: [0.1050739586353302], learning rate: 0.0100000000
Iteration 195000: total loss 0.0802, losses: [0.0802001804113388], learning rate: 0.0099000000
Iteration 195000: total loss 0.0688, losses: [0.06876057386398315], learning rate: 0.0100000000
Val loss  tensor(1.1610)
Val loss  tensor(1.0900)
Iteration 200000: total loss 0.0717, losses: [0.07166063040494919], learning rate: 0.0099000000
Iteration 200000: total loss 0.0918, losses: [0.09179693460464478], learning rate: 0.0100000000
Iteration 35000: total loss 0.1092, losses: [0.1092103123664856], learning rate: 0.0100000000
Iteration 35000: total loss 0.1187, losses: [0.11873355507850647], learning rate: 0.0100000000
Val loss  tensor(0.7043)
Val loss  tensor(1.0347)
Iteration 205000: total loss 0.0717, losses: [0.07167287170886993], learning rate: 0.0099000000
Iteration 205000: total loss 0.0923, losses: [0.09229689836502075], learning rate: 0.0100000000
Iteration 40000: total loss 0.1214, losses: [0.1213657557964325], learning rate: 0.0100000000
Iteration 40000: total loss 0.1078, losses: [0.10780081152915955], learning rate: 0.0100000000
Val loss  tensor(1.0651)
Val loss  tensor(1.0453)
Iteration 210000: total loss 0.0670, losses: [0.06695390492677689], learning rate: 0.0099000000
Iteration 210000: total loss 0.0921, losses: [0.0921316146850586], learning rate: 0.0100000000
Val loss  tensor(0.7501)
Val loss  tensor(1.0426)
Iteration 45000: total loss 0.1156, losses: [0.11556197702884674], learning rate: 0.0100000000
Iteration 45000: total loss 0.1153, losses: [0.11532819271087646], learning rate: 0.0100000000
Iteration 215000: total loss 0.0624, losses: [0.06235518306493759], learning rate: 0.0099000000
Iteration 215000: total loss 0.0783, losses: [0.07830974459648132], learning rate: 0.0100000000
Iteration 50000: total loss 0.1181, losses: [0.11809365451335907], learning rate: 0.0100000000
Iteration 50000: total loss 0.1047, losses: [0.10473774373531342], learning rate: 0.0100000000
Val loss  tensor(0.9272)
Val loss  tensor(1.0605)
Iteration 220000: total loss 0.0747, losses: [0.07471808046102524], learning rate: 0.0099000000
Iteration 220000: total loss 0.0836, losses: [0.0835924968123436], learning rate: 0.0100000000
Val loss  tensor(0.7302)
Val loss  tensor(0.9878)
Iteration 55000: total loss 0.1266, losses: [0.1266421377658844], learning rate: 0.0100000000
Iteration 55000: total loss 0.1070, losses: [0.10700539499521255], learning rate: 0.0100000000
Iteration 225000: total loss 0.0705, losses: [0.07048042863607407], learning rate: 0.0099000000
Iteration 225000: total loss 0.0775, losses: [0.07752875983715057], learning rate: 0.0100000000
Iteration 60000: total loss 0.1235, losses: [0.12350001931190491], learning rate: 0.0100000000
Iteration 60000: total loss 0.1173, losses: [0.11728035658597946], learning rate: 0.0100000000
Val loss  tensor(0.9596)
Val loss  tensor(0.9683)
Iteration 230000: total loss 0.0601, losses: [0.06013484671711922], learning rate: 0.0099000000
Iteration 230000: total loss 0.0742, losses: [0.0741962417960167], learning rate: 0.0100000000
Val loss  tensor(0.6956)
Val loss  tensor(0.9803)
Iteration 65000: total loss 0.1143, losses: [0.1142815425992012], learning rate: 0.0100000000
Iteration 65000: total loss 0.1164, losses: [0.11638957262039185], learning rate: 0.0100000000
Iteration 235000: total loss 0.0783, losses: [0.07830243557691574], learning rate: 0.0099000000
Iteration 235000: total loss 0.0852, losses: [0.0851736068725586], learning rate: 0.0100000000
Iteration 70000: total loss 0.0914, losses: [0.0913696140050888], learning rate: 0.0100000000
Iteration 70000: total loss 0.1047, losses: [0.10474752634763718], learning rate: 0.0100000000
Val loss  tensor(0.8775)
Val loss  tensor(0.9885)
Iteration 240000: total loss 0.0688, losses: [0.06881311535835266], learning rate: 0.0099000000
Iteration 240000: total loss 0.0759, losses: [0.07587191462516785], learning rate: 0.0100000000
Val loss  tensor(0.7514)
Val loss  tensor(0.9679)
Iteration 75000: total loss 0.0937, losses: [0.09368515014648438], learning rate: 0.0100000000
Iteration 75000: total loss 0.1058, losses: [0.10575713217258453], learning rate: 0.0100000000
Iteration 245000: total loss 0.0587, losses: [0.058735039085149765], learning rate: 0.0099000000
Iteration 245000: total loss 0.0850, losses: [0.08500204235315323], learning rate: 0.0099000000
Iteration 80000: total loss 0.1100, losses: [0.11004593968391418], learning rate: 0.0100000000
Iteration 80000: total loss 0.1066, losses: [0.10659600794315338], learning rate: 0.0100000000
Val loss  tensor(0.8977)
Val loss  tensor(0.9147)
Iteration 250000: total loss 0.0797, losses: [0.07974153012037277], learning rate: 0.0099000000
Iteration 250000: total loss 0.0707, losses: [0.07073979079723358], learning rate: 0.0099000000
Val loss  tensor(0.7914)
Val loss  tensor(0.9487)
Iteration 85000: total loss 0.0985, losses: [0.09849946200847626], learning rate: 0.0100000000
Iteration 85000: total loss 0.1158, losses: [0.115773506462574], learning rate: 0.0100000000
Iteration 255000: total loss 0.0720, losses: [0.07200299203395844], learning rate: 0.0099000000
Iteration 255000: total loss 0.0858, losses: [0.08584697544574738], learning rate: 0.0099000000
Iteration 90000: total loss 0.0979, losses: [0.09790561348199844], learning rate: 0.0100000000
Iteration 90000: total loss 0.1166, losses: [0.11664336919784546], learning rate: 0.0100000000
Val loss  tensor(0.7986)
Val loss  tensor(0.9553)
Iteration 260000: total loss 0.0682, losses: [0.0682469829916954], learning rate: 0.0099000000
Iteration 260000: total loss 0.1007, losses: [0.10067423433065414], learning rate: 0.0099000000
Val loss  tensor(0.7737)
Val loss  tensor(0.9550)
Iteration 95000: total loss 0.0859, losses: [0.08586203306913376], learning rate: 0.0100000000
Iteration 95000: total loss 0.1035, losses: [0.10352569818496704], learning rate: 0.0100000000
Iteration 265000: total loss 0.0672, losses: [0.06719615310430527], learning rate: 0.0099000000
Iteration 265000: total loss 0.0732, losses: [0.07319691777229309], learning rate: 0.0099000000
Iteration 270000: total loss 0.0647, losses: [0.06474223732948303], learning rate: 0.0099000000
Iteration 270000: total loss 0.0753, losses: [0.07527876645326614], learning rate: 0.0099000000
Val loss  tensor(0.7777)
Val loss  tensor(1.1858)
Iteration 100000: total loss 0.0992, losses: [0.09919484704732895], learning rate: 0.0100000000
Iteration 100000: total loss 0.0989, losses: [0.09886351227760315], learning rate: 0.0100000000
Val loss  tensor(0.8963)
Val loss  tensor(0.8980)
Iteration 275000: total loss 0.0618, losses: [0.0617714487016201], learning rate: 0.0099000000
Iteration 275000: total loss 0.0783, losses: [0.07825659215450287], learning rate: 0.0099000000
Iteration 105000: total loss 0.0934, losses: [0.09338823705911636], learning rate: 0.0100000000
Iteration 105000: total loss 0.1057, losses: [0.10565610975027084], learning rate: 0.0100000000
Iteration 280000: total loss 0.0862, losses: [0.08618185669183731], learning rate: 0.0099000000
Iteration 280000: total loss 0.0748, losses: [0.0747794583439827], learning rate: 0.0099000000
Val loss  tensor(0.8062)
Val loss  tensor(1.3019)
Iteration 110000: total loss 0.1064, losses: [0.1064327210187912], learning rate: 0.0100000000
Iteration 110000: total loss 0.1018, losses: [0.10181309282779694], learning rate: 0.0100000000
Val loss  tensor(0.7817)
Val loss  tensor(0.8284)
Iteration 285000: total loss 0.0665, losses: [0.06648804247379303], learning rate: 0.0099000000
Iteration 285000: total loss 0.0719, losses: [0.07187134772539139], learning rate: 0.0099000000
Iteration 115000: total loss 0.1037, losses: [0.1036662682890892], learning rate: 0.0100000000
Iteration 115000: total loss 0.0757, losses: [0.07568539679050446], learning rate: 0.0100000000
Iteration 290000: total loss 0.0644, losses: [0.06442324817180634], learning rate: 0.0099000000
Iteration 290000: total loss 0.0799, losses: [0.07986272871494293], learning rate: 0.0099000000
Val loss  tensor(0.8068)
Val loss  tensor(1.3465)
Iteration 120000: total loss 0.1101, losses: [0.1101171150803566], learning rate: 0.0100000000
Iteration 120000: total loss 0.1079, losses: [0.1078546941280365], learning rate: 0.0100000000
Val loss  tensor(0.8724)
Val loss  tensor(0.8791)
Iteration 295000: total loss 0.0522, losses: [0.0521845705807209], learning rate: 0.0099000000
Iteration 295000: total loss 0.0782, losses: [0.07818266749382019], learning rate: 0.0099000000
Iteration 125000: total loss 0.0795, losses: [0.07948382198810577], learning rate: 0.0100000000
Iteration 125000: total loss 0.0978, losses: [0.09781798720359802], learning rate: 0.0100000000
Iteration 300000: total loss 0.0758, losses: [0.07584399729967117], learning rate: 0.0099000000
Iteration 300000: total loss 0.0693, losses: [0.06934484839439392], learning rate: 0.0099000000
Val loss  tensor(0.7741)
Val loss  tensor(1.4196)
Iteration 130000: total loss 0.0915, losses: [0.09151436388492584], learning rate: 0.0100000000
Iteration 130000: total loss 0.0888, losses: [0.08876877278089523], learning rate: 0.0100000000
Val loss  tensor(0.7615)
Val loss  tensor(0.8730)
Iteration 305000: total loss 0.0609, losses: [0.06094910576939583], learning rate: 0.0099000000
Iteration 305000: total loss 0.0896, losses: [0.08955542743206024], learning rate: 0.0099000000
Iteration 135000: total loss 0.0965, losses: [0.09646071493625641], learning rate: 0.0100000000
Iteration 135000: total loss 0.1041, losses: [0.10412350296974182], learning rate: 0.0100000000
Iteration 310000: total loss 0.0727, losses: [0.07272042334079742], learning rate: 0.0099000000
Iteration 310000: total loss 0.0993, losses: [0.09928324818611145], learning rate: 0.0099000000
Val loss  tensor(0.7268)
Val loss  tensor(1.5763)
Iteration 140000: total loss 0.0910, losses: [0.09096695482730865], learning rate: 0.0100000000
Iteration 140000: total loss 0.0963, losses: [0.09633597731590271], learning rate: 0.0100000000
Val loss  tensor(0.8330)
Val loss  tensor(0.8800)
Iteration 315000: total loss 0.0843, losses: [0.08428890258073807], learning rate: 0.0099000000
Iteration 315000: total loss 0.0865, losses: [0.08651060611009598], learning rate: 0.0099000000
Iteration 145000: total loss 0.0925, losses: [0.09249213337898254], learning rate: 0.0100000000
Iteration 145000: total loss 0.1224, losses: [0.12241780012845993], learning rate: 0.0100000000
Iteration 320000: total loss 0.0711, losses: [0.07108861207962036], learning rate: 0.0099000000
Iteration 320000: total loss 0.0730, losses: [0.0729549452662468], learning rate: 0.0099000000
Val loss  tensor(0.7456)
Val loss  tensor(1.5715)
Iteration 150000: total loss 0.0941, losses: [0.09412804245948792], learning rate: 0.0100000000
Iteration 150000: total loss 0.1145, losses: [0.114549919962883], learning rate: 0.0100000000
Val loss  tensor(0.7061)
Val loss  tensor(0.8200)
Iteration 325000: total loss 0.0651, losses: [0.06514130532741547], learning rate: 0.0099000000
Iteration 325000: total loss 0.0847, losses: [0.08474339544773102], learning rate: 0.0099000000
Iteration 155000: total loss 0.0716, losses: [0.07163982838392258], learning rate: 0.0100000000
Iteration 155000: total loss 0.0842, losses: [0.08418016880750656], learning rate: 0.0100000000
Iteration 330000: total loss 0.0667, losses: [0.06672497093677521], learning rate: 0.0099000000
Iteration 330000: total loss 0.0682, losses: [0.0682028979063034], learning rate: 0.0099000000
Val loss  tensor(0.7135)
Val loss  tensor(1.5625)
Iteration 160000: total loss 0.0825, losses: [0.08245029300451279], learning rate: 0.0100000000
Iteration 160000: total loss 0.0766, losses: [0.07662321627140045], learning rate: 0.0100000000
Val loss  tensor(0.7568)
Val loss  tensor(0.9242)
Iteration 335000: total loss 0.0770, losses: [0.0770164206624031], learning rate: 0.0099000000
Iteration 335000: total loss 0.0815, losses: [0.0815124586224556], learning rate: 0.0099000000
Iteration 340000: total loss 0.0714, losses: [0.07138332724571228], learning rate: 0.0099000000
Iteration 340000: total loss 0.0716, losses: [0.07158543914556503], learning rate: 0.0099000000
Iteration 165000: total loss 0.0662, losses: [0.06616035103797913], learning rate: 0.0100000000
Iteration 165000: total loss 0.0908, losses: [0.09081494063138962], learning rate: 0.0100000000
Val loss  tensor(0.7213)
Val loss  tensor(1.4942)
Iteration 345000: total loss 0.0633, losses: [0.06325127929449081], learning rate: 0.0098010000
Iteration 345000: total loss 0.0699, losses: [0.06990494579076767], learning rate: 0.0099000000
Iteration 170000: total loss 0.0765, losses: [0.07651649415493011], learning rate: 0.0100000000
Iteration 170000: total loss 0.0915, losses: [0.09146309643983841], learning rate: 0.0100000000
Val loss  tensor(0.7278)
Val loss  tensor(0.8460)
Iteration 350000: total loss 0.0611, losses: [0.06113215163350105], learning rate: 0.0098010000
Iteration 350000: total loss 0.0692, losses: [0.06917295604944229], learning rate: 0.0099000000
Val loss  tensor(0.7014)
Val loss  tensor(1.4891)
Iteration 175000: total loss 0.0858, losses: [0.08581817150115967], learning rate: 0.0100000000
Iteration 175000: total loss 0.1073, losses: [0.10725340247154236], learning rate: 0.0100000000
Iteration 355000: total loss 0.0692, losses: [0.06915341317653656], learning rate: 0.0098010000
Iteration 355000: total loss 0.0836, losses: [0.08361971378326416], learning rate: 0.0099000000
Iteration 180000: total loss 0.0727, losses: [0.07266845554113388], learning rate: 0.0100000000
Iteration 180000: total loss 0.0853, losses: [0.08531572669744492], learning rate: 0.0100000000
Val loss  tensor(0.6903)
Val loss  tensor(0.9017)
Iteration 360000: total loss 0.0750, losses: [0.0749877318739891], learning rate: 0.0098010000
Iteration 360000: total loss 0.0578, losses: [0.05781774967908859], learning rate: 0.0099000000
Val loss  tensor(0.7948)
Val loss  tensor(1.4718)
Iteration 185000: total loss 0.0984, losses: [0.09841607511043549], learning rate: 0.0100000000
Iteration 185000: total loss 0.0969, losses: [0.09693581610918045], learning rate: 0.0100000000
Iteration 365000: total loss 0.0440, losses: [0.044045861810445786], learning rate: 0.0098010000
Iteration 365000: total loss 0.0759, losses: [0.0759103000164032], learning rate: 0.0098010000
Iteration 190000: total loss 0.0758, losses: [0.07583639025688171], learning rate: 0.0100000000
Iteration 190000: total loss 0.0922, losses: [0.09221170842647552], learning rate: 0.0100000000
Val loss  tensor(0.6838)
Val loss  tensor(0.8968)
Iteration 370000: total loss 0.0525, losses: [0.05249487981200218], learning rate: 0.0098010000
Iteration 370000: total loss 0.0745, losses: [0.07452989369630814], learning rate: 0.0098010000
Val loss  tensor(0.7135)
Val loss  tensor(1.4996)
Iteration 195000: total loss 0.0860, losses: [0.08596979081630707], learning rate: 0.0100000000
Iteration 195000: total loss 0.1153, losses: [0.11534883826971054], learning rate: 0.0100000000
Iteration 375000: total loss 0.0621, losses: [0.06206178292632103], learning rate: 0.0098010000
Iteration 375000: total loss 0.0791, losses: [0.07908894121646881], learning rate: 0.0098010000
Iteration 200000: total loss 0.0874, losses: [0.08736543357372284], learning rate: 0.0100000000
Iteration 200000: total loss 0.0959, losses: [0.09590842574834824], learning rate: 0.0100000000
Val loss  tensor(0.8374)
Val loss  tensor(0.8254)
Iteration 380000: total loss 0.0609, losses: [0.06093854084610939], learning rate: 0.0098010000
Iteration 380000: total loss 0.0641, losses: [0.06406238675117493], learning rate: 0.0098010000
Val loss  tensor(0.6853)
Val loss  tensor(1.4823)
Iteration 205000: total loss 0.0862, losses: [0.08620642870664597], learning rate: 0.0100000000
Iteration 205000: total loss 0.1008, losses: [0.10083732008934021], learning rate: 0.0100000000
Iteration 385000: total loss 0.0644, losses: [0.0643664002418518], learning rate: 0.0098010000
Iteration 385000: total loss 0.0770, losses: [0.07702851295471191], learning rate: 0.0098010000
Iteration 210000: total loss 0.0727, losses: [0.07274757325649261], learning rate: 0.0100000000
Iteration 210000: total loss 0.0970, losses: [0.09704333543777466], learning rate: 0.0100000000
Val loss  tensor(0.7106)
Val loss  tensor(0.8590)
Iteration 390000: total loss 0.0593, losses: [0.0593298003077507], learning rate: 0.0098010000
Iteration 390000: total loss 0.0623, losses: [0.06225906312465668], learning rate: 0.0098010000
Val loss  tensor(0.7409)
Val loss  tensor(1.4749)
Iteration 215000: total loss 0.0701, losses: [0.07011424750089645], learning rate: 0.0100000000
Iteration 215000: total loss 0.0734, losses: [0.07340644299983978], learning rate: 0.0100000000
Iteration 395000: total loss 0.0620, losses: [0.061959266662597656], learning rate: 0.0098010000
Iteration 395000: total loss 0.0565, losses: [0.05651845037937164], learning rate: 0.0098010000
Iteration 220000: total loss 0.0822, losses: [0.08222611248493195], learning rate: 0.0100000000
Iteration 220000: total loss 0.1197, losses: [0.11968006193637848], learning rate: 0.0100000000
Val loss  tensor(0.7068)
Val loss  tensor(0.7955)
Iteration 400000: total loss 0.0780, losses: [0.07804878801107407], learning rate: 0.0098010000
Iteration 400000: total loss 0.0804, losses: [0.08044448494911194], learning rate: 0.0098010000
Val loss  tensor(0.8261)
Val loss  tensor(1.4144)
Iteration 225000: total loss 0.0794, losses: [0.07939866185188293], learning rate: 0.0100000000
Iteration 225000: total loss 0.0762, losses: [0.0761784017086029], learning rate: 0.0100000000
Iteration 405000: total loss 0.0570, losses: [0.05702746659517288], learning rate: 0.0098010000
Iteration 405000: total loss 0.0643, losses: [0.06429657340049744], learning rate: 0.0098010000
Iteration 230000: total loss 0.0837, losses: [0.08374732732772827], learning rate: 0.0100000000
Iteration 230000: total loss 0.0805, losses: [0.0804639607667923], learning rate: 0.0100000000
Val loss  tensor(0.9012)
Val loss  tensor(0.8313)
Iteration 410000: total loss 0.0581, losses: [0.058118924498558044], learning rate: 0.0098010000
Iteration 410000: total loss 0.0606, losses: [0.060585737228393555], learning rate: 0.0098010000
Val loss  tensor(0.7423)
Val loss  tensor(1.3599)
Iteration 235000: total loss 0.0811, losses: [0.08109423518180847], learning rate: 0.0100000000
Iteration 235000: total loss 0.1113, losses: [0.11132767796516418], learning rate: 0.0100000000
Iteration 415000: total loss 0.0583, losses: [0.05826616287231445], learning rate: 0.0098010000
Iteration 415000: total loss 0.0803, losses: [0.08028124272823334], learning rate: 0.0098010000
Iteration 240000: total loss 0.0800, losses: [0.08004666864871979], learning rate: 0.0100000000
Iteration 240000: total loss 0.0810, losses: [0.0810237005352974], learning rate: 0.0100000000
Iteration 420000: total loss 0.0631, losses: [0.06312861293554306], learning rate: 0.0098010000
Iteration 420000: total loss 0.0696, losses: [0.06957316398620605], learning rate: 0.0098010000
Val loss  tensor(0.6790)
Val loss  tensor(0.8401)
Val loss  tensor(0.7764)
Val loss  tensor(1.3739)
Iteration 425000: total loss 0.0571, losses: [0.057102836668491364], learning rate: 0.0098010000
Iteration 425000: total loss 0.0715, losses: [0.07151643186807632], learning rate: 0.0098010000
Iteration 245000: total loss 0.0706, losses: [0.07061095535755157], learning rate: 0.0100000000
Iteration 245000: total loss 0.0709, losses: [0.07092109322547913], learning rate: 0.0100000000
Iteration 430000: total loss 0.0689, losses: [0.06888951361179352], learning rate: 0.0098010000
Iteration 430000: total loss 0.0618, losses: [0.061765190213918686], learning rate: 0.0098010000
Val loss  tensor(0.7943)
Val loss  tensor(1.4735)
Iteration 250000: total loss 0.0883, losses: [0.08831607550382614], learning rate: 0.0100000000
Iteration 250000: total loss 0.0962, losses: [0.09620669484138489], learning rate: 0.0100000000
Val loss  tensor(0.6932)
Val loss  tensor(0.8811)
Iteration 435000: total loss 0.0508, losses: [0.05083755403757095], learning rate: 0.0098010000
Iteration 435000: total loss 0.0815, losses: [0.08154772967100143], learning rate: 0.0098010000
Iteration 255000: total loss 0.0727, losses: [0.07272473722696304], learning rate: 0.0100000000
Iteration 255000: total loss 0.0725, losses: [0.07250968366861343], learning rate: 0.0100000000
Iteration 440000: total loss 0.0597, losses: [0.05965394154191017], learning rate: 0.0098010000
Iteration 440000: total loss 0.0932, losses: [0.09315625578165054], learning rate: 0.0098010000
Val loss  tensor(0.8017)
Val loss  tensor(1.3902)
Iteration 260000: total loss 0.0751, losses: [0.07510977983474731], learning rate: 0.0100000000
Iteration 260000: total loss 0.0980, losses: [0.09802676737308502], learning rate: 0.0100000000
Val loss  tensor(0.8487)
Val loss  tensor(1.0007)
Iteration 445000: total loss 0.0679, losses: [0.0679444968700409], learning rate: 0.0098010000
Iteration 445000: total loss 0.0700, losses: [0.06999967992305756], learning rate: 0.0098010000
Iteration 265000: total loss 0.0715, losses: [0.07154002040624619], learning rate: 0.0100000000
Iteration 265000: total loss 0.0980, losses: [0.09795862436294556], learning rate: 0.0100000000
Iteration 450000: total loss 0.0618, losses: [0.06182624399662018], learning rate: 0.0098010000
Iteration 450000: total loss 0.0608, losses: [0.06078798323869705], learning rate: 0.0098010000
Val loss  tensor(0.6886)
Val loss  tensor(1.4385)
Iteration 270000: total loss 0.0723, losses: [0.0722716748714447], learning rate: 0.0100000000
Iteration 270000: total loss 0.0916, losses: [0.09158594906330109], learning rate: 0.0100000000
Val loss  tensor(0.7931)
Val loss  tensor(1.0107)
Iteration 455000: total loss 0.0574, losses: [0.057422757148742676], learning rate: 0.0098010000
Iteration 455000: total loss 0.0649, losses: [0.06488363444805145], learning rate: 0.0098010000
Iteration 275000: total loss 0.0602, losses: [0.06023203581571579], learning rate: 0.0100000000
Iteration 275000: total loss 0.0913, losses: [0.09127858281135559], learning rate: 0.0100000000
Iteration 460000: total loss 0.0662, losses: [0.06619545817375183], learning rate: 0.0098010000
Iteration 460000: total loss 0.0701, losses: [0.07005590945482254], learning rate: 0.0098010000
Val loss  tensor(0.7928)
Val loss  tensor(1.4095)
Iteration 280000: total loss 0.0805, losses: [0.08053816854953766], learning rate: 0.0100000000
Iteration 280000: total loss 0.0955, losses: [0.09548570960760117], learning rate: 0.0100000000
Val loss  tensor(0.8194)
Val loss  tensor(0.9033)
Iteration 465000: total loss 0.0646, losses: [0.06459017097949982], learning rate: 0.0098010000
Iteration 465000: total loss 0.0744, losses: [0.07435083389282227], learning rate: 0.0098010000
Iteration 285000: total loss 0.0687, losses: [0.06874891370534897], learning rate: 0.0100000000
Iteration 285000: total loss 0.0858, losses: [0.08575458079576492], learning rate: 0.0100000000
Iteration 470000: total loss 0.0578, losses: [0.057764746248722076], learning rate: 0.0098010000
Iteration 470000: total loss 0.0660, losses: [0.06601119041442871], learning rate: 0.0098010000
Val loss  tensor(0.7386)
Val loss  tensor(1.5490)
Iteration 290000: total loss 0.0662, losses: [0.06621795892715454], learning rate: 0.0100000000
Iteration 475000: total loss 0.0449, losses: [0.04492805153131485], learning rate: 0.0098010000
Iteration 475000: total loss 0.0629, losses: [0.0628741979598999], learning rate: 0.0097029900
Iteration 290000: total loss 0.0934, losses: [0.09337577223777771], learning rate: 0.0100000000
Val loss  tensor(0.8778)
Val loss  tensor(1.1561)
Iteration 480000: total loss 0.0583, losses: [0.05828871950507164], learning rate: 0.0098010000
Iteration 480000: total loss 0.0783, losses: [0.07834450155496597], learning rate: 0.0097029900
Val loss  tensor(0.7207)
Val loss  tensor(1.4868)
Iteration 295000: total loss 0.0737, losses: [0.07370860129594803], learning rate: 0.0100000000
Iteration 295000: total loss 0.0846, losses: [0.08462785184383392], learning rate: 0.0100000000
Iteration 485000: total loss nan, losses: [nan], learning rate: 0.0098010000
Iteration 485000: total loss 0.0659, losses: [0.06587624549865723], learning rate: 0.0097029900
Iteration 300000: total loss 0.0686, losses: [0.06858444213867188], learning rate: 0.0100000000
Iteration 300000: total loss 0.0934, losses: [0.09338969737291336], learning rate: 0.0100000000
Val loss  tensor(0.9078)
Val loss  tensor(1.0668)
Iteration 490000: total loss nan, losses: [nan], learning rate: 0.0098010000
Iteration 490000: total loss 0.0580, losses: [0.05797264724969864], learning rate: 0.0097029900
Val loss  tensor(nan)
Val loss  tensor(1.5276)
Iteration 305000: total loss 0.0642, losses: [0.06416343152523041], learning rate: 0.0100000000
Iteration 305000: total loss 0.0915, losses: [0.09145014733076096], learning rate: 0.0100000000
Iteration 495000: total loss nan, losses: [nan], learning rate: 0.0097029900
Iteration 495000: total loss 0.0557, losses: [0.05568641051650047], learning rate: 0.0097029900
Iteration 310000: total loss 0.0743, losses: [0.07429489493370056], learning rate: 0.0100000000
Iteration 310000: total loss 0.0830, losses: [0.08297567814588547], learning rate: 0.0100000000
Val loss  tensor(0.8874)
Val loss  tensor(1.2189)
Iteration 500000: total loss nan, losses: [nan], learning rate: 0.0097029900
Iteration 500000: total loss 0.0789, losses: [0.07885216176509857], learning rate: 0.0097029900
Val loss  tensor(nan)
Val loss  tensor(1.4774)
Iteration 315000: total loss 0.0773, losses: [0.07727880775928497], learning rate: 0.0100000000
Iteration 315000: total loss 0.0957, losses: [0.09566690027713776], learning rate: 0.0100000000
Iteration 505000: total loss nan, losses: [nan], learning rate: 0.0097029900
Iteration 505000: total loss 0.0682, losses: [0.06820112466812134], learning rate: 0.0097029900
Iteration 320000: total loss 0.0701, losses: [0.07011525332927704], learning rate: 0.0100000000
Iteration 320000: total loss 0.0684, losses: [0.06836733967065811], learning rate: 0.0100000000
Val loss  tensor(0.9131)
Val loss  tensor(1.1988)
Iteration 510000: total loss nan, losses: [nan], learning rate: 0.0097029900
Iteration 510000: total loss 0.0618, losses: [0.06180374324321747], learning rate: 0.0097029900
Val loss  tensor(nan)
Val loss  tensor(1.5356)
Iteration 325000: total loss 0.0662, losses: [0.06620505452156067], learning rate: 0.0100000000
Iteration 325000: total loss 0.0797, losses: [0.07970601320266724], learning rate: 0.0100000000
Iteration 515000: total loss nan, losses: [nan], learning rate: 0.0097029900
Iteration 515000: total loss 0.0704, losses: [0.07043588161468506], learning rate: 0.0097029900
Iteration 330000: total loss 0.0633, losses: [0.06328928470611572], learning rate: 0.0100000000
Iteration 330000: total loss 0.0800, losses: [0.07999233156442642], learning rate: 0.0100000000
Val loss  tensor(0.7976)
Val loss  tensor(1.0594)
Iteration 520000: total loss nan, losses: [nan], learning rate: 0.0097029900
Iteration 520000: total loss 0.0476, losses: [0.04757138714194298], learning rate: 0.0097029900
Val loss  tensor(nan)
Val loss  tensor(1.5502)
Iteration 335000: total loss 0.0575, losses: [0.05747894197702408], learning rate: 0.0100000000
Iteration 335000: total loss 0.0841, losses: [0.08411253988742828], learning rate: 0.0099000000
Iteration 525000: total loss nan, losses: [nan], learning rate: 0.0097029900
Iteration 525000: total loss 0.0696, losses: [0.06959063559770584], learning rate: 0.0097029900
Iteration 340000: total loss 0.0733, losses: [0.07329662144184113], learning rate: 0.0100000000
Iteration 340000: total loss 0.0657, losses: [0.06565417349338531], learning rate: 0.0099000000
Val loss  tensor(0.8223)
Val loss  tensor(1.1633)
Iteration 530000: total loss nan, losses: [nan], learning rate: 0.0097029900
Iteration 530000: total loss 0.0768, losses: [0.07683368027210236], learning rate: 0.0097029900
Val loss  tensor(nan)
Val loss  tensor(1.5725)
Iteration 535000: total loss nan, losses: [nan], learning rate: 0.0097029900
Iteration 535000: total loss 0.0652, losses: [0.06516507267951965], learning rate: 0.0097029900
Iteration 345000: total loss 0.0600, losses: [0.06002834439277649], learning rate: 0.0100000000
Iteration 345000: total loss 0.0814, losses: [0.0813661515712738], learning rate: 0.0099000000
Iteration 540000: total loss nan, losses: [nan], learning rate: 0.0097029900
Iteration 540000: total loss 0.0670, losses: [0.06697095930576324], learning rate: 0.0097029900
Val loss  tensor(nan)
Val loss  tensor(1.4736)
Iteration 350000: total loss 0.0644, losses: [0.06442141532897949], learning rate: 0.0100000000
Iteration 350000: total loss 0.0736, losses: [0.07362683862447739], learning rate: 0.0099000000
Val loss  tensor(0.7878)
Val loss  tensor(1.2226)
Iteration 545000: total loss nan, losses: [nan], learning rate: 0.0097029900
Iteration 545000: total loss 0.0691, losses: [0.06905683130025864], learning rate: 0.0097029900
Iteration 355000: total loss 0.0656, losses: [0.0655663013458252], learning rate: 0.0099000000
Iteration 355000: total loss 0.0833, losses: [0.08332358300685883], learning rate: 0.0099000000
Iteration 550000: total loss nan, losses: [nan], learning rate: 0.0097029900
Iteration 550000: total loss 0.0626, losses: [0.06257524341344833], learning rate: 0.0097029900
Val loss  tensor(nan)
Val loss  tensor(1.4165)
Iteration 360000: total loss 0.0688, losses: [0.06880931556224823], learning rate: 0.0099000000
Iteration 360000: total loss 0.0729, losses: [0.07291699945926666], learning rate: 0.0099000000
Val loss  tensor(0.8332)
Val loss  tensor(0.9581)
Iteration 555000: total loss nan, losses: [nan], learning rate: 0.0097029900
Iteration 555000: total loss 0.0698, losses: [0.06975208222866058], learning rate: 0.0097029900
Iteration 365000: total loss 0.0496, losses: [0.04957199841737747], learning rate: 0.0099000000
Iteration 365000: total loss 0.0707, losses: [0.07070890069007874], learning rate: 0.0099000000
Iteration 560000: total loss nan, losses: [nan], learning rate: 0.0097029900
Iteration 560000: total loss 0.0686, losses: [0.06860990822315216], learning rate: 0.0097029900
Val loss  tensor(nan)
Val loss  tensor(1.4653)
Iteration 370000: total loss 0.0545, losses: [0.05454894155263901], learning rate: 0.0099000000
Iteration 370000: total loss 0.0812, losses: [0.08119987696409225], learning rate: 0.0099000000
Val loss  tensor(0.7682)
Val loss  tensor(1.0417)
Iteration 565000: total loss nan, losses: [nan], learning rate: 0.0097029900
Iteration 565000: total loss 0.0712, losses: [0.07118062674999237], learning rate: 0.0097029900
Iteration 375000: total loss 0.0669, losses: [0.06686317175626755], learning rate: 0.0099000000
Iteration 375000: total loss 0.0759, losses: [0.07586820423603058], learning rate: 0.0099000000
Iteration 570000: total loss nan, losses: [nan], learning rate: 0.0097029900
Iteration 570000: total loss 0.0677, losses: [0.0676584392786026], learning rate: 0.0097029900
Val loss  tensor(nan)
Val loss  tensor(1.5301)
Iteration 380000: total loss 0.0650, losses: [0.06500168144702911], learning rate: 0.0099000000
Iteration 380000: total loss 0.0810, losses: [0.0810362845659256], learning rate: 0.0099000000
Val loss  tensor(0.7594)
Val loss  tensor(0.9710)
Iteration 575000: total loss nan, losses: [nan], learning rate: 0.0097029900
Iteration 575000: total loss 0.0637, losses: [0.0637321025133133], learning rate: 0.0097029900
Iteration 385000: total loss 0.0642, losses: [0.06416171789169312], learning rate: 0.0099000000
Iteration 385000: total loss 0.0800, losses: [0.07995831966400146], learning rate: 0.0099000000
Iteration 580000: total loss nan, losses: [nan], learning rate: 0.0097029900
Iteration 580000: total loss 0.0623, losses: [0.06229524686932564], learning rate: 0.0097029900
Val loss  tensor(nan)
Val loss  tensor(1.4711)
Iteration 390000: total loss 0.0642, losses: [0.06422111392021179], learning rate: 0.0099000000
Iteration 390000: total loss 0.0702, losses: [0.07017677277326584], learning rate: 0.0099000000
Val loss  tensor(0.7739)
Val loss  tensor(0.9425)
Iteration 585000: total loss nan, losses: [nan], learning rate: 0.0097029900
Iteration 585000: total loss 0.0933, losses: [0.09331247210502625], learning rate: 0.0096059601
Iteration 395000: total loss 0.0810, losses: [0.08100541681051254], learning rate: 0.0099000000
Iteration 395000: total loss 0.0623, losses: [0.0622856505215168], learning rate: 0.0099000000
Iteration 590000: total loss nan, losses: [nan], learning rate: 0.0097029900
Iteration 590000: total loss 0.0612, losses: [0.061171628534793854], learning rate: 0.0096059601
Val loss  tensor(nan)
Val loss  tensor(1.4704)
Iteration 400000: total loss 0.0816, losses: [0.0816015750169754], learning rate: 0.0099000000
Iteration 400000: total loss 0.0779, losses: [0.07788418978452682], learning rate: 0.0099000000
Val loss  tensor(0.8151)
Val loss  tensor(0.8832)
Iteration 595000: total loss nan, losses: [nan], learning rate: 0.0097029900
Iteration 595000: total loss 0.0693, losses: [0.0693332850933075], learning rate: 0.0096059601
Iteration 600000: total loss nan, losses: [nan], learning rate: 0.0097029900
Iteration 600000: total loss 0.0783, losses: [0.0783270001411438], learning rate: 0.0096059601
Val loss  tensor(nan)
Val loss  tensor(1.4523)
Iteration 405000: total loss 0.0636, losses: [0.06356368958950043], learning rate: 0.0099000000
Iteration 405000: total loss 0.0987, losses: [0.09872844815254211], learning rate: 0.0099000000
Iteration 605000: total loss nan, losses: [nan], learning rate: 0.0096059601
Iteration 605000: total loss 0.0731, losses: [0.073055699467659], learning rate: 0.0096059601
Iteration 410000: total loss 0.0691, losses: [0.06909701228141785], learning rate: 0.0099000000
Iteration 410000: total loss 0.0690, losses: [0.06899333000183105], learning rate: 0.0099000000
Val loss  tensor(0.6846)
Val loss  tensor(0.9106)
Iteration 610000: total loss nan, losses: [nan], learning rate: 0.0096059601
Iteration 610000: total loss 0.0672, losses: [0.06716775894165039], learning rate: 0.0096059601
Val loss  tensor(nan)
Val loss  tensor(1.4414)
Iteration 415000: total loss 0.0660, losses: [0.06601667404174805], learning rate: 0.0099000000
Iteration 415000: total loss 0.0874, losses: [0.08743355423212051], learning rate: 0.0099000000
Iteration 615000: total loss nan, losses: [nan], learning rate: 0.0096059601
Iteration 615000: total loss 0.0606, losses: [0.06057518720626831], learning rate: 0.0096059601
Iteration 420000: total loss 0.0774, losses: [0.07736369967460632], learning rate: 0.0099000000
Iteration 420000: total loss 0.0714, losses: [0.07135001569986343], learning rate: 0.0099000000
Val loss  tensor(0.7236)
Val loss  tensor(0.9376)
Iteration 620000: total loss nan, losses: [nan], learning rate: 0.0096059601
Iteration 620000: total loss 0.0641, losses: [0.06410849094390869], learning rate: 0.0096059601
Val loss  tensor(nan)
Val loss  tensor(1.4978)
Iteration 425000: total loss 0.0642, losses: [0.06422124058008194], learning rate: 0.0099000000
Iteration 425000: total loss 0.0836, losses: [0.0835791528224945], learning rate: 0.0099000000
Iteration 625000: total loss nan, losses: [nan], learning rate: 0.0096059601
Iteration 625000: total loss 0.0644, losses: [0.06435154378414154], learning rate: 0.0096059601
Iteration 430000: total loss 0.0570, losses: [0.05701127275824547], learning rate: 0.0099000000
Iteration 430000: total loss 0.0846, losses: [0.08456453680992126], learning rate: 0.0099000000
Val loss  tensor(0.7692)
Val loss  tensor(0.9425)
Iteration 630000: total loss nan, losses: [nan], learning rate: 0.0096059601
Iteration 630000: total loss 0.0825, losses: [0.08246347308158875], learning rate: 0.0096059601
Val loss  tensor(nan)
Val loss  tensor(1.3915)
Iteration 435000: total loss 0.0785, losses: [0.07851541042327881], learning rate: 0.0099000000
Iteration 435000: total loss 0.0799, losses: [0.07990828901529312], learning rate: 0.0099000000
Iteration 635000: total loss nan, losses: [nan], learning rate: 0.0096059601
Iteration 635000: total loss 0.0679, losses: [0.06794808804988861], learning rate: 0.0096059601
Iteration 440000: total loss 0.0808, losses: [0.08084945380687714], learning rate: 0.0099000000
Iteration 440000: total loss 0.0720, losses: [0.0719580203294754], learning rate: 0.0099000000
Val loss  tensor(0.9770)
Val loss  tensor(1.0165)
Iteration 640000: total loss nan, losses: [nan], learning rate: 0.0096059601
Iteration 640000: total loss 0.0747, losses: [0.07473598420619965], learning rate: 0.0096059601
Val loss  tensor(nan)
Val loss  tensor(1.4447)
Iteration 445000: total loss 0.0740, losses: [0.073957659304142], learning rate: 0.0099000000
Iteration 445000: total loss 0.0670, losses: [0.06699413061141968], learning rate: 0.0098010000
Iteration 645000: total loss nan, losses: [nan], learning rate: 0.0096059601
Iteration 645000: total loss 0.0796, losses: [0.07958494126796722], learning rate: 0.0096059601
Iteration 450000: total loss 0.0604, losses: [0.060367926955223083], learning rate: 0.0099000000
Iteration 450000: total loss 0.0731, losses: [0.07310093939304352], learning rate: 0.0098010000
Val loss  tensor(0.7509)
Val loss  tensor(0.9576)
Iteration 650000: total loss nan, losses: [nan], learning rate: 0.0096059601
Iteration 650000: total loss 0.0573, losses: [0.05726907029747963], learning rate: 0.0096059601
Val loss  tensor(nan)
Val loss  tensor(1.4931)
Iteration 455000: total loss 0.0815, losses: [0.08146408200263977], learning rate: 0.0099000000
Iteration 455000: total loss 0.0693, losses: [0.06930974125862122], learning rate: 0.0098010000
Iteration 655000: total loss nan, losses: [nan], learning rate: 0.0096059601
Iteration 655000: total loss 0.0615, losses: [0.06149137765169144], learning rate: 0.0096059601
Iteration 460000: total loss 0.0492, losses: [0.04915224015712738], learning rate: 0.0099000000
Iteration 460000: total loss 0.0980, losses: [0.09796179831027985], learning rate: 0.0098010000
Val loss  tensor(0.7229)
Val loss  tensor(0.9551)
Iteration 660000: total loss nan, losses: [nan], learning rate: 0.0096059601
Iteration 660000: total loss 0.0640, losses: [0.06400218605995178], learning rate: 0.0096059601
Val loss  tensor(nan)
Val loss  tensor(1.4326)
Iteration 465000: total loss 0.0652, losses: [0.06522796303033829], learning rate: 0.0098010000
Iteration 465000: total loss 0.0748, losses: [0.07475970685482025], learning rate: 0.0098010000
Iteration 665000: total loss nan, losses: [nan], learning rate: 0.0096059601
Iteration 665000: total loss 0.0672, losses: [0.06716494262218475], learning rate: 0.0096059601
Iteration 470000: total loss 0.0611, losses: [0.061077218502759933], learning rate: 0.0098010000
Iteration 470000: total loss 0.0723, losses: [0.07227520644664764], learning rate: 0.0098010000
Val loss  tensor(0.7557)
Val loss  tensor(0.9460)
Iteration 670000: total loss nan, losses: [nan], learning rate: 0.0096059601
Iteration 670000: total loss 0.0557, losses: [0.05569782108068466], learning rate: 0.0096059601
Val loss  tensor(nan)
Val loss  tensor(1.3623)
Iteration 475000: total loss 0.0625, losses: [0.06245703250169754], learning rate: 0.0098010000
Iteration 475000: total loss 0.0792, losses: [0.07919631898403168], learning rate: 0.0098010000
Iteration 675000: total loss nan, losses: [nan], learning rate: 0.0096059601
Iteration 675000: total loss 0.0607, losses: [0.06072024628520012], learning rate: 0.0096059601
Iteration 680000: total loss nan, losses: [nan], learning rate: 0.0096059601
Iteration 680000: total loss 0.0543, losses: [0.054273590445518494], learning rate: 0.0096059601
Val loss  tensor(nan)
Val loss  tensor(1.4182)
Iteration 480000: total loss 0.0637, losses: [0.063652403652668], learning rate: 0.0098010000
Iteration 480000: total loss 0.0839, losses: [0.08392062038183212], learning rate: 0.0098010000
Val loss  tensor(0.6927)
Val loss  tensor(0.9299)
Iteration 685000: total loss nan, losses: [nan], learning rate: 0.0096059601
Iteration 685000: total loss 0.0664, losses: [0.06638438254594803], learning rate: 0.0096059601
Iteration 485000: total loss 0.0640, losses: [0.06398552656173706], learning rate: 0.0098010000
Iteration 485000: total loss 0.0816, losses: [0.08157849311828613], learning rate: 0.0098010000
Iteration 690000: total loss nan, losses: [nan], learning rate: 0.0096059601
Iteration 690000: total loss 0.0621, losses: [0.06211042404174805], learning rate: 0.0096059601
Val loss  tensor(nan)
Val loss  tensor(1.3929)
Iteration 490000: total loss 0.0659, losses: [0.0658843144774437], learning rate: 0.0098010000
Iteration 490000: total loss 0.0644, losses: [0.06442590057849884], learning rate: 0.0098010000
Val loss  tensor(0.7134)
Val loss  tensor(1.0358)
Iteration 695000: total loss nan, losses: [nan], learning rate: 0.0096059601
Iteration 695000: total loss 0.0595, losses: [0.059468790888786316], learning rate: 0.0095099005
Iteration 495000: total loss 0.0631, losses: [0.06306996941566467], learning rate: 0.0098010000
Iteration 495000: total loss 0.0650, losses: [0.06497655063867569], learning rate: 0.0098010000
Iteration 700000: total loss nan, losses: [nan], learning rate: 0.0096059601
Iteration 700000: total loss 0.0536, losses: [0.05363230034708977], learning rate: 0.0095099005
Val loss  tensor(nan)
Val loss  tensor(1.4083)
Iteration 500000: total loss 0.0580, losses: [0.05804626643657684], learning rate: 0.0098010000
Iteration 500000: total loss 0.0647, losses: [0.06469426304101944], learning rate: 0.0098010000
Val loss  tensor(0.6400)
Val loss  tensor(1.0015)
Iteration 705000: total loss nan, losses: [nan], learning rate: 0.0096059601
Iteration 705000: total loss 0.0679, losses: [0.06787469983100891], learning rate: 0.0095099005
Iteration 505000: total loss 0.0537, losses: [0.05365455895662308], learning rate: 0.0098010000
Iteration 505000: total loss 0.0823, losses: [0.08227094262838364], learning rate: 0.0098010000
Iteration 710000: total loss nan, losses: [nan], learning rate: 0.0096059601
Iteration 710000: total loss 0.0588, losses: [0.058773502707481384], learning rate: 0.0095099005
Val loss  tensor(nan)
Val loss  tensor(1.3849)
Iteration 510000: total loss 0.0682, losses: [0.06824210286140442], learning rate: 0.0098010000
Iteration 510000: total loss 0.0592, losses: [0.05921710282564163], learning rate: 0.0098010000
Val loss  tensor(0.7372)
Val loss  tensor(1.0370)
Iteration 715000: total loss nan, losses: [nan], learning rate: 0.0095099005
Iteration 715000: total loss 0.0676, losses: [0.06764659285545349], learning rate: 0.0095099005
Iteration 515000: total loss 0.0837, losses: [0.08371638506650925], learning rate: 0.0098010000
Iteration 515000: total loss 0.0729, losses: [0.07287438958883286], learning rate: 0.0098010000
Iteration 720000: total loss nan, losses: [nan], learning rate: 0.0095099005
Iteration 720000: total loss 0.0608, losses: [0.06081336364150047], learning rate: 0.0095099005
Val loss  tensor(nan)
Val loss  tensor(1.3815)
Iteration 520000: total loss 0.0574, losses: [0.057386331260204315], learning rate: 0.0098010000
Iteration 520000: total loss 0.0781, losses: [0.07809009402990341], learning rate: 0.0098010000
Val loss  tensor(0.6914)
Val loss  tensor(0.9104)
Iteration 725000: total loss nan, losses: [nan], learning rate: 0.0095099005
Iteration 725000: total loss 0.0746, losses: [0.07456614077091217], learning rate: 0.0095099005
Iteration 525000: total loss 0.0711, losses: [0.07111889868974686], learning rate: 0.0098010000
Iteration 525000: total loss 0.0847, losses: [0.0847090408205986], learning rate: 0.0098010000
Iteration 730000: total loss nan, losses: [nan], learning rate: 0.0095099005
Iteration 730000: total loss 0.0780, losses: [0.07802769541740417], learning rate: 0.0095099005
Val loss  tensor(nan)
Val loss  tensor(1.3803)
Iteration 530000: total loss 0.0727, losses: [0.0727279931306839], learning rate: 0.0098010000
Iteration 530000: total loss 0.0688, losses: [0.06882847845554352], learning rate: 0.0098010000
Val loss  tensor(0.7667)
Val loss  tensor(0.9416)
Iteration 735000: total loss nan, losses: [nan], learning rate: 0.0095099005
Iteration 735000: total loss 0.0669, losses: [0.06691442430019379], learning rate: 0.0095099005
Iteration 535000: total loss 0.0657, losses: [0.06571599096059799], learning rate: 0.0098010000
Iteration 535000: total loss 0.0535, losses: [0.0535346195101738], learning rate: 0.0098010000
Iteration 740000: total loss nan, losses: [nan], learning rate: 0.0095099005
Iteration 740000: total loss 0.0705, losses: [0.07053015381097794], learning rate: 0.0095099005
Val loss  tensor(nan)
Val loss  tensor(1.3183)
Iteration 540000: total loss 0.0542, losses: [0.054232027381658554], learning rate: 0.0098010000
Iteration 540000: total loss 0.0993, losses: [0.0992787629365921], learning rate: 0.0098010000
Val loss  tensor(0.6661)
Val loss  tensor(0.9757)
Iteration 745000: total loss nan, losses: [nan], learning rate: 0.0095099005
Iteration 745000: total loss 0.0582, losses: [0.05820818245410919], learning rate: 0.0095099005
Iteration 750000: total loss nan, losses: [nan], learning rate: 0.0095099005
Iteration 750000: total loss 0.0680, losses: [0.06803421676158905], learning rate: 0.0095099005
Iteration 545000: total loss 0.0611, losses: [0.06106595695018768], learning rate: 0.0098010000
Iteration 545000: total loss 0.0781, losses: [0.07805555313825607], learning rate: 0.0098010000
Val loss  tensor(nan)
Val loss  tensor(1.3382)
Iteration 755000: total loss nan, losses: [nan], learning rate: 0.0095099005
Iteration 755000: total loss 0.0659, losses: [0.06590183079242706], learning rate: 0.0095099005
Iteration 550000: total loss 0.0711, losses: [0.07106548547744751], learning rate: 0.0098010000
Iteration 550000: total loss 0.0695, losses: [0.06945142149925232], learning rate: 0.0098010000
Val loss  tensor(0.7111)
Val loss  tensor(0.9368)
Iteration 760000: total loss nan, losses: [nan], learning rate: 0.0095099005
Iteration 760000: total loss 0.0574, losses: [0.05743459239602089], learning rate: 0.0095099005
Val loss  tensor(nan)
Val loss  tensor(1.3089)
Iteration 555000: total loss 0.0703, losses: [0.07029761373996735], learning rate: 0.0098010000
Iteration 555000: total loss 0.0765, losses: [0.07651714980602264], learning rate: 0.0097029900
Iteration 765000: total loss nan, losses: [nan], learning rate: 0.0095099005
Iteration 765000: total loss 0.0679, losses: [0.067875936627388], learning rate: 0.0095099005
Iteration 560000: total loss 0.0604, losses: [0.06036243215203285], learning rate: 0.0098010000
Iteration 560000: total loss 0.0689, losses: [0.06889566034078598], learning rate: 0.0097029900
Val loss  tensor(0.6901)
Val loss  tensor(0.9291)
Iteration 770000: total loss nan, losses: [nan], learning rate: 0.0095099005
Iteration 770000: total loss 0.0683, losses: [0.06831638514995575], learning rate: 0.0095099005
Val loss  tensor(nan)
Val loss  tensor(1.2553)
Iteration 565000: total loss 0.0505, losses: [0.050487250089645386], learning rate: 0.0098010000
Iteration 565000: total loss 0.0671, losses: [0.06709861755371094], learning rate: 0.0097029900
Iteration 775000: total loss nan, losses: [nan], learning rate: 0.0095099005
Iteration 775000: total loss 0.0672, losses: [0.0671645998954773], learning rate: 0.0095099005
Iteration 570000: total loss 0.0575, losses: [0.05752558633685112], learning rate: 0.0098010000
Iteration 570000: total loss 0.0689, losses: [0.06888051331043243], learning rate: 0.0097029900
Val loss  tensor(0.6852)
Val loss  tensor(0.9550)
Iteration 780000: total loss nan, losses: [nan], learning rate: 0.0095099005
Iteration 780000: total loss 0.0552, losses: [0.05517943203449249], learning rate: 0.0095099005
Val loss  tensor(nan)
Val loss  tensor(1.3212)
Iteration 575000: total loss 0.0580, losses: [0.057997290045022964], learning rate: 0.0098010000
Iteration 575000: total loss 0.0805, losses: [0.08051655441522598], learning rate: 0.0097029900
Iteration 785000: total loss nan, losses: [nan], learning rate: 0.0095099005
Iteration 785000: total loss 0.0459, losses: [0.045943502336740494], learning rate: 0.0095099005
Iteration 580000: total loss 0.0558, losses: [0.055822230875492096], learning rate: 0.0098010000
Iteration 580000: total loss 0.0809, losses: [0.08094862103462219], learning rate: 0.0097029900
Val loss  tensor(0.7357)
Val loss  tensor(0.9383)
Iteration 790000: total loss nan, losses: [nan], learning rate: 0.0095099005
Iteration 790000: total loss 0.0537, losses: [0.05369368568062782], learning rate: 0.0095099005
Val loss  tensor(nan)
Val loss  tensor(1.2623)
Iteration 585000: total loss 0.0625, losses: [0.06250811368227005], learning rate: 0.0098010000
Iteration 585000: total loss 0.0858, losses: [0.08575818687677383], learning rate: 0.0097029900
Iteration 795000: total loss nan, losses: [nan], learning rate: 0.0095099005
Iteration 795000: total loss 0.0647, losses: [0.06466784328222275], learning rate: 0.0095099005
Iteration 590000: total loss 0.0545, losses: [0.05453145503997803], learning rate: 0.0098010000
Iteration 590000: total loss 0.0692, losses: [0.06922312080860138], learning rate: 0.0097029900
Val loss  tensor(0.7358)
Val loss  tensor(0.9682)
Iteration 800000: total loss nan, losses: [nan], learning rate: 0.0095099005
Iteration 800000: total loss 0.0525, losses: [0.05252232030034065], learning rate: 0.0095099005
Val loss  tensor(nan)
Val loss  tensor(1.1826)
Iteration 595000: total loss 0.0622, losses: [0.06223033368587494], learning rate: 0.0098010000
Iteration 595000: total loss 0.0608, losses: [0.06084360182285309], learning rate: 0.0097029900
Iteration 805000: total loss nan, losses: [nan], learning rate: 0.0095099005
Iteration 805000: total loss 0.0668, losses: [0.06680391728878021], learning rate: 0.0094148015
Iteration 810000: total loss nan, losses: [nan], learning rate: 0.0095099005
Iteration 810000: total loss 0.0527, losses: [0.05273623391985893], learning rate: 0.0094148015
Iteration 600000: total loss 0.0671, losses: [0.06711289286613464], learning rate: 0.0098010000
Iteration 600000: total loss 0.0658, losses: [0.06577238440513611], learning rate: 0.0097029900
Val loss  tensor(nan)
Val loss  tensor(1.2155)
Val loss  tensor(0.6758)
Val loss  tensor(0.9218)
Iteration 815000: total loss nan, losses: [nan], learning rate: 0.0095099005
Iteration 815000: total loss 0.0661, losses: [0.06606647372245789], learning rate: 0.0094148015
Iteration 605000: total loss 0.0635, losses: [0.06352876126766205], learning rate: 0.0098010000
Iteration 605000: total loss 0.0603, losses: [0.0603208914399147], learning rate: 0.0097029900
Iteration 820000: total loss nan, losses: [nan], learning rate: 0.0095099005
Iteration 820000: total loss 0.0704, losses: [0.07039868831634521], learning rate: 0.0094148015
Val loss  tensor(nan)
Val loss  tensor(1.1169)
Iteration 610000: total loss 0.0612, losses: [0.06124497950077057], learning rate: 0.0098010000
Iteration 610000: total loss 0.0661, losses: [0.066134512424469], learning rate: 0.0097029900
Val loss  tensor(0.7823)
Val loss  tensor(0.9341)
Iteration 825000: total loss nan, losses: [nan], learning rate: 0.0094148015
Iteration 825000: total loss 0.0633, losses: [0.06328665465116501], learning rate: 0.0094148015
Iteration 615000: total loss 0.0496, losses: [0.04958925396203995], learning rate: 0.0097029900
Iteration 615000: total loss 0.0675, losses: [0.06749460101127625], learning rate: 0.0097029900
Iteration 830000: total loss nan, losses: [nan], learning rate: 0.0094148015
Iteration 830000: total loss 0.0614, losses: [0.06143305450677872], learning rate: 0.0094148015
Val loss  tensor(nan)
Val loss  tensor(1.1598)
Iteration 620000: total loss 0.0614, losses: [0.061383526772260666], learning rate: 0.0097029900
Iteration 620000: total loss 0.0628, losses: [0.0627976506948471], learning rate: 0.0097029900
Val loss  tensor(0.6693)
Val loss  tensor(0.9347)
Iteration 835000: total loss nan, losses: [nan], learning rate: 0.0094148015
Iteration 835000: total loss 0.0579, losses: [0.057915203273296356], learning rate: 0.0094148015
Iteration 625000: total loss 0.0685, losses: [0.06853228062391281], learning rate: 0.0097029900
Iteration 625000: total loss 0.0811, losses: [0.08110985159873962], learning rate: 0.0097029900
Iteration 840000: total loss nan, losses: [nan], learning rate: 0.0094148015
Iteration 840000: total loss 0.0609, losses: [0.060878753662109375], learning rate: 0.0094148015
Val loss  tensor(nan)
Val loss  tensor(1.1632)
Iteration 630000: total loss 0.0615, losses: [0.06145515292882919], learning rate: 0.0097029900
Iteration 630000: total loss 0.0574, losses: [0.057421714067459106], learning rate: 0.0097029900
Val loss  tensor(0.7711)
Val loss  tensor(0.8793)
Iteration 845000: total loss nan, losses: [nan], learning rate: 0.0094148015
Iteration 845000: total loss 0.0584, losses: [0.05836154520511627], learning rate: 0.0094148015
Iteration 635000: total loss 0.0598, losses: [0.05976841598749161], learning rate: 0.0097029900
Iteration 635000: total loss 0.0751, losses: [0.07512564957141876], learning rate: 0.0097029900
Iteration 850000: total loss nan, losses: [nan], learning rate: 0.0094148015
Iteration 850000: total loss 0.0626, losses: [0.06258047372102737], learning rate: 0.0094148015
Val loss  tensor(nan)
Val loss  tensor(1.1866)
Iteration 640000: total loss 0.0610, losses: [0.06100085377693176], learning rate: 0.0097029900
Iteration 640000: total loss 0.0802, losses: [0.08019539713859558], learning rate: 0.0097029900
Val loss  tensor(0.7509)
Val loss  tensor(0.9122)
Iteration 855000: total loss nan, losses: [nan], learning rate: 0.0094148015
Iteration 855000: total loss 0.0589, losses: [0.058882612735033035], learning rate: 0.0094148015
Iteration 645000: total loss 0.0519, losses: [0.05187402665615082], learning rate: 0.0097029900
Iteration 645000: total loss 0.0564, losses: [0.0564417839050293], learning rate: 0.0097029900
Iteration 860000: total loss nan, losses: [nan], learning rate: 0.0094148015
Iteration 860000: total loss 0.0528, losses: [0.05284849554300308], learning rate: 0.0094148015
Val loss  tensor(nan)
Val loss  tensor(1.1347)
Iteration 650000: total loss 0.0738, losses: [0.07380005717277527], learning rate: 0.0097029900
Iteration 650000: total loss 0.0642, losses: [0.06418803334236145], learning rate: 0.0097029900
Val loss  tensor(0.7247)
Val loss  tensor(0.9027)
Iteration 865000: total loss nan, losses: [nan], learning rate: 0.0094148015
Iteration 865000: total loss 0.0642, losses: [0.06421796977519989], learning rate: 0.0094148015
Iteration 655000: total loss 0.0540, losses: [0.054015930742025375], learning rate: 0.0097029900
Iteration 655000: total loss 0.0689, losses: [0.0688539370894432], learning rate: 0.0097029900
Iteration 870000: total loss nan, losses: [nan], learning rate: 0.0094148015
Iteration 870000: total loss 0.0634, losses: [0.06342879682779312], learning rate: 0.0094148015
Val loss  tensor(nan)
Val loss  tensor(1.1110)
Iteration 660000: total loss 0.0485, losses: [0.04847143962979317], learning rate: 0.0097029900
Iteration 660000: total loss 0.0846, losses: [0.08455100655555725], learning rate: 0.0097029900
Iteration 875000: total loss nan, losses: [nan], learning rate: 0.0094148015
Iteration 875000: total loss 0.0557, losses: [0.0556551069021225], learning rate: 0.0094148015
Val loss  tensor(0.7044)
Val loss  tensor(0.8536)
Iteration 880000: total loss nan, losses: [nan], learning rate: 0.0094148015
Iteration 880000: total loss 0.0681, losses: [0.06805126368999481], learning rate: 0.0094148015
Val loss  tensor(nan)
Val loss  tensor(1.1439)
Iteration 665000: total loss 0.0640, losses: [0.06404867768287659], learning rate: 0.0097029900
Iteration 665000: total loss 0.0760, losses: [0.07601602375507355], learning rate: 0.0096059601
Iteration 885000: total loss nan, losses: [nan], learning rate: 0.0094148015
Iteration 885000: total loss 0.0639, losses: [0.06386251747608185], learning rate: 0.0094148015
Iteration 670000: total loss 0.0556, losses: [0.055572208017110825], learning rate: 0.0097029900
Iteration 670000: total loss 0.0649, losses: [0.06487831473350525], learning rate: 0.0096059601
Val loss  tensor(0.7374)
Val loss  tensor(0.8704)
Iteration 890000: total loss nan, losses: [nan], learning rate: 0.0094148015
Iteration 890000: total loss 0.0642, losses: [0.06420925259590149], learning rate: 0.0094148015
Val loss  tensor(nan)
Val loss  tensor(1.1198)
Iteration 675000: total loss 0.0582, losses: [0.0582457110285759], learning rate: 0.0097029900
Iteration 675000: total loss 0.0780, losses: [0.07799690961837769], learning rate: 0.0096059601
Iteration 895000: total loss nan, losses: [nan], learning rate: 0.0094148015
Iteration 895000: total loss 0.0643, losses: [0.06430443376302719], learning rate: 0.0094148015
Iteration 680000: total loss 0.0608, losses: [0.06076889485120773], learning rate: 0.0097029900
Iteration 680000: total loss 0.0736, losses: [0.07356680929660797], learning rate: 0.0096059601
Val loss  tensor(0.6976)
Val loss  tensor(0.8521)
Iteration 900000: total loss nan, losses: [nan], learning rate: 0.0094148015
Iteration 900000: total loss 0.0582, losses: [0.05820688605308533], learning rate: 0.0094148015
Val loss  tensor(nan)
Val loss  tensor(1.1022)
Iteration 685000: total loss 0.0555, losses: [0.05551739037036896], learning rate: 0.0097029900
Iteration 685000: total loss 0.0550, losses: [0.05497371032834053], learning rate: 0.0096059601
Iteration 905000: total loss nan, losses: [nan], learning rate: 0.0094148015
Iteration 905000: total loss 0.0567, losses: [0.056695517152547836], learning rate: 0.0094148015
Iteration 690000: total loss 0.0623, losses: [0.062320224940776825], learning rate: 0.0097029900
Iteration 690000: total loss 0.0765, losses: [0.07651057839393616], learning rate: 0.0096059601
Val loss  tensor(0.8026)
Val loss  tensor(0.9030)
Iteration 910000: total loss nan, losses: [nan], learning rate: 0.0094148015
Iteration 910000: total loss 0.0592, losses: [0.05923733487725258], learning rate: 0.0094148015
Val loss  tensor(nan)
Val loss  tensor(1.0670)
Iteration 695000: total loss 0.0581, losses: [0.05810628831386566], learning rate: 0.0097029900
Iteration 695000: total loss 0.0625, losses: [0.06251849234104156], learning rate: 0.0096059601
Iteration 915000: total loss nan, losses: [nan], learning rate: 0.0094148015
Iteration 915000: total loss 0.0619, losses: [0.06190598011016846], learning rate: 0.0093206535
Iteration 700000: total loss 0.0699, losses: [0.06987057626247406], learning rate: 0.0097029900
Iteration 700000: total loss 0.0653, losses: [0.06534980982542038], learning rate: 0.0096059601
Val loss  tensor(0.8253)
Val loss  tensor(0.9125)
Iteration 920000: total loss nan, losses: [nan], learning rate: 0.0094148015
Iteration 920000: total loss 0.0654, losses: [0.06538178026676178], learning rate: 0.0093206535
Val loss  tensor(nan)
Val loss  tensor(1.0921)
Iteration 705000: total loss 0.0581, losses: [0.058123327791690826], learning rate: 0.0097029900
Iteration 705000: total loss 0.0851, losses: [0.08509449660778046], learning rate: 0.0096059601
Iteration 925000: total loss nan, losses: [nan], learning rate: 0.0094148015
Iteration 925000: total loss 0.0680, losses: [0.06795310974121094], learning rate: 0.0093206535
Iteration 710000: total loss 0.0606, losses: [0.060584165155887604], learning rate: 0.0097029900
Iteration 710000: total loss 0.0508, losses: [0.05083402991294861], learning rate: 0.0096059601
Val loss  tensor(0.6671)
Val loss  tensor(0.9106)
Iteration 930000: total loss nan, losses: [nan], learning rate: 0.0094148015
Iteration 930000: total loss 0.0541, losses: [0.05406041443347931], learning rate: 0.0093206535
Val loss  tensor(nan)
Val loss  tensor(1.0154)
Iteration 715000: total loss 0.0591, losses: [0.05907510593533516], learning rate: 0.0097029900
Iteration 715000: total loss 0.0662, losses: [0.06617214530706406], learning rate: 0.0096059601
Iteration 935000: total loss nan, losses: [nan], learning rate: 0.0093206535
Iteration 935000: total loss 0.0602, losses: [0.06019141897559166], learning rate: 0.0093206535
Iteration 720000: total loss 0.0501, losses: [0.05005950480699539], learning rate: 0.0097029900
Iteration 720000: total loss 0.0632, losses: [0.06324884295463562], learning rate: 0.0096059601
Val loss  tensor(0.6708)
Val loss  tensor(0.9282)
Iteration 940000: total loss nan, losses: [nan], learning rate: 0.0093206535
Iteration 940000: total loss 0.0577, losses: [0.05770941078662872], learning rate: 0.0093206535
Val loss  tensor(nan)
Val loss  tensor(1.0856)
Iteration 725000: total loss 0.0550, losses: [0.05496741831302643], learning rate: 0.0096059601
Iteration 725000: total loss 0.0725, losses: [0.07246111333370209], learning rate: 0.0096059601
Iteration 945000: total loss nan, losses: [nan], learning rate: 0.0093206535
Iteration 945000: total loss 0.0682, losses: [0.06818707287311554], learning rate: 0.0093206535
Iteration 950000: total loss nan, losses: [nan], learning rate: 0.0093206535
Iteration 950000: total loss 0.0725, losses: [0.07254724204540253], learning rate: 0.0093206535
Val loss  tensor(nan)
Val loss  tensor(1.1227)
Iteration 730000: total loss 0.0784, losses: [0.07842989265918732], learning rate: 0.0096059601
Iteration 730000: total loss 0.0521, losses: [0.05207192897796631], learning rate: 0.0096059601
Val loss  tensor(0.7270)
Val loss  tensor(0.8575)
Iteration 955000: total loss nan, losses: [nan], learning rate: 0.0093206535
Iteration 955000: total loss 0.0710, losses: [0.07103558629751205], learning rate: 0.0093206535
Iteration 735000: total loss 0.0628, losses: [0.06281831860542297], learning rate: 0.0096059601
Iteration 735000: total loss 0.0640, losses: [0.06400196254253387], learning rate: 0.0096059601
Iteration 960000: total loss nan, losses: [nan], learning rate: 0.0093206535
Iteration 960000: total loss 0.0652, losses: [0.06516557931900024], learning rate: 0.0093206535
Val loss  tensor(nan)
Val loss  tensor(1.0283)
Iteration 740000: total loss 0.0625, losses: [0.06248244643211365], learning rate: 0.0096059601
Iteration 740000: total loss 0.0630, losses: [0.06295057386159897], learning rate: 0.0096059601
Val loss  tensor(0.6890)
Val loss  tensor(0.8584)
Iteration 965000: total loss nan, losses: [nan], learning rate: 0.0093206535
Iteration 965000: total loss 0.0566, losses: [0.05664413049817085], learning rate: 0.0093206535
Iteration 745000: total loss 0.0620, losses: [0.06199809908866882], learning rate: 0.0096059601
Iteration 745000: total loss 0.0492, losses: [0.049247290939092636], learning rate: 0.0096059601
Iteration 970000: total loss nan, losses: [nan], learning rate: 0.0093206535
Iteration 970000: total loss 0.0476, losses: [0.047586534172296524], learning rate: 0.0093206535
Val loss  tensor(nan)
Val loss  tensor(1.0801)
Iteration 750000: total loss 0.0694, losses: [0.06939047574996948], learning rate: 0.0096059601
Iteration 750000: total loss 0.0529, losses: [0.05288311839103699], learning rate: 0.0096059601
Val loss  tensor(0.7931)
Val loss  tensor(0.8247)
Iteration 975000: total loss nan, losses: [nan], learning rate: 0.0093206535
Iteration 975000: total loss 0.0473, losses: [0.0473468154668808], learning rate: 0.0093206535
Iteration 755000: total loss 0.0507, losses: [0.050662338733673096], learning rate: 0.0096059601
Iteration 755000: total loss 0.0680, losses: [0.06798864901065826], learning rate: 0.0096059601
Iteration 980000: total loss nan, losses: [nan], learning rate: 0.0093206535
Iteration 980000: total loss 0.0639, losses: [0.06388676911592484], learning rate: 0.0093206535
Val loss  tensor(nan)
Val loss  tensor(1.1177)
Iteration 760000: total loss 0.0603, losses: [0.06028946861624718], learning rate: 0.0096059601
Iteration 760000: total loss 0.0690, losses: [0.06897754967212677], learning rate: 0.0096059601
Val loss  tensor(0.7898)
Val loss  tensor(0.9083)
Iteration 985000: total loss nan, losses: [nan], learning rate: 0.0093206535
Iteration 985000: total loss 0.0604, losses: [0.06038777530193329], learning rate: 0.0093206535
Iteration 765000: total loss 0.0567, losses: [0.05668307840824127], learning rate: 0.0096059601
Iteration 765000: total loss 0.0684, losses: [0.06842131167650223], learning rate: 0.0096059601
Iteration 990000: total loss nan, losses: [nan], learning rate: 0.0093206535
Iteration 990000: total loss 0.0545, losses: [0.054541558027267456], learning rate: 0.0093206535
Val loss  tensor(nan)
Val loss  tensor(1.0993)
Iteration 770000: total loss 0.0555, losses: [0.05547711253166199], learning rate: 0.0096059601
Iteration 770000: total loss 0.0528, losses: [0.05279117077589035], learning rate: 0.0096059601
Val loss  tensor(0.6754)
Val loss  tensor(0.8373)
Iteration 995000: total loss nan, losses: [nan], learning rate: 0.0093206535
Iteration 995000: total loss 0.0491, losses: [0.049120791256427765], learning rate: 0.0093206535
Iteration 775000: total loss 0.0576, losses: [0.05763369798660278], learning rate: 0.0096059601
Iteration 775000: total loss 0.0574, losses: [0.05735998600721359], learning rate: 0.0095099005
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=32, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=32, out_features=32, bias=True)
    (3): SiLU()
    (4): Linear(in_features=32, out_features=2, bias=True)
  )
)
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=32, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=32, out_features=64, bias=True)
    (3): SiLU()
    (4): Linear(in_features=64, out_features=2, bias=True)
  )
)
cuda:0
cuda:0
Folder already there
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=32, bias=True)
    (1): SiLU()
    (2): Linear(in_features=32, out_features=32, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=32, out_features=2, bias=True)
  )
)
Folder already there
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=64, bias=True)
    (1): SiLU()
    (2): Linear(in_features=64, out_features=32, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=32, out_features=2, bias=True)
  )
)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
Iteration 0: total loss 2.4240, losses: [2.424030303955078], learning rate: 0.0100000000
Iteration 0: total loss 2.4916, losses: [2.4915521144866943], learning rate: 0.0100000000
Val loss  tensor(1.2542)
Val loss  tensor(1.3919)
Iteration 780000: total loss 0.0482, losses: [0.048244260251522064], learning rate: 0.0096059601
Iteration 780000: total loss 0.0749, losses: [0.07487024366855621], learning rate: 0.0095099005
Val loss  tensor(0.7378)
Val loss  tensor(0.8398)
Iteration 5000: total loss 0.2093, losses: [0.2092808485031128], learning rate: 0.0100000000
Iteration 5000: total loss 0.2628, losses: [0.2627660632133484], learning rate: 0.0100000000
Iteration 785000: total loss 0.0615, losses: [0.06145224720239639], learning rate: 0.0096059601
Iteration 785000: total loss 0.0783, losses: [0.07830643653869629], learning rate: 0.0095099005
Iteration 790000: total loss 0.0567, losses: [0.056657418608665466], learning rate: 0.0096059601
Iteration 790000: total loss 0.0710, losses: [0.07101310789585114], learning rate: 0.0095099005
Iteration 10000: total loss 0.1686, losses: [0.16862085461616516], learning rate: 0.0100000000
Iteration 10000: total loss 0.2821, losses: [0.28205400705337524], learning rate: 0.0100000000
Val loss  tensor(0.7088)
Val loss  tensor(0.8792)
Val loss  tensor(2.3283)
Val loss  tensor(1.8728)
Iteration 795000: total loss 0.0708, losses: [0.07076804339885712], learning rate: 0.0096059601
Iteration 795000: total loss 0.0561, losses: [0.05607699975371361], learning rate: 0.0095099005
Iteration 15000: total loss 0.1577, losses: [0.15768635272979736], learning rate: 0.0100000000
Iteration 15000: total loss 0.1961, losses: [0.19608861207962036], learning rate: 0.0100000000
Iteration 800000: total loss 0.0533, losses: [0.05334404110908508], learning rate: 0.0096059601
Iteration 800000: total loss 0.0608, losses: [0.060843758285045624], learning rate: 0.0095099005
Val loss  tensor(0.7694)
Val loss  tensor(0.8637)
Iteration 20000: total loss 0.1623, losses: [0.16226401925086975], learning rate: 0.0100000000
Iteration 20000: total loss 0.1534, losses: [0.1533907651901245], learning rate: 0.0100000000
Val loss  tensor(2.0573)
Val loss  tensor(1.2005)
Iteration 805000: total loss 0.0600, losses: [0.06001277267932892], learning rate: 0.0096059601
Iteration 805000: total loss 0.0500, losses: [0.04997842758893967], learning rate: 0.0095099005
Iteration 25000: total loss 0.1559, losses: [0.15587694942951202], learning rate: 0.0100000000
Iteration 25000: total loss 0.1528, losses: [0.15283885598182678], learning rate: 0.0100000000
Iteration 810000: total loss 0.0565, losses: [0.05647914856672287], learning rate: 0.0096059601
Iteration 810000: total loss 0.0521, losses: [0.05213106423616409], learning rate: 0.0095099005
Val loss  tensor(0.6887)
Val loss  tensor(0.8472)
Iteration 30000: total loss 0.1301, losses: [0.13014887273311615], learning rate: 0.0100000000
Iteration 30000: total loss 0.1618, losses: [0.1617768555879593], learning rate: 0.0100000000
Val loss  tensor(1.3255)
Val loss  tensor(1.1265)
Iteration 815000: total loss 0.0597, losses: [0.059668511152267456], learning rate: 0.0096059601
Iteration 815000: total loss 0.0681, losses: [0.06808260828256607], learning rate: 0.0095099005
Iteration 35000: total loss 0.1208, losses: [0.12083056569099426], learning rate: 0.0100000000
Iteration 35000: total loss 0.2420, losses: [0.2419593632221222], learning rate: 0.0100000000
Iteration 820000: total loss 0.0674, losses: [0.06737907975912094], learning rate: 0.0096059601
Iteration 820000: total loss 0.0739, losses: [0.07394081354141235], learning rate: 0.0095099005
Val loss  tensor(0.8521)
Val loss  tensor(0.8598)
Iteration 40000: total loss 0.1028, losses: [0.10277703404426575], learning rate: 0.0100000000
Iteration 40000: total loss 0.1490, losses: [0.14903785288333893], learning rate: 0.0100000000
Val loss  tensor(0.9385)
Val loss  tensor(1.1631)
Iteration 825000: total loss 0.0695, losses: [0.06949494779109955], learning rate: 0.0096059601
Iteration 825000: total loss 0.0501, losses: [0.050129152834415436], learning rate: 0.0095099005
Iteration 45000: total loss 0.1557, losses: [0.15572383999824524], learning rate: 0.0100000000
Iteration 45000: total loss 0.1197, losses: [0.11965583264827728], learning rate: 0.0100000000
Iteration 830000: total loss 0.0681, losses: [0.06809712946414948], learning rate: 0.0096059601
Iteration 830000: total loss 0.0534, losses: [0.05344792455434799], learning rate: 0.0095099005
Val loss  tensor(0.6388)
Val loss  tensor(0.8357)
Iteration 50000: total loss 0.1500, losses: [0.14995688199996948], learning rate: 0.0100000000
Iteration 50000: total loss 0.1042, losses: [0.10418150573968887], learning rate: 0.0100000000
Val loss  tensor(0.9913)
Val loss  tensor(1.2765)
Iteration 835000: total loss 0.0588, losses: [0.05879171937704086], learning rate: 0.0096059601
Iteration 835000: total loss 0.0711, losses: [0.07114920020103455], learning rate: 0.0095099005
Iteration 55000: total loss 0.0931, losses: [0.09312891215085983], learning rate: 0.0100000000
Iteration 55000: total loss 0.1392, losses: [0.1391901671886444], learning rate: 0.0100000000
Iteration 840000: total loss 0.0552, losses: [0.05521104112267494], learning rate: 0.0096059601
Iteration 840000: total loss 0.0802, losses: [0.08018438518047333], learning rate: 0.0095099005
Val loss  tensor(0.8085)
Val loss  tensor(0.8736)
Iteration 60000: total loss 0.0949, losses: [0.09488914161920547], learning rate: 0.0100000000
Iteration 60000: total loss 0.1185, losses: [0.11849662661552429], learning rate: 0.0100000000
Val loss  tensor(1.2835)
Val loss  tensor(1.0103)
Iteration 845000: total loss 0.0675, losses: [0.06754904985427856], learning rate: 0.0096059601
Iteration 845000: total loss 0.0538, losses: [0.053829729557037354], learning rate: 0.0095099005
Iteration 65000: total loss 0.0898, losses: [0.08984650671482086], learning rate: 0.0100000000
Iteration 65000: total loss 0.1110, losses: [0.11098465323448181], learning rate: 0.0100000000
Iteration 850000: total loss 0.0605, losses: [0.06049874424934387], learning rate: 0.0096059601
Iteration 850000: total loss 0.0691, losses: [0.06913763284683228], learning rate: 0.0095099005
Val loss  tensor(0.7295)
Val loss  tensor(0.8425)
Iteration 70000: total loss 0.1760, losses: [0.1760183423757553], learning rate: 0.0100000000
Iteration 70000: total loss 0.0795, losses: [0.07945956289768219], learning rate: 0.0100000000
Val loss  tensor(1.3318)
Val loss  tensor(1.1258)
Iteration 855000: total loss 0.0685, losses: [0.06852252036333084], learning rate: 0.0096059601
Iteration 855000: total loss 0.0529, losses: [0.05290280282497406], learning rate: 0.0095099005
Iteration 75000: total loss 0.0865, losses: [0.08650051057338715], learning rate: 0.0100000000
Iteration 75000: total loss 0.1410, losses: [0.14100056886672974], learning rate: 0.0100000000
Iteration 860000: total loss 0.0562, losses: [0.05620449036359787], learning rate: 0.0096059601
Iteration 860000: total loss 0.0727, losses: [0.07268908619880676], learning rate: 0.0095099005
Val loss  tensor(0.8149)
Val loss  tensor(0.8228)
Iteration 865000: total loss 0.0628, losses: [0.06279657781124115], learning rate: 0.0096059601
Iteration 865000: total loss 0.0576, losses: [0.05759405717253685], learning rate: 0.0095099005
Iteration 80000: total loss 0.0853, losses: [0.08528570830821991], learning rate: 0.0100000000
Iteration 80000: total loss 0.1445, losses: [0.14450933039188385], learning rate: 0.0100000000
Val loss  tensor(1.3221)
Val loss  tensor(0.8155)
Iteration 870000: total loss 0.0618, losses: [0.061825767159461975], learning rate: 0.0096059601
Iteration 870000: total loss 0.0768, losses: [0.0767822116613388], learning rate: 0.0095099005
Val loss  tensor(0.8170)
Val loss  tensor(0.8706)
Iteration 85000: total loss 0.0824, losses: [0.08236999809741974], learning rate: 0.0100000000
Iteration 85000: total loss 0.1388, losses: [0.13876980543136597], learning rate: 0.0100000000
Iteration 875000: total loss 0.0552, losses: [0.055242881178855896], learning rate: 0.0096059601
Iteration 875000: total loss 0.0776, losses: [0.07764241099357605], learning rate: 0.0095099005
Iteration 90000: total loss 0.0721, losses: [0.07214418053627014], learning rate: 0.0100000000
Iteration 90000: total loss 0.1408, losses: [0.1408417671918869], learning rate: 0.0100000000
Val loss  tensor(1.4947)
Val loss  tensor(1.1457)
Iteration 880000: total loss 0.0545, losses: [0.05453953146934509], learning rate: 0.0096059601
Iteration 880000: total loss 0.0702, losses: [0.07021160423755646], learning rate: 0.0095099005
Val loss  tensor(0.8160)
Val loss  tensor(0.9053)
Iteration 95000: total loss 0.0801, losses: [0.08010801672935486], learning rate: 0.0100000000
Iteration 95000: total loss 0.1091, losses: [0.10914097726345062], learning rate: 0.0100000000
Iteration 885000: total loss 0.0595, losses: [0.05950986593961716], learning rate: 0.0096059601
Iteration 885000: total loss 0.0538, losses: [0.0537799708545208], learning rate: 0.0094148015
Iteration 100000: total loss 0.0856, losses: [0.0855797678232193], learning rate: 0.0100000000
Iteration 100000: total loss 0.1363, losses: [0.13630734384059906], learning rate: 0.0100000000
Val loss  tensor(1.3548)
Val loss  tensor(1.2578)
Iteration 890000: total loss 0.0738, losses: [0.07380882650613785], learning rate: 0.0096059601
Iteration 890000: total loss 0.0668, losses: [0.06680077314376831], learning rate: 0.0094148015
Val loss  tensor(0.7044)
Val loss  tensor(0.8389)
Iteration 105000: total loss 0.0732, losses: [0.07322479784488678], learning rate: 0.0100000000
Iteration 105000: total loss 0.1172, losses: [0.11716847121715546], learning rate: 0.0100000000
Iteration 895000: total loss 0.0533, losses: [0.05333883687853813], learning rate: 0.0096059601
Iteration 895000: total loss 0.0814, losses: [0.08136236667633057], learning rate: 0.0094148015
Iteration 110000: total loss 0.0864, losses: [0.08637365698814392], learning rate: 0.0100000000
Iteration 110000: total loss 0.0997, losses: [0.09969804435968399], learning rate: 0.0100000000
Val loss  tensor(1.3583)
Val loss  tensor(1.3553)
Iteration 900000: total loss 0.0479, losses: [0.0479436032474041], learning rate: 0.0096059601
Iteration 900000: total loss 0.0560, losses: [0.055994804948568344], learning rate: 0.0094148015
Val loss  tensor(0.6995)
Val loss  tensor(0.8346)
Iteration 115000: total loss 0.0918, losses: [0.0917862206697464], learning rate: 0.0100000000
Iteration 115000: total loss 0.1051, losses: [0.10506059974431992], learning rate: 0.0100000000
Iteration 905000: total loss 0.0603, losses: [0.06031167507171631], learning rate: 0.0096059601
Iteration 905000: total loss 0.0681, losses: [0.06806600838899612], learning rate: 0.0094148015
Iteration 120000: total loss 0.0689, losses: [0.06888343393802643], learning rate: 0.0100000000
Iteration 120000: total loss 0.1133, losses: [0.11331579834222794], learning rate: 0.0100000000
Val loss  tensor(1.2171)
Val loss  tensor(1.3155)
Iteration 910000: total loss 0.0692, losses: [0.06915628910064697], learning rate: 0.0096059601
Iteration 910000: total loss 0.0596, losses: [0.05964348465204239], learning rate: 0.0094148015
Val loss  tensor(0.7602)
Val loss  tensor(0.8874)
Iteration 125000: total loss 0.0674, losses: [0.0674038827419281], learning rate: 0.0100000000
Iteration 125000: total loss 0.1265, losses: [0.1264892816543579], learning rate: 0.0100000000
Iteration 915000: total loss 0.0624, losses: [0.06243826448917389], learning rate: 0.0096059601
Iteration 915000: total loss 0.0658, losses: [0.06577453017234802], learning rate: 0.0094148015
Iteration 920000: total loss 0.0464, losses: [0.04640049487352371], learning rate: 0.0096059601
Iteration 920000: total loss 0.0551, losses: [0.05511854588985443], learning rate: 0.0094148015
Val loss  tensor(0.7441)
Val loss  tensor(0.8366)
Iteration 130000: total loss 0.0716, losses: [0.07156835496425629], learning rate: 0.0100000000
Iteration 130000: total loss 0.1093, losses: [0.10927028954029083], learning rate: 0.0100000000
Val loss  tensor(1.3274)
Val loss  tensor(1.2094)
Iteration 925000: total loss 0.0561, losses: [0.056115396320819855], learning rate: 0.0096059601
Iteration 925000: total loss 0.0587, losses: [0.05872444063425064], learning rate: 0.0094148015
Iteration 135000: total loss 0.0665, losses: [0.06647175550460815], learning rate: 0.0100000000
Iteration 135000: total loss 0.1272, losses: [0.12721431255340576], learning rate: 0.0100000000
Iteration 930000: total loss 0.0717, losses: [0.07171379029750824], learning rate: 0.0096059601
Iteration 930000: total loss 0.0673, losses: [0.06732018291950226], learning rate: 0.0094148015
Val loss  tensor(0.7104)
Val loss  tensor(0.8187)
Iteration 140000: total loss 0.0697, losses: [0.06971054524183273], learning rate: 0.0100000000
Iteration 140000: total loss 0.1259, losses: [0.1258600801229477], learning rate: 0.0100000000
Val loss  tensor(1.2697)
Val loss  tensor(1.2523)
Iteration 935000: total loss 0.0615, losses: [0.0615340918302536], learning rate: 0.0096059601
Iteration 935000: total loss 0.0613, losses: [0.061347845941782], learning rate: 0.0094148015
Iteration 145000: total loss 0.0705, losses: [0.07049290090799332], learning rate: 0.0100000000
Iteration 145000: total loss 0.0931, losses: [0.09313931316137314], learning rate: 0.0100000000
Iteration 940000: total loss 0.0525, losses: [0.052514899522066116], learning rate: 0.0096059601
Iteration 940000: total loss 0.0635, losses: [0.06351134926080704], learning rate: 0.0094148015
Val loss  tensor(0.9017)
Val loss  tensor(0.8959)
Iteration 150000: total loss 0.0737, losses: [0.07373364269733429], learning rate: 0.0100000000
Iteration 150000: total loss 0.1306, losses: [0.1306360512971878], learning rate: 0.0100000000
Val loss  tensor(1.1763)
Val loss  tensor(1.3507)
Iteration 945000: total loss 0.0578, losses: [0.05776827037334442], learning rate: 0.0095099005
Iteration 945000: total loss 0.0541, losses: [0.05406016856431961], learning rate: 0.0094148015
Iteration 155000: total loss 0.0623, losses: [0.06234663724899292], learning rate: 0.0099000000
Iteration 155000: total loss 0.1117, losses: [0.11170046031475067], learning rate: 0.0100000000
Iteration 950000: total loss 0.0526, losses: [0.052559077739715576], learning rate: 0.0095099005
Iteration 950000: total loss 0.0565, losses: [0.056524090468883514], learning rate: 0.0094148015
Val loss  tensor(0.6966)
Val loss  tensor(0.8871)
Iteration 160000: total loss 0.0672, losses: [0.06724410504102707], learning rate: 0.0099000000
Iteration 160000: total loss 0.1034, losses: [0.10335351526737213], learning rate: 0.0100000000
Val loss  tensor(1.1503)
Val loss  tensor(1.0844)
Iteration 955000: total loss 0.0506, losses: [0.05064810812473297], learning rate: 0.0095099005
Iteration 955000: total loss 0.0677, losses: [0.06772571802139282], learning rate: 0.0094148015
Iteration 165000: total loss 0.0684, losses: [0.06839567422866821], learning rate: 0.0099000000
Iteration 165000: total loss 0.0944, losses: [0.09440366923809052], learning rate: 0.0100000000
Iteration 960000: total loss 0.0449, losses: [0.04493960738182068], learning rate: 0.0095099005
Iteration 960000: total loss 0.0648, losses: [0.06481675058603287], learning rate: 0.0094148015
Val loss  tensor(0.7159)
Val loss  tensor(0.8137)
Iteration 170000: total loss 0.1227, losses: [0.12273131310939789], learning rate: 0.0100000000
Iteration 170000: total loss 0.0629, losses: [0.0628858208656311], learning rate: 0.0099000000
Val loss  tensor(0.9739)
Val loss  tensor(1.1521)
Iteration 965000: total loss 0.0595, losses: [0.05952198803424835], learning rate: 0.0095099005
Iteration 965000: total loss 0.0622, losses: [0.062181126326322556], learning rate: 0.0094148015
Iteration 175000: total loss 0.1086, losses: [0.10861900448799133], learning rate: 0.0100000000
Iteration 175000: total loss 0.0655, losses: [0.06554317474365234], learning rate: 0.0099000000
Iteration 970000: total loss 0.0611, losses: [0.06113128364086151], learning rate: 0.0095099005
Iteration 970000: total loss 0.0519, losses: [0.0518939346075058], learning rate: 0.0094148015
Val loss  tensor(0.8335)
Val loss  tensor(0.8672)
Iteration 180000: total loss 0.0929, losses: [0.0928841382265091], learning rate: 0.0100000000
Iteration 180000: total loss 0.0610, losses: [0.060977280139923096], learning rate: 0.0099000000
Val loss  tensor(0.8576)
Val loss  tensor(1.1755)
Iteration 975000: total loss 0.0618, losses: [0.06177825480699539], learning rate: 0.0095099005
Iteration 975000: total loss 0.0637, losses: [0.06367021054029465], learning rate: 0.0094148015
Iteration 185000: total loss 0.0799, losses: [0.07985301315784454], learning rate: 0.0099000000
Iteration 185000: total loss 0.0899, losses: [0.0898832231760025], learning rate: 0.0100000000
Iteration 980000: total loss 0.0644, losses: [0.06442101299762726], learning rate: 0.0095099005
Iteration 980000: total loss 0.0695, losses: [0.06953646242618561], learning rate: 0.0094148015
Val loss  tensor(0.7565)
Val loss  tensor(0.8907)
Iteration 190000: total loss 0.0595, losses: [0.05948520451784134], learning rate: 0.0099000000
Iteration 190000: total loss 0.1086, losses: [0.10855479538440704], learning rate: 0.0100000000
Val loss  tensor(1.0156)
Val loss  tensor(1.1627)
Iteration 985000: total loss 0.0647, losses: [0.06468093395233154], learning rate: 0.0095099005
Iteration 985000: total loss 0.0622, losses: [0.06220865622162819], learning rate: 0.0094148015
Iteration 990000: total loss 0.0555, losses: [0.05549408495426178], learning rate: 0.0095099005
Iteration 990000: total loss 0.0775, losses: [0.0774780884385109], learning rate: 0.0094148015
Iteration 195000: total loss 0.0545, losses: [0.05450241267681122], learning rate: 0.0099000000
Iteration 195000: total loss 0.0859, losses: [0.08587539196014404], learning rate: 0.0099000000
Val loss  tensor(0.7007)
Val loss  tensor(0.8400)
Iteration 995000: total loss 0.0532, losses: [0.05323862284421921], learning rate: 0.0095099005
Iteration 995000: total loss 0.0599, losses: [0.05986882746219635], learning rate: 0.0093206535
Iteration 200000: total loss 0.0605, losses: [0.0604814849793911], learning rate: 0.0099000000
Iteration 200000: total loss 0.1086, losses: [0.10862934589385986], learning rate: 0.0099000000
Val loss  tensor(1.1849)
Val loss  tensor(0.7945)
Iteration 205000: total loss 0.0668, losses: [0.06682335585355759], learning rate: 0.0099000000
Iteration 205000: total loss 0.0918, losses: [0.09184287488460541], learning rate: 0.0099000000
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=32, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=32, out_features=64, bias=True)
    (3): SiLU()
    (4): Linear(in_features=64, out_features=2, bias=True)
  )
)
cuda:1
Folder already there
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=32, bias=True)
    (1): SiLU()
    (2): Linear(in_features=32, out_features=32, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=32, out_features=2, bias=True)
  )
)
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=64, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=64, out_features=32, bias=True)
    (3): SiLU()
    (4): Linear(in_features=32, out_features=2, bias=True)
  )
)
cuda:1
Folder already there
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=64, bias=True)
    (1): SiLU()
    (2): Linear(in_features=64, out_features=32, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=32, out_features=2, bias=True)
  )
)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
Iteration 0: total loss 2.4937, losses: [2.4936575889587402], learning rate: 0.0100000000
Iteration 0: total loss 2.7570, losses: [2.7570223808288574], learning rate: 0.0100000000
Val loss  tensor(1.3955)
Val loss  tensor(1.4778)
Iteration 210000: total loss 0.0492, losses: [0.04922157898545265], learning rate: 0.0099000000
Iteration 210000: total loss 0.0930, losses: [0.09296490997076035], learning rate: 0.0099000000
Val loss  tensor(1.1787)
Val loss  tensor(0.8820)
Iteration 5000: total loss 0.2727, losses: [0.2726706266403198], learning rate: 0.0100000000
Iteration 5000: total loss 0.2192, losses: [0.21920673549175262], learning rate: 0.0100000000
Iteration 215000: total loss 0.0709, losses: [0.070924773812294], learning rate: 0.0099000000
Iteration 215000: total loss 0.1094, losses: [0.10944433510303497], learning rate: 0.0099000000
Iteration 10000: total loss 0.2561, losses: [0.25610458850860596], learning rate: 0.0100000000
Iteration 10000: total loss 0.1849, losses: [0.1848844587802887], learning rate: 0.0100000000
Val loss  tensor(1.7353)
Val loss  tensor(1.2377)
Iteration 220000: total loss 0.0730, losses: [0.07302844524383545], learning rate: 0.0099000000
Iteration 220000: total loss 0.0839, losses: [0.083903968334198], learning rate: 0.0099000000
Val loss  tensor(1.1507)
Val loss  tensor(0.8688)
Iteration 15000: total loss 0.1746, losses: [0.17455875873565674], learning rate: 0.0100000000
Iteration 15000: total loss 0.1625, losses: [0.16253390908241272], learning rate: 0.0100000000
Iteration 225000: total loss 0.0675, losses: [0.06749308109283447], learning rate: 0.0099000000
Iteration 225000: total loss 0.1003, losses: [0.10030122101306915], learning rate: 0.0099000000
Iteration 20000: total loss 0.1906, losses: [0.19062653183937073], learning rate: 0.0100000000
Iteration 20000: total loss 0.1294, losses: [0.12939079105854034], learning rate: 0.0100000000
Val loss  tensor(0.9738)
Val loss  tensor(1.1190)
Iteration 230000: total loss 0.0682, losses: [0.06822715699672699], learning rate: 0.0099000000
Iteration 230000: total loss 0.1046, losses: [0.1045648381114006], learning rate: 0.0099000000
Val loss  tensor(1.1598)
Val loss  tensor(0.8411)
Iteration 25000: total loss 0.1665, losses: [0.16645637154579163], learning rate: 0.0100000000
Iteration 25000: total loss 0.1270, losses: [0.1270264983177185], learning rate: 0.0100000000
Iteration 235000: total loss 0.0611, losses: [0.061135184019804], learning rate: 0.0099000000
Iteration 235000: total loss 0.1095, losses: [0.10945502668619156], learning rate: 0.0099000000
Iteration 30000: total loss 0.1564, losses: [0.15637356042861938], learning rate: 0.0100000000
Iteration 30000: total loss 0.1018, losses: [0.10184980928897858], learning rate: 0.0100000000
Val loss  tensor(1.0247)
Val loss  tensor(1.0863)
Iteration 240000: total loss 0.0529, losses: [0.052900224924087524], learning rate: 0.0099000000
Iteration 240000: total loss 0.0826, losses: [0.08255431056022644], learning rate: 0.0099000000
Val loss  tensor(1.1283)
Val loss  tensor(0.9978)
Iteration 35000: total loss 0.1439, losses: [0.14394721388816833], learning rate: 0.0100000000
Iteration 35000: total loss 0.1172, losses: [0.1172298863530159], learning rate: 0.0100000000
Iteration 245000: total loss 0.0558, losses: [0.05582956224679947], learning rate: 0.0099000000
Iteration 245000: total loss 0.1136, losses: [0.11357903480529785], learning rate: 0.0099000000
Iteration 40000: total loss 0.1362, losses: [0.136195108294487], learning rate: 0.0100000000
Iteration 40000: total loss 0.1010, losses: [0.10097644478082657], learning rate: 0.0100000000
Val loss  tensor(1.0078)
Val loss  tensor(1.1108)
Iteration 250000: total loss 0.0656, losses: [0.06560659408569336], learning rate: 0.0099000000
Iteration 250000: total loss 0.1078, losses: [0.10776529461145401], learning rate: 0.0099000000
Val loss  tensor(1.1337)
Val loss  tensor(1.0963)
Iteration 45000: total loss 0.1170, losses: [0.11695708334445953], learning rate: 0.0100000000
Iteration 45000: total loss 0.1131, losses: [0.11314208805561066], learning rate: 0.0100000000
Iteration 255000: total loss 0.0641, losses: [0.06409843266010284], learning rate: 0.0099000000
Iteration 255000: total loss 0.0938, losses: [0.09379824995994568], learning rate: 0.0099000000
Iteration 50000: total loss 0.1308, losses: [0.13078269362449646], learning rate: 0.0100000000
Iteration 50000: total loss 0.1080, losses: [0.10796055197715759], learning rate: 0.0100000000
Val loss  tensor(1.1643)
Val loss  tensor(1.1114)
Iteration 260000: total loss 0.0545, losses: [0.054519474506378174], learning rate: 0.0099000000
Iteration 260000: total loss 0.0887, losses: [0.08865833282470703], learning rate: 0.0099000000
Val loss  tensor(1.1462)
Val loss  tensor(0.8887)
Iteration 55000: total loss 0.1037, losses: [0.10369091480970383], learning rate: 0.0100000000
Iteration 55000: total loss 0.1080, losses: [0.10802662372589111], learning rate: 0.0100000000
Iteration 265000: total loss 0.0594, losses: [0.05936545133590698], learning rate: 0.0099000000
Iteration 265000: total loss 0.0830, losses: [0.08304301649332047], learning rate: 0.0099000000
Iteration 60000: total loss 0.1140, losses: [0.11395125091075897], learning rate: 0.0100000000
Iteration 60000: total loss 0.0955, losses: [0.0954737663269043], learning rate: 0.0100000000
Val loss  tensor(1.1313)
Val loss  tensor(1.1619)
Iteration 270000: total loss 0.0654, losses: [0.06543620675802231], learning rate: 0.0099000000
Iteration 270000: total loss 0.1002, losses: [0.10015860944986343], learning rate: 0.0099000000
Val loss  tensor(1.1402)
Val loss  tensor(0.8712)
Iteration 65000: total loss 0.1019, losses: [0.10185939073562622], learning rate: 0.0100000000
Iteration 65000: total loss 0.1030, losses: [0.10297027230262756], learning rate: 0.0100000000
Iteration 275000: total loss 0.0588, losses: [0.05876932293176651], learning rate: 0.0099000000
Iteration 275000: total loss 0.0935, losses: [0.093515545129776], learning rate: 0.0099000000
Iteration 70000: total loss 0.1196, losses: [0.11962611973285675], learning rate: 0.0100000000
Iteration 70000: total loss 0.0925, losses: [0.09254519641399384], learning rate: 0.0100000000
Val loss  tensor(1.1986)
Val loss  tensor(1.0946)
Iteration 280000: total loss 0.0641, losses: [0.06408882141113281], learning rate: 0.0099000000
Iteration 280000: total loss 0.0810, losses: [0.08100821077823639], learning rate: 0.0099000000
Val loss  tensor(1.1017)
Val loss  tensor(0.8540)
Iteration 75000: total loss 0.1261, losses: [0.12606114149093628], learning rate: 0.0100000000
Iteration 75000: total loss 0.1120, losses: [0.11196821928024292], learning rate: 0.0100000000
Iteration 285000: total loss 0.0623, losses: [0.06231498718261719], learning rate: 0.0099000000
Iteration 285000: total loss 0.0996, losses: [0.09956932067871094], learning rate: 0.0099000000
Iteration 80000: total loss 0.1308, losses: [0.13083946704864502], learning rate: 0.0100000000
Iteration 80000: total loss 0.0825, losses: [0.08247749507427216], learning rate: 0.0100000000
Val loss  tensor(1.1447)
Val loss  tensor(1.1172)
Iteration 290000: total loss 0.0658, losses: [0.06582695990800858], learning rate: 0.0099000000
Iteration 290000: total loss 0.0757, losses: [0.07572606950998306], learning rate: 0.0099000000
Val loss  tensor(1.1407)
Val loss  tensor(0.8433)
Iteration 85000: total loss 0.1057, losses: [0.10574522614479065], learning rate: 0.0100000000
Iteration 85000: total loss 0.0881, losses: [0.08812636882066727], learning rate: 0.0100000000
Iteration 295000: total loss 0.0645, losses: [0.06449443101882935], learning rate: 0.0099000000
Iteration 295000: total loss 0.0805, losses: [0.08052127063274384], learning rate: 0.0099000000
Iteration 90000: total loss 0.0798, losses: [0.07981610298156738], learning rate: 0.0100000000
Iteration 90000: total loss 0.0835, losses: [0.08351074904203415], learning rate: 0.0100000000
Val loss  tensor(1.0728)
Val loss  tensor(1.1741)
Iteration 300000: total loss 0.0519, losses: [0.051948174834251404], learning rate: 0.0099000000
Iteration 300000: total loss 0.0798, losses: [0.079839788377285], learning rate: 0.0099000000
Val loss  tensor(1.1086)
Val loss  tensor(0.8503)
Iteration 95000: total loss 0.0894, losses: [0.08937226235866547], learning rate: 0.0100000000
Iteration 95000: total loss 0.0799, losses: [0.07989136874675751], learning rate: 0.0100000000
Iteration 305000: total loss 0.0638, losses: [0.06376442313194275], learning rate: 0.0099000000
Iteration 305000: total loss 0.0925, losses: [0.09246484935283661], learning rate: 0.0099000000
Iteration 100000: total loss 0.0815, losses: [0.08146033436059952], learning rate: 0.0100000000
Iteration 100000: total loss 0.0900, losses: [0.09002053737640381], learning rate: 0.0100000000
Val loss  tensor(1.0351)
Val loss  tensor(1.0609)
Iteration 310000: total loss 0.0519, losses: [0.051904331892728806], learning rate: 0.0099000000
Iteration 310000: total loss 0.0983, losses: [0.09825821220874786], learning rate: 0.0099000000
Val loss  tensor(1.0888)
Val loss  tensor(0.7866)
Iteration 105000: total loss 0.0874, losses: [0.08741317689418793], learning rate: 0.0100000000
Iteration 105000: total loss 0.0965, losses: [0.0964592844247818], learning rate: 0.0100000000
Iteration 315000: total loss 0.0647, losses: [0.06471145153045654], learning rate: 0.0099000000
Iteration 315000: total loss 0.0828, losses: [0.08284978568553925], learning rate: 0.0099000000
Iteration 110000: total loss 0.0773, losses: [0.07731038331985474], learning rate: 0.0100000000
Iteration 110000: total loss 0.0889, losses: [0.08890198171138763], learning rate: 0.0100000000
Val loss  tensor(1.1186)
Val loss  tensor(1.1298)
Iteration 320000: total loss 0.0530, losses: [0.05296005308628082], learning rate: 0.0099000000
Iteration 320000: total loss 0.0878, losses: [0.0878235250711441], learning rate: 0.0099000000
Val loss  tensor(1.0722)
Val loss  tensor(0.7601)
Iteration 115000: total loss 0.0820, losses: [0.08200176060199738], learning rate: 0.0100000000
Iteration 115000: total loss 0.0811, losses: [0.08110198378562927], learning rate: 0.0100000000
Iteration 325000: total loss 0.0626, losses: [0.06262336671352386], learning rate: 0.0099000000
Iteration 325000: total loss 0.0717, losses: [0.07174158096313477], learning rate: 0.0099000000
Iteration 120000: total loss 0.0856, losses: [0.0855962336063385], learning rate: 0.0100000000
Iteration 120000: total loss 0.0758, losses: [0.07578609883785248], learning rate: 0.0100000000
Val loss  tensor(1.2089)
Val loss  tensor(1.0402)
Iteration 330000: total loss 0.0511, losses: [0.0511179193854332], learning rate: 0.0099000000
Iteration 330000: total loss 0.0967, losses: [0.09671636670827866], learning rate: 0.0099000000
Val loss  tensor(1.0805)
Val loss  tensor(0.7851)
Iteration 125000: total loss 0.0880, losses: [0.08797439932823181], learning rate: 0.0100000000
Iteration 125000: total loss 0.0742, losses: [0.0742347463965416], learning rate: 0.0100000000
Iteration 335000: total loss 0.0604, losses: [0.060386352241039276], learning rate: 0.0099000000
Iteration 335000: total loss 0.0995, losses: [0.09946322441101074], learning rate: 0.0099000000
Iteration 130000: total loss 0.0758, losses: [0.07583886384963989], learning rate: 0.0100000000
Iteration 130000: total loss 0.0775, losses: [0.07752180099487305], learning rate: 0.0100000000
Val loss  tensor(1.0881)
Val loss  tensor(1.0708)
Iteration 340000: total loss 0.0525, losses: [0.0524851530790329], learning rate: 0.0099000000
Iteration 340000: total loss 0.0942, losses: [0.09423203766345978], learning rate: 0.0099000000
Val loss  tensor(1.0917)
Val loss  tensor(0.7875)
Iteration 135000: total loss 0.0957, losses: [0.09574234485626221], learning rate: 0.0099000000
Iteration 135000: total loss 0.0780, losses: [0.0780022144317627], learning rate: 0.0100000000
Iteration 345000: total loss 0.0631, losses: [0.0631256178021431], learning rate: 0.0099000000
Iteration 345000: total loss 0.0729, losses: [0.07289527356624603], learning rate: 0.0099000000
Iteration 140000: total loss 0.0859, losses: [0.08587523549795151], learning rate: 0.0099000000
Iteration 140000: total loss 0.0762, losses: [0.07617012411355972], learning rate: 0.0100000000
Val loss  tensor(1.0729)
Val loss  tensor(1.0615)
Iteration 350000: total loss 0.0569, losses: [0.05692702531814575], learning rate: 0.0099000000
Iteration 350000: total loss 0.0926, losses: [0.09259048104286194], learning rate: 0.0099000000
Val loss  tensor(1.0622)
Val loss  tensor(0.9345)
Iteration 145000: total loss 0.0801, losses: [0.08006616681814194], learning rate: 0.0099000000
Iteration 145000: total loss 0.0782, losses: [0.07818663120269775], learning rate: 0.0100000000
Iteration 355000: total loss 0.0533, losses: [0.053270477801561356], learning rate: 0.0099000000
Iteration 355000: total loss 0.0885, losses: [0.08851690590381622], learning rate: 0.0099000000
Iteration 150000: total loss 0.0711, losses: [0.07109083235263824], learning rate: 0.0100000000
Iteration 150000: total loss 0.0774, losses: [0.07738672196865082], learning rate: 0.0099000000
Val loss  tensor(1.0548)
Val loss  tensor(1.0716)
Iteration 360000: total loss 0.0689, losses: [0.06893006712198257], learning rate: 0.0099000000
Iteration 360000: total loss 0.0808, losses: [0.08077682554721832], learning rate: 0.0099000000
Val loss  tensor(0.8319)
Val loss  tensor(1.1127)
Iteration 155000: total loss 0.0805, losses: [0.08049362897872925], learning rate: 0.0099000000
Iteration 155000: total loss 0.0838, losses: [0.08378058671951294], learning rate: 0.0100000000
Iteration 365000: total loss 0.0569, losses: [0.05686410516500473], learning rate: 0.0099000000
Iteration 365000: total loss 0.0804, losses: [0.08043761551380157], learning rate: 0.0099000000
Iteration 160000: total loss 0.0808, losses: [0.08078894019126892], learning rate: 0.0099000000
Iteration 160000: total loss 0.0898, losses: [0.0898427814245224], learning rate: 0.0100000000
Val loss  tensor(1.0862)
Val loss  tensor(1.5931)
Iteration 370000: total loss 0.0583, losses: [0.05827917531132698], learning rate: 0.0099000000
Iteration 370000: total loss 0.0822, losses: [0.08215898275375366], learning rate: 0.0099000000
Val loss  tensor(1.1541)
Val loss  tensor(0.9185)
Iteration 165000: total loss 0.0680, losses: [0.06799793243408203], learning rate: 0.0099000000
Iteration 165000: total loss 0.0761, losses: [0.07605566084384918], learning rate: 0.0100000000
Iteration 375000: total loss 0.0588, losses: [0.058772116899490356], learning rate: 0.0099000000
Iteration 375000: total loss 0.0819, losses: [0.08194205909967422], learning rate: 0.0099000000
Iteration 170000: total loss 0.0844, losses: [0.08442603051662445], learning rate: 0.0099000000
Iteration 170000: total loss 0.0782, losses: [0.07818113267421722], learning rate: 0.0100000000
Val loss  tensor(1.0474)
Val loss  tensor(1.7858)
Iteration 380000: total loss 0.0520, losses: [0.0520235076546669], learning rate: 0.0099000000
Iteration 380000: total loss 0.0818, losses: [0.08182190358638763], learning rate: 0.0099000000
Val loss  tensor(1.0679)
Val loss  tensor(0.8188)
Iteration 175000: total loss 0.0655, losses: [0.06548726558685303], learning rate: 0.0099000000
Iteration 175000: total loss 0.0777, losses: [0.0776578038930893], learning rate: 0.0100000000
Iteration 385000: total loss 0.0522, losses: [0.05223657935857773], learning rate: 0.0099000000
Iteration 385000: total loss 0.0821, losses: [0.082069993019104], learning rate: 0.0099000000
Iteration 180000: total loss 0.0844, losses: [0.08443164825439453], learning rate: 0.0099000000
Iteration 180000: total loss 0.0647, losses: [0.06468763947486877], learning rate: 0.0100000000
Val loss  tensor(1.1032)
Val loss  tensor(1.8650)
Iteration 390000: total loss 0.0481, losses: [0.048065848648548126], learning rate: 0.0099000000
Iteration 390000: total loss 0.0855, losses: [0.0854933112859726], learning rate: 0.0099000000
Val loss  tensor(1.2683)
Val loss  tensor(0.8832)
Iteration 185000: total loss 0.0821, losses: [0.08210544288158417], learning rate: 0.0099000000
Iteration 185000: total loss 0.0802, losses: [0.08024047315120697], learning rate: 0.0100000000
Iteration 395000: total loss 0.0609, losses: [0.06094389408826828], learning rate: 0.0099000000
Iteration 395000: total loss 0.0861, losses: [0.08607827872037888], learning rate: 0.0099000000
Iteration 190000: total loss 0.0745, losses: [0.07454811036586761], learning rate: 0.0099000000
Iteration 190000: total loss 0.0690, losses: [0.06903208792209625], learning rate: 0.0100000000
Val loss  tensor(1.0379)
Val loss  tensor(1.7671)
Iteration 400000: total loss 0.0646, losses: [0.06461457908153534], learning rate: 0.0099000000
Iteration 400000: total loss 0.0900, losses: [0.0899568721652031], learning rate: 0.0099000000
Val loss  tensor(1.1378)
Val loss  tensor(0.8441)
Iteration 195000: total loss 0.0707, losses: [0.07074478268623352], learning rate: 0.0099000000
Iteration 195000: total loss 0.0744, losses: [0.07444453239440918], learning rate: 0.0100000000
Iteration 405000: total loss 0.0540, losses: [0.05404593050479889], learning rate: 0.0099000000
Iteration 405000: total loss 0.0884, losses: [0.08844238519668579], learning rate: 0.0099000000
Iteration 200000: total loss 0.0709, losses: [0.07087010145187378], learning rate: 0.0099000000
Iteration 200000: total loss 0.0697, losses: [0.06971359997987747], learning rate: 0.0100000000
Val loss  tensor(1.0203)
Val loss  tensor(1.6197)
Iteration 410000: total loss 0.0573, losses: [0.05734843388199806], learning rate: 0.0099000000
Iteration 410000: total loss 0.0849, losses: [0.08485148847103119], learning rate: 0.0099000000
Val loss  tensor(0.8406)
Val loss  tensor(1.2048)
Iteration 205000: total loss 0.0721, losses: [0.072055384516716], learning rate: 0.0099000000
Iteration 205000: total loss 0.0727, losses: [0.07273079454898834], learning rate: 0.0100000000
Iteration 415000: total loss 0.0566, losses: [0.05660393089056015], learning rate: 0.0099000000
Iteration 415000: total loss 0.0758, losses: [0.07582738250494003], learning rate: 0.0099000000
Iteration 210000: total loss 0.0637, losses: [0.06373387575149536], learning rate: 0.0099000000
Iteration 210000: total loss 0.0792, losses: [0.07916350662708282], learning rate: 0.0100000000
Val loss  tensor(1.0349)
Val loss  tensor(1.6230)
Iteration 420000: total loss 0.0691, losses: [0.06906335055828094], learning rate: 0.0099000000
Iteration 420000: total loss 0.0990, losses: [0.09904804825782776], learning rate: 0.0099000000
Val loss  tensor(1.2041)
Val loss  tensor(0.8253)
Iteration 215000: total loss 0.0699, losses: [0.06987432390451431], learning rate: 0.0099000000
Iteration 215000: total loss 0.0789, losses: [0.07887990772724152], learning rate: 0.0100000000
Iteration 425000: total loss 0.0494, losses: [0.04943279176950455], learning rate: 0.0099000000
Iteration 425000: total loss 0.0701, losses: [0.07008333504199982], learning rate: 0.0099000000
Iteration 220000: total loss 0.0656, losses: [0.06556058675050735], learning rate: 0.0099000000
Iteration 220000: total loss 0.0722, losses: [0.07218018174171448], learning rate: 0.0100000000
Val loss  tensor(1.0227)
Val loss  tensor(1.9627)
Iteration 430000: total loss 0.0561, losses: [0.05609678104519844], learning rate: 0.0099000000
Iteration 430000: total loss 0.0982, losses: [0.09818421304225922], learning rate: 0.0099000000
Val loss  tensor(1.1103)
Val loss  tensor(0.8241)
Iteration 225000: total loss 0.0688, losses: [0.06883685290813446], learning rate: 0.0099000000
Iteration 225000: total loss 0.0746, losses: [0.07456304132938385], learning rate: 0.0100000000
Iteration 435000: total loss 0.0558, losses: [0.05579613149166107], learning rate: 0.0099000000
Iteration 435000: total loss 0.0720, losses: [0.07197738438844681], learning rate: 0.0098010000
Iteration 230000: total loss 0.0656, losses: [0.06557273864746094], learning rate: 0.0099000000
Iteration 230000: total loss 0.0610, losses: [0.0610036626458168], learning rate: 0.0100000000
Val loss  tensor(0.9904)
Val loss  tensor(1.7894)
Iteration 440000: total loss 0.0817, losses: [0.08171935379505157], learning rate: 0.0098010000
Iteration 440000: total loss 0.0601, losses: [0.060099389404058456], learning rate: 0.0099000000
Val loss  tensor(1.1761)
Val loss  tensor(0.7961)
Iteration 235000: total loss 0.0720, losses: [0.07200036942958832], learning rate: 0.0099000000
Iteration 235000: total loss 0.0808, losses: [0.08077417314052582], learning rate: 0.0100000000
Iteration 445000: total loss 0.0543, losses: [0.05430198460817337], learning rate: 0.0099000000
Iteration 445000: total loss 0.0699, losses: [0.06990265101194382], learning rate: 0.0098010000
Iteration 240000: total loss 0.0525, losses: [0.05247912555932999], learning rate: 0.0099000000
Iteration 240000: total loss 0.0730, losses: [0.07296007871627808], learning rate: 0.0100000000
Val loss  tensor(1.0959)
Val loss  tensor(2.2096)
Iteration 450000: total loss 0.0581, losses: [0.05810412019491196], learning rate: 0.0099000000
Iteration 450000: total loss 0.0814, losses: [0.08142554014921188], learning rate: 0.0098010000
Val loss  tensor(1.2519)
Val loss  tensor(0.8399)
Iteration 245000: total loss 0.0512, losses: [0.05122175067663193], learning rate: 0.0098010000
Iteration 245000: total loss 0.0839, losses: [0.08393418788909912], learning rate: 0.0100000000
Iteration 455000: total loss 0.0539, losses: [0.05392551049590111], learning rate: 0.0099000000
Iteration 455000: total loss 0.0861, losses: [0.0861457884311676], learning rate: 0.0098010000
Iteration 250000: total loss 0.0564, losses: [0.05643624812364578], learning rate: 0.0098010000
Iteration 250000: total loss 0.0596, losses: [0.059641361236572266], learning rate: 0.0100000000
Val loss  tensor(1.0404)
Val loss  tensor(1.9577)
Iteration 460000: total loss 0.0455, losses: [0.04550597071647644], learning rate: 0.0099000000
Iteration 460000: total loss 0.0693, losses: [0.06926499307155609], learning rate: 0.0098010000
Val loss  tensor(1.0746)
Val loss  tensor(0.9930)
Iteration 255000: total loss 0.0613, losses: [0.06127440929412842], learning rate: 0.0098010000
Iteration 255000: total loss 0.0683, losses: [0.06825323402881622], learning rate: 0.0100000000
Iteration 465000: total loss 0.0608, losses: [0.06083247438073158], learning rate: 0.0098010000
Iteration 465000: total loss 0.0685, losses: [0.06854750216007233], learning rate: 0.0098010000
Iteration 260000: total loss 0.0666, losses: [0.06658627837896347], learning rate: 0.0098010000
Iteration 260000: total loss 0.0591, losses: [0.05907237157225609], learning rate: 0.0100000000
Val loss  tensor(0.9795)
Val loss  tensor(2.0832)
Iteration 470000: total loss 0.0473, losses: [0.0472724586725235], learning rate: 0.0098010000
Iteration 470000: total loss 0.0732, losses: [0.07318374514579773], learning rate: 0.0098010000
Val loss  tensor(1.1705)
Val loss  tensor(0.8452)
Iteration 265000: total loss 0.0642, losses: [0.06418885290622711], learning rate: 0.0098010000
Iteration 265000: total loss 0.0784, losses: [0.07840327173471451], learning rate: 0.0099000000
Iteration 475000: total loss 0.0548, losses: [0.054753996431827545], learning rate: 0.0098010000
Iteration 475000: total loss 0.0702, losses: [0.0702129378914833], learning rate: 0.0098010000
Iteration 270000: total loss 0.0569, losses: [0.056911714375019073], learning rate: 0.0098010000
Iteration 270000: total loss 0.0711, losses: [0.0710717961192131], learning rate: 0.0099000000
Val loss  tensor(0.9894)
Val loss  tensor(1.9091)
Iteration 480000: total loss 0.0506, losses: [0.050573449581861496], learning rate: 0.0098010000
Iteration 480000: total loss 0.0682, losses: [0.06815239787101746], learning rate: 0.0098010000
Val loss  tensor(0.8004)
Val loss  tensor(1.0303)
Iteration 275000: total loss 0.0669, losses: [0.06691982597112656], learning rate: 0.0098010000
Iteration 275000: total loss 0.0596, losses: [0.0595596507191658], learning rate: 0.0099000000
Iteration 485000: total loss 0.0539, losses: [0.05390097200870514], learning rate: 0.0098010000
Iteration 485000: total loss 0.0801, losses: [0.08008064329624176], learning rate: 0.0098010000
Iteration 280000: total loss 0.0615, losses: [0.06146489828824997], learning rate: 0.0098010000
Iteration 280000: total loss 0.0532, losses: [0.053224675357341766], learning rate: 0.0099000000
Val loss  tensor(1.0148)
Val loss  tensor(1.3838)
Iteration 490000: total loss 0.0538, losses: [0.05375538766384125], learning rate: 0.0098010000
Iteration 490000: total loss 0.0658, losses: [0.06575718522071838], learning rate: 0.0098010000
Val loss  tensor(1.0119)
Val loss  tensor(0.8253)
Iteration 285000: total loss 0.0614, losses: [0.061432138085365295], learning rate: 0.0098010000
Iteration 285000: total loss 0.0503, losses: [0.050344087183475494], learning rate: 0.0099000000
Iteration 495000: total loss 0.0560, losses: [0.05596747249364853], learning rate: 0.0098010000
Iteration 495000: total loss 0.0870, losses: [0.08700768649578094], learning rate: 0.0098010000
Iteration 290000: total loss 0.0627, losses: [0.06268444657325745], learning rate: 0.0098010000
Iteration 290000: total loss 0.0529, losses: [0.05287481099367142], learning rate: 0.0099000000
Val loss  tensor(1.0690)
Val loss  tensor(1.3697)
Iteration 500000: total loss 0.0415, losses: [0.041539765894412994], learning rate: 0.0098010000
Iteration 500000: total loss 0.0644, losses: [0.06441298127174377], learning rate: 0.0098010000
Val loss  tensor(0.8589)
Val loss  tensor(1.0543)
Iteration 295000: total loss 0.0625, losses: [0.062496937811374664], learning rate: 0.0098010000
Iteration 295000: total loss 0.0507, losses: [0.050684086978435516], learning rate: 0.0099000000
Iteration 505000: total loss 0.0530, losses: [0.053010813891887665], learning rate: 0.0098010000
Iteration 505000: total loss 0.0729, losses: [0.07289665192365646], learning rate: 0.0098010000
Iteration 300000: total loss 0.0732, losses: [0.07321641594171524], learning rate: 0.0098010000
Iteration 300000: total loss 0.0505, losses: [0.05053054541349411], learning rate: 0.0099000000
Val loss  tensor(1.0445)
Val loss  tensor(1.3565)
Iteration 510000: total loss 0.0561, losses: [0.05611278861761093], learning rate: 0.0098010000
Iteration 510000: total loss 0.0743, losses: [0.07434988021850586], learning rate: 0.0098010000
Val loss  tensor(1.4384)
Val loss  tensor(1.1173)
Iteration 305000: total loss 0.0524, losses: [0.05240832641720772], learning rate: 0.0098010000
Iteration 305000: total loss 0.0486, losses: [0.048633866012096405], learning rate: 0.0099000000
Iteration 515000: total loss 0.0482, losses: [0.0482194721698761], learning rate: 0.0098010000
Iteration 515000: total loss 0.0901, losses: [0.0901017114520073], learning rate: 0.0098010000
Iteration 310000: total loss 0.0600, losses: [0.06002046912908554], learning rate: 0.0098010000
Iteration 310000: total loss 0.0519, losses: [0.05194201320409775], learning rate: 0.0099000000
Val loss  tensor(1.0002)
Val loss  tensor(1.2394)
Iteration 520000: total loss 0.0529, losses: [0.05289144068956375], learning rate: 0.0098010000
Iteration 520000: total loss 0.0896, losses: [0.08957324177026749], learning rate: 0.0098010000
Val loss  tensor(1.0695)
Val loss  tensor(1.0441)
Iteration 315000: total loss 0.0611, losses: [0.06107635796070099], learning rate: 0.0098010000
Iteration 315000: total loss 0.0546, losses: [0.054604534059762955], learning rate: 0.0099000000
Iteration 525000: total loss 0.0642, losses: [0.06420843303203583], learning rate: 0.0098010000
Iteration 525000: total loss 0.0538, losses: [0.053798288106918335], learning rate: 0.0098010000
Iteration 320000: total loss 0.0544, losses: [0.05436054617166519], learning rate: 0.0098010000
Iteration 320000: total loss 0.0478, losses: [0.04778332635760307], learning rate: 0.0099000000
Val loss  tensor(1.6254)
Val loss  tensor(1.3338)
Iteration 530000: total loss 0.0512, losses: [0.05122198909521103], learning rate: 0.0098010000
Iteration 530000: total loss 0.0779, losses: [0.07793335616588593], learning rate: 0.0098010000
Val loss  tensor(0.9558)
Val loss  tensor(0.9736)
Iteration 325000: total loss 0.0585, losses: [0.05854644253849983], learning rate: 0.0098010000
Iteration 325000: total loss 0.0465, losses: [0.04648596793413162], learning rate: 0.0099000000
Iteration 535000: total loss 0.0477, losses: [0.04774367809295654], learning rate: 0.0098010000
Iteration 535000: total loss 0.0721, losses: [0.07206267863512039], learning rate: 0.0098010000
Iteration 330000: total loss 0.0621, losses: [0.06205452233552933], learning rate: 0.0098010000
Iteration 330000: total loss 0.0670, losses: [0.06701162457466125], learning rate: 0.0099000000
Val loss  tensor(1.4273)
Val loss  tensor(1.1650)
Iteration 540000: total loss 0.0494, losses: [0.04944678768515587], learning rate: 0.0098010000
Iteration 540000: total loss 0.0863, losses: [0.08633802831172943], learning rate: 0.0098010000
Val loss  tensor(1.0970)
Val loss  tensor(0.9733)
Iteration 335000: total loss 0.0614, losses: [0.061382777988910675], learning rate: 0.0098010000
Iteration 335000: total loss 0.0435, losses: [0.043454017490148544], learning rate: 0.0099000000
Iteration 545000: total loss 0.0941, losses: [0.09413571655750275], learning rate: 0.0097029900
Iteration 545000: total loss 0.0502, losses: [0.050190359354019165], learning rate: 0.0098010000
Iteration 340000: total loss 0.0619, losses: [0.06190627068281174], learning rate: 0.0098010000
Iteration 340000: total loss 0.0467, losses: [0.0466625839471817], learning rate: 0.0099000000
Val loss  tensor(1.6468)
Val loss  tensor(1.3112)
Iteration 550000: total loss 0.0508, losses: [0.05077837407588959], learning rate: 0.0098010000
Iteration 550000: total loss 0.0592, losses: [0.0591980516910553], learning rate: 0.0097029900
Val loss  tensor(0.9248)
Val loss  tensor(1.2871)
Iteration 345000: total loss 0.0609, losses: [0.06086868792772293], learning rate: 0.0098010000
Iteration 345000: total loss 0.0482, losses: [0.04820546507835388], learning rate: 0.0099000000
Iteration 555000: total loss 0.0486, losses: [0.048571690917015076], learning rate: 0.0098010000
Iteration 555000: total loss 0.0771, losses: [0.07707495987415314], learning rate: 0.0097029900
Iteration 350000: total loss 0.0627, losses: [0.06272707879543304], learning rate: 0.0098010000
Iteration 350000: total loss 0.0541, losses: [0.05413343384861946], learning rate: 0.0099000000
Val loss  tensor(1.1452)
Val loss  tensor(1.1628)
Iteration 560000: total loss 0.0517, losses: [0.05171523988246918], learning rate: 0.0098010000
Iteration 560000: total loss 0.0746, losses: [0.07457496225833893], learning rate: 0.0097029900
Val loss  tensor(0.9272)
Val loss  tensor(1.7296)
Iteration 355000: total loss 0.0503, losses: [0.05026993155479431], learning rate: 0.0097029900
Iteration 355000: total loss 0.0481, losses: [0.04812014102935791], learning rate: 0.0099000000
Iteration 565000: total loss 0.0750, losses: [0.07501247525215149], learning rate: 0.0097029900
Iteration 565000: total loss 0.0513, losses: [0.05131992697715759], learning rate: 0.0098010000
Iteration 360000: total loss 0.0580, losses: [0.05804920196533203], learning rate: 0.0097029900
Iteration 360000: total loss 0.0489, losses: [0.048900336027145386], learning rate: 0.0099000000
Val loss  tensor(1.1832)
Val loss  tensor(1.0981)
Iteration 570000: total loss 0.0502, losses: [0.05022649094462395], learning rate: 0.0098010000
Iteration 570000: total loss 0.0727, losses: [0.0727234035730362], learning rate: 0.0097029900
Val loss  tensor(0.9492)
Val loss  tensor(1.4898)
Iteration 365000: total loss 0.0522, losses: [0.05215328931808472], learning rate: 0.0097029900
Iteration 365000: total loss 0.0586, losses: [0.05864532291889191], learning rate: 0.0099000000
Iteration 575000: total loss 0.0641, losses: [0.06412263959646225], learning rate: 0.0098010000
Iteration 575000: total loss 0.0853, losses: [0.08528363704681396], learning rate: 0.0097029900
Iteration 370000: total loss 0.0538, losses: [0.05376557260751724], learning rate: 0.0097029900
Iteration 370000: total loss 0.0447, losses: [0.04470553249120712], learning rate: 0.0099000000
Val loss  tensor(1.2962)
Val loss  tensor(1.0687)
Iteration 580000: total loss 0.0646, losses: [0.0645786002278328], learning rate: 0.0097029900
Iteration 580000: total loss 0.0472, losses: [0.04720667377114296], learning rate: 0.0098010000
Val loss  tensor(1.5482)
Val loss  tensor(0.9878)
Iteration 375000: total loss 0.0572, losses: [0.05715124309062958], learning rate: 0.0097029900
Iteration 375000: total loss 0.0539, losses: [0.053850214928388596], learning rate: 0.0098010000
Iteration 585000: total loss 0.0487, losses: [0.0486963614821434], learning rate: 0.0098010000
Iteration 585000: total loss 0.0742, losses: [0.07422363758087158], learning rate: 0.0097029900
Iteration 380000: total loss 0.0640, losses: [0.06396199762821198], learning rate: 0.0097029900
Iteration 380000: total loss 0.0491, losses: [0.04909570887684822], learning rate: 0.0098010000
Val loss  tensor(1.3530)
Val loss  tensor(1.1193)
Iteration 590000: total loss 0.0389, losses: [0.038858234882354736], learning rate: 0.0098010000
Iteration 590000: total loss 0.0684, losses: [0.06842637807130814], learning rate: 0.0097029900
Val loss  tensor(1.3035)
Val loss  tensor(0.9666)
Iteration 385000: total loss 0.0504, losses: [0.050368696451187134], learning rate: 0.0097029900
Iteration 385000: total loss 0.0475, losses: [0.04747287184000015], learning rate: 0.0098010000
Iteration 595000: total loss 0.0545, losses: [0.05448102205991745], learning rate: 0.0098010000
Iteration 595000: total loss 0.0765, losses: [0.0764712318778038], learning rate: 0.0097029900
Iteration 390000: total loss 0.0509, losses: [0.05094160512089729], learning rate: 0.0097029900
Iteration 390000: total loss 0.0340, losses: [0.034013599157333374], learning rate: 0.0098010000
Val loss  tensor(1.0091)
Val loss  tensor(1.0463)
Iteration 600000: total loss 0.0531, losses: [0.05314338579773903], learning rate: 0.0098010000
Iteration 600000: total loss 0.0523, losses: [0.05227969214320183], learning rate: 0.0097029900
Val loss  tensor(1.0142)
Val loss  tensor(1.4455)
Iteration 395000: total loss 0.0654, losses: [0.06541426479816437], learning rate: 0.0097029900
Iteration 395000: total loss 0.0450, losses: [0.045047465711832047], learning rate: 0.0098010000
Iteration 605000: total loss 0.0686, losses: [0.06859971582889557], learning rate: 0.0097029900
Iteration 605000: total loss 0.0471, losses: [0.047126539051532745], learning rate: 0.0098010000
Iteration 400000: total loss 0.0543, losses: [0.054317690432071686], learning rate: 0.0097029900
Iteration 400000: total loss 0.0439, losses: [0.04394663870334625], learning rate: 0.0098010000
Val loss  tensor(1.0265)
Val loss  tensor(1.0029)
Iteration 610000: total loss 0.0476, losses: [0.047633469104766846], learning rate: 0.0098010000
Iteration 610000: total loss 0.0768, losses: [0.07683081924915314], learning rate: 0.0097029900
Val loss  tensor(1.3506)
Val loss  tensor(0.9528)
Iteration 405000: total loss 0.0571, losses: [0.05712816119194031], learning rate: 0.0097029900
Iteration 405000: total loss 0.0473, losses: [0.047342926263809204], learning rate: 0.0098010000
Iteration 615000: total loss 0.0438, losses: [0.043802566826343536], learning rate: 0.0098010000
Iteration 615000: total loss 0.0694, losses: [0.06937044858932495], learning rate: 0.0097029900
Iteration 410000: total loss 0.0553, losses: [0.05529217794537544], learning rate: 0.0097029900
Iteration 410000: total loss 0.0396, losses: [0.03955170512199402], learning rate: 0.0098010000
Val loss  tensor(1.0482)
Val loss  tensor(1.1453)
Iteration 620000: total loss 0.0536, losses: [0.05363690108060837], learning rate: 0.0098010000
Iteration 620000: total loss 0.0693, losses: [0.06927496194839478], learning rate: 0.0097029900
Val loss  tensor(1.2959)
Val loss  tensor(0.9105)
Iteration 415000: total loss 0.0667, losses: [0.06670312583446503], learning rate: 0.0097029900
Iteration 415000: total loss 0.0493, losses: [0.04933503642678261], learning rate: 0.0098010000
Iteration 625000: total loss 0.0467, losses: [0.04671992361545563], learning rate: 0.0098010000
Iteration 625000: total loss 0.0729, losses: [0.07288089394569397], learning rate: 0.0097029900
Iteration 420000: total loss 0.0733, losses: [0.0732700452208519], learning rate: 0.0097029900
Iteration 420000: total loss 0.0525, losses: [0.05252847820520401], learning rate: 0.0098010000
Val loss  tensor(1.1490)
Val loss  tensor(1.0328)
Iteration 630000: total loss 0.0459, losses: [0.045865751802921295], learning rate: 0.0098010000
Iteration 630000: total loss 0.0626, losses: [0.06257268786430359], learning rate: 0.0097029900
Val loss  tensor(0.9697)
Val loss  tensor(1.4096)
Iteration 425000: total loss 0.0576, losses: [0.05758623778820038], learning rate: 0.0097029900
Iteration 425000: total loss 0.0573, losses: [0.05731860548257828], learning rate: 0.0098010000
Iteration 635000: total loss 0.0505, losses: [0.05048539116978645], learning rate: 0.0098010000
Iteration 635000: total loss 0.0667, losses: [0.06668870151042938], learning rate: 0.0097029900
Iteration 430000: total loss 0.0568, losses: [0.05676719918847084], learning rate: 0.0097029900
Iteration 430000: total loss 0.0453, losses: [0.0453217476606369], learning rate: 0.0098010000
Val loss  tensor(1.1595)
Val loss  tensor(1.1683)
Iteration 640000: total loss 0.0499, losses: [0.049931082874536514], learning rate: 0.0098010000
Iteration 640000: total loss 0.0729, losses: [0.07294854521751404], learning rate: 0.0097029900
Val loss  tensor(0.9419)
Val loss  tensor(1.3849)
Iteration 435000: total loss 0.0461, losses: [0.04606940597295761], learning rate: 0.0097029900
Iteration 435000: total loss 0.0588, losses: [0.058775197714567184], learning rate: 0.0098010000
Iteration 645000: total loss 0.0571, losses: [0.057120487093925476], learning rate: 0.0097029900
Iteration 645000: total loss 0.0839, losses: [0.08393914252519608], learning rate: 0.0097029900
Iteration 440000: total loss 0.0489, losses: [0.0489233136177063], learning rate: 0.0097029900
Iteration 440000: total loss 0.0470, losses: [0.046964146196842194], learning rate: 0.0098010000
Val loss  tensor(0.9257)
Val loss  tensor(1.1301)
Iteration 650000: total loss 0.0542, losses: [0.05423745885491371], learning rate: 0.0097029900
Iteration 650000: total loss 0.0639, losses: [0.06385751068592072], learning rate: 0.0097029900
Val loss  tensor(1.2510)
Val loss  tensor(0.9748)
Iteration 445000: total loss 0.0562, losses: [0.05622496083378792], learning rate: 0.0097029900
Iteration 445000: total loss 0.0476, losses: [0.04762933403253555], learning rate: 0.0098010000
Iteration 655000: total loss 0.0459, losses: [0.04592504724860191], learning rate: 0.0097029900
Iteration 655000: total loss 0.0773, losses: [0.07733171433210373], learning rate: 0.0096059601
Iteration 450000: total loss 0.0559, losses: [0.05585165694355965], learning rate: 0.0097029900
Iteration 450000: total loss 0.0437, losses: [0.043681662529706955], learning rate: 0.0098010000
Val loss  tensor(1.0113)
Val loss  tensor(1.0510)
Iteration 660000: total loss 0.0540, losses: [0.05399075150489807], learning rate: 0.0097029900
Iteration 660000: total loss 0.0749, losses: [0.07489027082920074], learning rate: 0.0096059601
Val loss  tensor(0.9776)
Val loss  tensor(1.1302)
Iteration 455000: total loss 0.0558, losses: [0.055834971368312836], learning rate: 0.0097029900
Iteration 455000: total loss 0.0495, losses: [0.049501385539770126], learning rate: 0.0098010000
Iteration 665000: total loss 0.0480, losses: [0.047963835299015045], learning rate: 0.0097029900
Iteration 665000: total loss 0.0545, losses: [0.0544869601726532], learning rate: 0.0096059601
Iteration 460000: total loss 0.0574, losses: [0.05735594779253006], learning rate: 0.0097029900
Iteration 460000: total loss 0.0423, losses: [0.04234719276428223], learning rate: 0.0098010000
Val loss  tensor(1.0136)
Val loss  tensor(1.1171)
Iteration 670000: total loss 0.0476, losses: [0.04763415828347206], learning rate: 0.0097029900
Iteration 670000: total loss 0.0584, losses: [0.05844435468316078], learning rate: 0.0096059601
Val loss  tensor(0.9207)
Val loss  tensor(1.0419)
Iteration 465000: total loss 0.0518, losses: [0.051764607429504395], learning rate: 0.0097029900
Iteration 465000: total loss 0.0505, losses: [0.050510793924331665], learning rate: 0.0098010000
Iteration 675000: total loss 0.0537, losses: [0.053670987486839294], learning rate: 0.0097029900
Iteration 675000: total loss 0.0600, losses: [0.0600152313709259], learning rate: 0.0096059601
Iteration 470000: total loss 0.0463, losses: [0.04626114293932915], learning rate: 0.0097029900
Iteration 470000: total loss 0.0480, losses: [0.04797109216451645], learning rate: 0.0098010000
Val loss  tensor(0.9399)
Val loss  tensor(1.1181)
Iteration 680000: total loss 0.0506, losses: [0.05056007206439972], learning rate: 0.0097029900
Iteration 680000: total loss 0.0685, losses: [0.06853389739990234], learning rate: 0.0096059601
Val loss  tensor(1.0753)
Val loss  tensor(0.9431)
Iteration 475000: total loss 0.0600, losses: [0.05996251851320267], learning rate: 0.0097029900
Iteration 475000: total loss 0.0460, losses: [0.045972034335136414], learning rate: 0.0098010000
Iteration 685000: total loss 0.0431, losses: [0.043085820972919464], learning rate: 0.0097029900
Iteration 685000: total loss 0.0504, losses: [0.050439804792404175], learning rate: 0.0096059601
Iteration 480000: total loss 0.0577, losses: [0.05772833898663521], learning rate: 0.0097029900
Iteration 480000: total loss 0.0439, losses: [0.04386129602789879], learning rate: 0.0098010000
Val loss  tensor(0.8728)
Val loss  tensor(1.1436)
Iteration 690000: total loss 0.0532, losses: [0.05317770317196846], learning rate: 0.0097029900
Iteration 690000: total loss 0.0624, losses: [0.06241561472415924], learning rate: 0.0096059601
Val loss  tensor(1.0171)
Val loss  tensor(0.9073)
Iteration 485000: total loss 0.0536, losses: [0.05360835790634155], learning rate: 0.0097029900
Iteration 485000: total loss 0.0426, losses: [0.04261837527155876], learning rate: 0.0098010000
Iteration 695000: total loss 0.0531, losses: [0.0530722551047802], learning rate: 0.0097029900
Iteration 695000: total loss 0.0635, losses: [0.06352905929088593], learning rate: 0.0096059601
Iteration 490000: total loss 0.0490, losses: [0.04901552200317383], learning rate: 0.0097029900
Iteration 490000: total loss 0.0479, losses: [0.04791704937815666], learning rate: 0.0098010000
Val loss  tensor(0.9107)
Val loss  tensor(1.0555)
Iteration 700000: total loss 0.0492, losses: [0.04919242113828659], learning rate: 0.0097029900
Iteration 700000: total loss 0.0755, losses: [0.07551497220993042], learning rate: 0.0096059601
Val loss  tensor(1.0334)
Val loss  tensor(1.0251)
Iteration 495000: total loss 0.0516, losses: [0.05162225663661957], learning rate: 0.0097029900
Iteration 495000: total loss 0.0484, losses: [0.04837523400783539], learning rate: 0.0098010000
Iteration 705000: total loss 0.0480, losses: [0.04802144318819046], learning rate: 0.0097029900
Iteration 705000: total loss 0.0698, losses: [0.06976379454135895], learning rate: 0.0096059601
Iteration 500000: total loss 0.0498, losses: [0.04983454942703247], learning rate: 0.0097029900
Iteration 500000: total loss 0.0468, losses: [0.04683336988091469], learning rate: 0.0098010000
Val loss  tensor(0.8799)
Val loss  tensor(0.9707)
Iteration 710000: total loss 0.0463, losses: [0.04629404470324516], learning rate: 0.0097029900
Iteration 710000: total loss 0.0764, losses: [0.07643505930900574], learning rate: 0.0096059601
Val loss  tensor(1.0552)
Val loss  tensor(1.0158)
Iteration 505000: total loss 0.0502, losses: [0.05024631693959236], learning rate: 0.0097029900
Iteration 505000: total loss 0.0450, losses: [0.04501742869615555], learning rate: 0.0098010000
Iteration 715000: total loss 0.0476, losses: [0.047627173364162445], learning rate: 0.0097029900
Iteration 715000: total loss 0.0539, losses: [0.05390894040465355], learning rate: 0.0096059601
Iteration 510000: total loss 0.0568, losses: [0.05677223205566406], learning rate: 0.0097029900
Iteration 510000: total loss 0.0442, losses: [0.04415128380060196], learning rate: 0.0098010000
Val loss  tensor(0.8401)
Val loss  tensor(1.0321)
Iteration 720000: total loss 0.0403, losses: [0.040266554802656174], learning rate: 0.0097029900
Iteration 720000: total loss 0.0695, losses: [0.06945672631263733], learning rate: 0.0096059601
Val loss  tensor(1.0723)
Val loss  tensor(0.9289)
Iteration 515000: total loss 0.0532, losses: [0.05324236676096916], learning rate: 0.0097029900
Iteration 515000: total loss 0.0499, losses: [0.04994966462254524], learning rate: 0.0098010000
Iteration 725000: total loss 0.0738, losses: [0.07377476990222931], learning rate: 0.0096059601
Iteration 725000: total loss 0.0507, losses: [0.05066243186593056], learning rate: 0.0097029900
Iteration 520000: total loss 0.0542, losses: [0.054224975407123566], learning rate: 0.0097029900
Iteration 520000: total loss 0.0414, losses: [0.04135219752788544], learning rate: 0.0098010000
Val loss  tensor(1.0706)
Val loss  tensor(1.0524)
Iteration 730000: total loss 0.0498, losses: [0.04978004842996597], learning rate: 0.0097029900
Iteration 730000: total loss 0.0803, losses: [0.08033174276351929], learning rate: 0.0096059601
Val loss  tensor(1.0561)
Val loss  tensor(1.0334)
Iteration 525000: total loss 0.0515, losses: [0.051473140716552734], learning rate: 0.0097029900
Iteration 525000: total loss 0.0420, losses: [0.04200434684753418], learning rate: 0.0098010000
Iteration 735000: total loss 0.0673, losses: [0.06731929630041122], learning rate: 0.0096059601
Iteration 735000: total loss 0.0505, losses: [0.05052739754319191], learning rate: 0.0097029900
Iteration 530000: total loss 0.0574, losses: [0.0573706217110157], learning rate: 0.0097029900
Iteration 530000: total loss 0.0510, losses: [0.05104131996631622], learning rate: 0.0098010000
Val loss  tensor(0.9610)
Val loss  tensor(1.0261)
Iteration 740000: total loss 0.0482, losses: [0.048189736902713776], learning rate: 0.0097029900
Iteration 740000: total loss 0.0643, losses: [0.06433769315481186], learning rate: 0.0096059601
Val loss  tensor(1.0594)
Val loss  tensor(0.9753)
Iteration 535000: total loss 0.0451, losses: [0.04508495330810547], learning rate: 0.0097029900
Iteration 535000: total loss 0.0506, losses: [0.05064735561609268], learning rate: 0.0098010000
Iteration 745000: total loss 0.0693, losses: [0.0692538172006607], learning rate: 0.0096059601
Iteration 745000: total loss 0.0528, losses: [0.05284448340535164], learning rate: 0.0097029900
Iteration 540000: total loss 0.0481, losses: [0.0481046661734581], learning rate: 0.0097029900
Iteration 540000: total loss 0.0487, losses: [0.04871010035276413], learning rate: 0.0098010000
Val loss  tensor(0.9005)
Val loss  tensor(1.0270)
Iteration 750000: total loss 0.0645, losses: [0.0645173192024231], learning rate: 0.0096059601
Iteration 750000: total loss 0.0411, losses: [0.04107510298490524], learning rate: 0.0097029900
Val loss  tensor(1.0616)
Val loss  tensor(1.0018)
Iteration 545000: total loss 0.0530, losses: [0.0530429445207119], learning rate: 0.0098010000
Iteration 545000: total loss 0.0436, losses: [0.043574362993240356], learning rate: 0.0097029900
Iteration 755000: total loss 0.0474, losses: [0.04740394279360771], learning rate: 0.0096059601
Iteration 755000: total loss 0.0735, losses: [0.07350069284439087], learning rate: 0.0096059601
Iteration 550000: total loss 0.0429, losses: [0.04292354732751846], learning rate: 0.0098010000
Iteration 550000: total loss 0.0498, losses: [0.049765508621931076], learning rate: 0.0097029900
Val loss  tensor(1.0402)
Val loss  tensor(0.9442)
Iteration 760000: total loss 0.0564, losses: [0.056449152529239655], learning rate: 0.0096059601
Iteration 760000: total loss 0.0597, losses: [0.059652168303728104], learning rate: 0.0096059601
Val loss  tensor(1.0635)
Val loss  tensor(1.0070)
Iteration 555000: total loss 0.0535, losses: [0.0534939281642437], learning rate: 0.0097029900
Iteration 555000: total loss 0.0533, losses: [0.05327969789505005], learning rate: 0.0098010000
Iteration 765000: total loss 0.0493, losses: [0.04930084943771362], learning rate: 0.0096059601
Iteration 765000: total loss 0.0732, losses: [0.07320454716682434], learning rate: 0.0095099005
Iteration 560000: total loss 0.0487, losses: [0.048735179007053375], learning rate: 0.0097029900
Iteration 560000: total loss 0.0418, losses: [0.04183099791407585], learning rate: 0.0098010000
Val loss  tensor(0.9076)
Val loss  tensor(1.1174)
Iteration 770000: total loss 0.0455, losses: [0.045526646077632904], learning rate: 0.0096059601
Iteration 770000: total loss 0.0624, losses: [0.06240388751029968], learning rate: 0.0095099005
Val loss  tensor(1.0596)
Val loss  tensor(0.9981)
Iteration 565000: total loss 0.0502, losses: [0.050236064940690994], learning rate: 0.0097029900
Iteration 565000: total loss 0.0417, losses: [0.04165561497211456], learning rate: 0.0098010000
Iteration 775000: total loss 0.0450, losses: [0.04499635845422745], learning rate: 0.0096059601
Iteration 775000: total loss 0.0597, losses: [0.05965424329042435], learning rate: 0.0095099005
Iteration 570000: total loss 0.0480, losses: [0.04797515645623207], learning rate: 0.0097029900
Iteration 570000: total loss 0.0419, losses: [0.041915327310562134], learning rate: 0.0098010000
Val loss  tensor(1.0066)
Val loss  tensor(1.0777)
Iteration 780000: total loss 0.0500, losses: [0.05003079026937485], learning rate: 0.0096059601
Iteration 780000: total loss 0.0599, losses: [0.05991804972290993], learning rate: 0.0095099005
Val loss  tensor(1.0834)
Val loss  tensor(1.0210)
Iteration 575000: total loss 0.0428, losses: [0.042789384722709656], learning rate: 0.0098010000
Iteration 575000: total loss 0.0550, losses: [0.05497623234987259], learning rate: 0.0097029900
Iteration 785000: total loss 0.0494, losses: [0.04942683130502701], learning rate: 0.0096059601
Iteration 785000: total loss 0.0636, losses: [0.0636402815580368], learning rate: 0.0095099005
Iteration 580000: total loss 0.0624, losses: [0.06242414563894272], learning rate: 0.0097029900
Iteration 580000: total loss 0.0429, losses: [0.04290898144245148], learning rate: 0.0098010000
Val loss  tensor(0.8652)
Val loss  tensor(1.0392)
Iteration 790000: total loss 0.0443, losses: [0.04426158219575882], learning rate: 0.0096059601
Iteration 790000: total loss 0.0752, losses: [0.07515620440244675], learning rate: 0.0095099005
Val loss  tensor(0.9222)
Val loss  tensor(1.0636)
Iteration 585000: total loss 0.0539, losses: [0.05387300252914429], learning rate: 0.0097029900
Iteration 585000: total loss 0.0439, losses: [0.043894797563552856], learning rate: 0.0098010000
Iteration 795000: total loss 0.0833, losses: [0.0833311602473259], learning rate: 0.0095099005
Iteration 795000: total loss 0.0423, losses: [0.042262107133865356], learning rate: 0.0096059601
Iteration 590000: total loss 0.0558, losses: [0.05582142248749733], learning rate: 0.0097029900
Iteration 590000: total loss 0.0452, losses: [0.045225419104099274], learning rate: 0.0098010000
Val loss  tensor(0.8271)
Val loss  tensor(1.0923)
Iteration 800000: total loss 0.0597, losses: [0.0597040057182312], learning rate: 0.0095099005
Iteration 800000: total loss 0.0434, losses: [0.043357498943805695], learning rate: 0.0096059601
Val loss  tensor(0.8860)
Val loss  tensor(1.0667)
Iteration 595000: total loss 0.0456, losses: [0.045604437589645386], learning rate: 0.0097029900
Iteration 595000: total loss 0.0449, losses: [0.04493994265794754], learning rate: 0.0098010000
Iteration 805000: total loss 0.0631, losses: [0.06314035505056381], learning rate: 0.0095099005
Iteration 805000: total loss 0.0397, losses: [0.03974059969186783], learning rate: 0.0096059601
Iteration 600000: total loss 0.0561, losses: [0.05612824112176895], learning rate: 0.0097029900
Iteration 600000: total loss 0.0342, losses: [0.03417003154754639], learning rate: 0.0098010000
Val loss  tensor(0.8526)
Val loss  tensor(1.0572)
Iteration 810000: total loss 0.0448, losses: [0.044789303094148636], learning rate: 0.0096059601
Iteration 810000: total loss 0.0631, losses: [0.06306695938110352], learning rate: 0.0095099005
Val loss  tensor(1.1158)
Val loss  tensor(1.0458)
Iteration 605000: total loss 0.0433, losses: [0.04333295673131943], learning rate: 0.0097029900
Iteration 605000: total loss 0.0437, losses: [0.043720632791519165], learning rate: 0.0098010000
Iteration 815000: total loss 0.0609, losses: [0.06090731546282768], learning rate: 0.0095099005
Iteration 815000: total loss 0.0416, losses: [0.04157499596476555], learning rate: 0.0096059601
Iteration 610000: total loss 0.0552, losses: [0.055189311504364014], learning rate: 0.0097029900
Iteration 610000: total loss 0.0432, losses: [0.043244898319244385], learning rate: 0.0098010000
Val loss  tensor(0.8621)
Val loss  tensor(1.0093)
Iteration 820000: total loss 0.0460, losses: [0.04595860838890076], learning rate: 0.0096059601
Iteration 820000: total loss 0.0548, losses: [0.05481816828250885], learning rate: 0.0095099005
Val loss  tensor(0.9796)
Val loss  tensor(1.0620)
Iteration 615000: total loss 0.0561, losses: [0.056060776114463806], learning rate: 0.0097029900
Iteration 615000: total loss 0.0475, losses: [0.047465283423662186], learning rate: 0.0097029900
Iteration 825000: total loss 0.0431, losses: [0.04306134581565857], learning rate: 0.0096059601
Iteration 825000: total loss 0.0564, losses: [0.05636478215456009], learning rate: 0.0095099005
Iteration 620000: total loss 0.0460, losses: [0.04601588100194931], learning rate: 0.0097029900
Iteration 620000: total loss 0.0503, losses: [0.0502878874540329], learning rate: 0.0097029900
Val loss  tensor(0.8093)
Val loss  tensor(0.9457)
Iteration 830000: total loss 0.0542, losses: [0.05417156219482422], learning rate: 0.0096059601
Iteration 830000: total loss 0.0883, losses: [0.08833342045545578], learning rate: 0.0095099005
Val loss  tensor(0.9101)
Val loss  tensor(1.0852)
Iteration 625000: total loss 0.0480, losses: [0.048011813312768936], learning rate: 0.0097029900
Iteration 625000: total loss 0.0403, losses: [0.04033607244491577], learning rate: 0.0097029900
Iteration 835000: total loss 0.0582, losses: [0.058203890919685364], learning rate: 0.0095099005
Iteration 835000: total loss 0.0502, losses: [0.050193242728710175], learning rate: 0.0096059601
Iteration 630000: total loss 0.0484, losses: [0.04835347831249237], learning rate: 0.0097029900
Iteration 630000: total loss 0.0490, losses: [0.048959966748952866], learning rate: 0.0097029900
Val loss  tensor(0.8304)
Val loss  tensor(1.0002)
Iteration 840000: total loss 0.0374, losses: [0.03742237761616707], learning rate: 0.0096059601
Iteration 840000: total loss 0.0592, losses: [0.05916852504014969], learning rate: 0.0095099005
Val loss  tensor(1.1246)
Val loss  tensor(0.9434)
Iteration 635000: total loss 0.0649, losses: [0.06492114067077637], learning rate: 0.0097029900
Iteration 635000: total loss 0.0450, losses: [0.04499395191669464], learning rate: 0.0097029900
Iteration 845000: total loss 0.0472, losses: [0.047233354300260544], learning rate: 0.0096059601
Iteration 845000: total loss 0.0621, losses: [0.06209658086299896], learning rate: 0.0095099005
Iteration 640000: total loss 0.0584, losses: [0.05837706848978996], learning rate: 0.0097029900
Iteration 640000: total loss 0.0387, losses: [0.03874415159225464], learning rate: 0.0097029900
Val loss  tensor(0.8911)
Val loss  tensor(1.0001)
Iteration 850000: total loss 0.0436, losses: [0.04363308101892471], learning rate: 0.0096059601
Iteration 850000: total loss 0.0709, losses: [0.070863738656044], learning rate: 0.0095099005
Val loss  tensor(0.9070)
Val loss  tensor(1.0934)
Iteration 645000: total loss 0.0555, losses: [0.05545444414019585], learning rate: 0.0097029900
Iteration 645000: total loss 0.0372, losses: [0.03721184283494949], learning rate: 0.0097029900
Iteration 855000: total loss 0.0438, losses: [0.043844688683748245], learning rate: 0.0096059601
Iteration 855000: total loss 0.0598, losses: [0.05978886038064957], learning rate: 0.0095099005
Iteration 650000: total loss 0.0408, losses: [0.04083215445280075], learning rate: 0.0097029900
Iteration 650000: total loss 0.0468, losses: [0.04681304469704628], learning rate: 0.0097029900
Val loss  tensor(1.0564)
Val loss  tensor(0.9848)
Iteration 860000: total loss 0.0476, losses: [0.04763474315404892], learning rate: 0.0096059601
Iteration 860000: total loss 0.0692, losses: [0.06915710121393204], learning rate: 0.0095099005
Val loss  tensor(1.1088)
Val loss  tensor(0.9716)
Iteration 655000: total loss 0.0571, losses: [0.05711466819047928], learning rate: 0.0097029900
Iteration 655000: total loss 0.0410, losses: [0.041018687188625336], learning rate: 0.0097029900
Iteration 865000: total loss 0.0443, losses: [0.044298239052295685], learning rate: 0.0095099005
Iteration 865000: total loss 0.0629, losses: [0.06290780007839203], learning rate: 0.0095099005
Iteration 660000: total loss 0.0480, losses: [0.04795529320836067], learning rate: 0.0097029900
Iteration 660000: total loss 0.0535, losses: [0.05350372940301895], learning rate: 0.0097029900
Val loss  tensor(0.8736)
Val loss  tensor(1.0516)
Iteration 870000: total loss 0.0496, losses: [0.04964815080165863], learning rate: 0.0095099005
Iteration 870000: total loss 0.0545, losses: [0.054514896124601364], learning rate: 0.0095099005
Val loss  tensor(1.0834)
Val loss  tensor(1.0152)
Iteration 665000: total loss 0.0544, losses: [0.054392892867326736], learning rate: 0.0097029900
Iteration 665000: total loss 0.0408, losses: [0.04075714945793152], learning rate: 0.0097029900
Iteration 875000: total loss 0.0426, losses: [0.04259415343403816], learning rate: 0.0095099005
Iteration 875000: total loss 0.0637, losses: [0.06369331479072571], learning rate: 0.0094148015
Iteration 670000: total loss 0.0467, losses: [0.04666048660874367], learning rate: 0.0097029900
Iteration 670000: total loss 0.0452, losses: [0.045153647661209106], learning rate: 0.0097029900
Val loss  tensor(0.8276)
Val loss  tensor(0.9801)
Iteration 880000: total loss 0.0462, losses: [0.046164464205503464], learning rate: 0.0095099005
Iteration 880000: total loss 0.0579, losses: [0.0579427145421505], learning rate: 0.0094148015
Val loss  tensor(1.0286)
Val loss  tensor(1.0684)
Iteration 675000: total loss 0.0446, losses: [0.0446433499455452], learning rate: 0.0097029900
Iteration 675000: total loss 0.0485, losses: [0.048485592007637024], learning rate: 0.0097029900
Iteration 885000: total loss 0.0536, losses: [0.053646981716156006], learning rate: 0.0094148015
Iteration 885000: total loss 0.0464, losses: [0.04635346680879593], learning rate: 0.0095099005
Iteration 680000: total loss 0.0572, losses: [0.05716988071799278], learning rate: 0.0097029900
Iteration 680000: total loss 0.0474, losses: [0.0473778136074543], learning rate: 0.0097029900
Val loss  tensor(0.8657)
Val loss  tensor(1.0080)
Iteration 890000: total loss 0.0626, losses: [0.06256595253944397], learning rate: 0.0094148015
Iteration 890000: total loss 0.0400, losses: [0.04001108929514885], learning rate: 0.0095099005
Val loss  tensor(1.0970)
Val loss  tensor(1.0869)
Iteration 685000: total loss 0.0449, losses: [0.044908557087183], learning rate: 0.0097029900
Iteration 685000: total loss 0.0482, losses: [0.0481603778898716], learning rate: 0.0097029900
Iteration 895000: total loss 0.0399, losses: [0.039941512048244476], learning rate: 0.0095099005
Iteration 895000: total loss 0.0480, losses: [0.04797663539648056], learning rate: 0.0094148015
Iteration 690000: total loss 0.0443, losses: [0.044320248067379], learning rate: 0.0097029900
Iteration 690000: total loss 0.0372, losses: [0.037151142954826355], learning rate: 0.0097029900
Val loss  tensor(0.8381)
Val loss  tensor(0.9499)
Iteration 900000: total loss 0.0491, losses: [0.04912770912051201], learning rate: 0.0095099005
Iteration 900000: total loss 0.0597, losses: [0.05970887839794159], learning rate: 0.0094148015
Val loss  tensor(0.9192)
Val loss  tensor(1.1325)
Iteration 695000: total loss 0.0457, losses: [0.04568484425544739], learning rate: 0.0097029900
Iteration 695000: total loss 0.0472, losses: [0.047182098031044006], learning rate: 0.0097029900
Iteration 905000: total loss 0.0471, losses: [0.04712434485554695], learning rate: 0.0095099005
Iteration 905000: total loss 0.0594, losses: [0.0594460591673851], learning rate: 0.0094148015
Iteration 700000: total loss 0.0459, losses: [0.04589221999049187], learning rate: 0.0097029900
Iteration 700000: total loss 0.0361, losses: [0.036140017211437225], learning rate: 0.0097029900
Val loss  tensor(0.8389)
Val loss  tensor(1.0190)
Iteration 910000: total loss 0.0445, losses: [0.044483788311481476], learning rate: 0.0095099005
Iteration 910000: total loss 0.0651, losses: [0.06510159373283386], learning rate: 0.0094148015
Val loss  tensor(1.0842)
Val loss  tensor(1.0247)
Iteration 705000: total loss 0.0581, losses: [0.058065131306648254], learning rate: 0.0097029900
Iteration 705000: total loss 0.0413, losses: [0.04132384434342384], learning rate: 0.0097029900
Iteration 915000: total loss 0.0452, losses: [0.045173972845077515], learning rate: 0.0095099005
Iteration 915000: total loss 0.0682, losses: [0.0681808814406395], learning rate: 0.0094148015
Iteration 710000: total loss 0.0527, losses: [0.052674319595098495], learning rate: 0.0097029900
Iteration 710000: total loss 0.0451, losses: [0.045126911252737045], learning rate: 0.0097029900
Val loss  tensor(0.8551)
Val loss  tensor(0.8995)
Iteration 920000: total loss 0.0437, losses: [0.04365189000964165], learning rate: 0.0095099005
Iteration 920000: total loss 0.0545, losses: [0.05447949096560478], learning rate: 0.0094148015
Val loss  tensor(1.0977)
Val loss  tensor(1.0184)
Iteration 715000: total loss 0.0456, losses: [0.04564093053340912], learning rate: 0.0097029900
Iteration 715000: total loss 0.0380, losses: [0.037952251732349396], learning rate: 0.0097029900
Iteration 925000: total loss 0.0382, losses: [0.03819703683257103], learning rate: 0.0095099005
Iteration 925000: total loss 0.0619, losses: [0.06185699254274368], learning rate: 0.0094148015
Iteration 720000: total loss 0.0584, losses: [0.058402564376592636], learning rate: 0.0097029900
Iteration 720000: total loss 0.0427, losses: [0.04270618408918381], learning rate: 0.0097029900
Val loss  tensor(0.8149)
Val loss  tensor(0.9688)
Iteration 930000: total loss 0.0380, losses: [0.03795398771762848], learning rate: 0.0095099005
Iteration 930000: total loss 0.0579, losses: [0.05792255327105522], learning rate: 0.0094148015
Val loss  tensor(1.0786)
Val loss  tensor(0.9716)
Iteration 725000: total loss 0.0614, losses: [0.06140458583831787], learning rate: 0.0097029900
Iteration 725000: total loss 0.0358, losses: [0.03576190024614334], learning rate: 0.0097029900
Iteration 935000: total loss 0.0472, losses: [0.04715278372168541], learning rate: 0.0095099005
Iteration 935000: total loss 0.0603, losses: [0.06030794978141785], learning rate: 0.0094148015
Iteration 730000: total loss 0.0480, losses: [0.04804094880819321], learning rate: 0.0097029900
Iteration 730000: total loss 0.0356, losses: [0.03564947471022606], learning rate: 0.0097029900
Val loss  tensor(0.8457)
Val loss  tensor(0.9674)
Iteration 940000: total loss 0.0461, losses: [0.046067461371421814], learning rate: 0.0095099005
Iteration 940000: total loss 0.0632, losses: [0.0631536915898323], learning rate: 0.0094148015
Val loss  tensor(1.1466)
Val loss  tensor(1.0700)
Iteration 735000: total loss 0.0395, losses: [0.0395466648042202], learning rate: 0.0096059601
Iteration 735000: total loss 0.0452, losses: [0.04515114426612854], learning rate: 0.0097029900
Iteration 945000: total loss 0.0440, losses: [0.04402077943086624], learning rate: 0.0095099005
Iteration 945000: total loss 0.0674, losses: [0.06744854152202606], learning rate: 0.0094148015
Iteration 740000: total loss 0.0478, losses: [0.04778467118740082], learning rate: 0.0096059601
Iteration 740000: total loss 0.0492, losses: [0.049223486334085464], learning rate: 0.0097029900
Val loss  tensor(1.7976)
Val loss  tensor(0.9846)
Iteration 950000: total loss 0.0443, losses: [0.04430830478668213], learning rate: 0.0095099005
Iteration 950000: total loss 0.0601, losses: [0.06005939096212387], learning rate: 0.0094148015
Val loss  tensor(1.0838)
Val loss  tensor(1.0393)
Iteration 745000: total loss 0.0504, losses: [0.05040806531906128], learning rate: 0.0096059601
Iteration 745000: total loss 0.0347, losses: [0.03465092182159424], learning rate: 0.0097029900
Iteration 955000: total loss 0.0551, losses: [0.05507934093475342], learning rate: 0.0095099005
Iteration 955000: total loss 0.0611, losses: [0.061141256242990494], learning rate: 0.0094148015
Iteration 750000: total loss 0.0330, losses: [0.033027131110429764], learning rate: 0.0096059601
Iteration 750000: total loss 0.0477, losses: [0.04770351201295853], learning rate: 0.0097029900
Val loss  tensor(0.8431)
Val loss  tensor(1.0009)
Iteration 960000: total loss 0.0445, losses: [0.04446849226951599], learning rate: 0.0095099005
Iteration 960000: total loss 0.0618, losses: [0.061785440891981125], learning rate: 0.0094148015
Val loss  tensor(0.9725)
Val loss  tensor(1.0785)
Iteration 755000: total loss 0.0560, losses: [0.056009553372859955], learning rate: 0.0096059601
Iteration 755000: total loss 0.0467, losses: [0.04668419063091278], learning rate: 0.0097029900
Iteration 965000: total loss 0.0467, losses: [0.04668561369180679], learning rate: 0.0095099005
Iteration 965000: total loss 0.0634, losses: [0.06340868771076202], learning rate: 0.0094148015
Iteration 760000: total loss 0.0500, losses: [0.04999329894781113], learning rate: 0.0096059601
Iteration 760000: total loss 0.0462, losses: [0.046190984547138214], learning rate: 0.0097029900
Val loss  tensor(0.8899)
Val loss  tensor(0.9795)
Iteration 970000: total loss 0.0421, losses: [0.04205222427845001], learning rate: 0.0095099005
Iteration 970000: total loss 0.0619, losses: [0.06194151192903519], learning rate: 0.0094148015
Val loss  tensor(1.1000)
Val loss  tensor(0.9518)
Iteration 765000: total loss 0.0610, losses: [0.061028677970170975], learning rate: 0.0096059601
Iteration 765000: total loss 0.0439, losses: [0.043888553977012634], learning rate: 0.0097029900
Iteration 975000: total loss 0.0427, losses: [0.04268680512905121], learning rate: 0.0094148015
Iteration 975000: total loss 0.0642, losses: [0.06418542563915253], learning rate: 0.0094148015
Iteration 770000: total loss 0.0501, losses: [0.050107553601264954], learning rate: 0.0096059601
Iteration 770000: total loss 0.0413, losses: [0.04133227840065956], learning rate: 0.0097029900
Val loss  tensor(0.7985)
Val loss  tensor(0.9809)
Iteration 980000: total loss 0.0473, losses: [0.04728427529335022], learning rate: 0.0094148015
Iteration 980000: total loss 0.0598, losses: [0.05975451320409775], learning rate: 0.0094148015
Val loss  tensor(1.2152)
Val loss  tensor(0.9408)
Iteration 775000: total loss 0.0422, losses: [0.04222142696380615], learning rate: 0.0096059601
Iteration 775000: total loss 0.0368, losses: [0.03683312609791756], learning rate: 0.0097029900
Iteration 985000: total loss 0.0458, losses: [0.04584108293056488], learning rate: 0.0094148015
Iteration 985000: total loss 0.0465, losses: [0.046517856419086456], learning rate: 0.0093206535
Iteration 780000: total loss 0.0527, losses: [0.05270840972661972], learning rate: 0.0096059601
Iteration 780000: total loss 0.0304, losses: [0.030387017875909805], learning rate: 0.0097029900
Val loss  tensor(0.8780)
Val loss  tensor(0.9480)
Iteration 990000: total loss 0.0439, losses: [0.043923597782850266], learning rate: 0.0094148015
Iteration 990000: total loss 0.0637, losses: [0.06367366760969162], learning rate: 0.0093206535
Val loss  tensor(1.0852)
Val loss  tensor(0.9837)
Iteration 785000: total loss 0.0562, losses: [0.056163299828767776], learning rate: 0.0096059601
Iteration 785000: total loss 0.0490, losses: [0.0489608533680439], learning rate: 0.0097029900
Iteration 995000: total loss 0.0733, losses: [0.07332170754671097], learning rate: 0.0093206535
Iteration 995000: total loss 0.0499, losses: [0.04990265518426895], learning rate: 0.0094148015
Iteration 790000: total loss 0.0578, losses: [0.05784403532743454], learning rate: 0.0096059601
Iteration 790000: total loss 0.0462, losses: [0.04616192728281021], learning rate: 0.0097029900
Val loss  tensor(0.9171)
Val loss  tensor(1.0677)
Iteration 795000: total loss 0.0539, losses: [0.05390939861536026], learning rate: 0.0096059601
Iteration 795000: total loss 0.0372, losses: [0.037233658134937286], learning rate: 0.0097029900
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=64, bias=True)
    (1): SiLU()
    (2): Linear(in_features=64, out_features=32, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=32, out_features=2, bias=True)
  )
)
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=32, bias=True)
    (1): SiLU()
    (2): Linear(in_features=32, out_features=32, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=32, out_features=2, bias=True)
  )
)
cuda:0
cuda:0
Folder already there
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=64, bias=True)
    (1): SiLU()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): SiLU()
    (4): Linear(in_features=64, out_features=2, bias=True)
  )
)
Folder already there
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=32, bias=True)
    (1): SiLU()
    (2): Linear(in_features=32, out_features=32, bias=True)
    (3): SiLU()
    (4): Linear(in_features=32, out_features=2, bias=True)
  )
)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
Iteration 0: total loss 2.6553, losses: [2.655341148376465], learning rate: 0.0100000000
Iteration 0: total loss 2.3867, losses: [2.3867197036743164], learning rate: 0.0100000000
Val loss  tensor(1.3502)
Val loss  tensor(1.4503)
Iteration 800000: total loss 0.0572, losses: [0.057186245918273926], learning rate: 0.0096059601
Iteration 800000: total loss 0.0394, losses: [0.0393638014793396], learning rate: 0.0097029900
Val loss  tensor(0.8986)
Val loss  tensor(0.8679)
Iteration 5000: total loss 0.2225, losses: [0.22245076298713684], learning rate: 0.0100000000
Iteration 5000: total loss 0.2561, losses: [0.256142795085907], learning rate: 0.0100000000
Iteration 805000: total loss 0.0487, losses: [0.04866752773523331], learning rate: 0.0096059601
Iteration 805000: total loss 0.0443, losses: [0.04429580643773079], learning rate: 0.0097029900
Iteration 10000: total loss 0.1501, losses: [0.1500542014837265], learning rate: 0.0100000000
Iteration 10000: total loss 0.1983, losses: [0.1982978731393814], learning rate: 0.0100000000
Val loss  tensor(0.9819)
Val loss  tensor(1.1321)
Iteration 810000: total loss 0.0474, losses: [0.047406964004039764], learning rate: 0.0096059601
Iteration 810000: total loss 0.0408, losses: [0.04080329090356827], learning rate: 0.0097029900
Val loss  tensor(0.8465)
Val loss  tensor(1.0420)
Iteration 15000: total loss 0.1222, losses: [0.12217657268047333], learning rate: 0.0100000000
Iteration 15000: total loss 0.1499, losses: [0.14985774457454681], learning rate: 0.0100000000
Iteration 20000: total loss 0.1276, losses: [0.1275673806667328], learning rate: 0.0100000000
Iteration 20000: total loss 0.1461, losses: [0.1460653841495514], learning rate: 0.0100000000
Val loss  tensor(0.9732)
Val loss  tensor(1.2167)
Iteration 815000: total loss 0.0436, losses: [0.043605729937553406], learning rate: 0.0096059601
Iteration 815000: total loss 0.0462, losses: [0.04617073014378548], learning rate: 0.0097029900
Iteration 25000: total loss 0.1241, losses: [0.1241224929690361], learning rate: 0.0100000000
Iteration 25000: total loss 0.1363, losses: [0.1363060474395752], learning rate: 0.0100000000
Iteration 820000: total loss 0.0567, losses: [0.05668490380048752], learning rate: 0.0096059601
Iteration 820000: total loss 0.0388, losses: [0.03876231610774994], learning rate: 0.0097029900
Val loss  tensor(0.8529)
Val loss  tensor(0.9383)
Iteration 30000: total loss 0.0999, losses: [0.09987647831439972], learning rate: 0.0100000000
Iteration 30000: total loss 0.0909, losses: [0.09092741459608078], learning rate: 0.0100000000
Val loss  tensor(0.8813)
Val loss  tensor(1.0172)
Iteration 825000: total loss 0.0343, losses: [0.03431198000907898], learning rate: 0.0096059601
Iteration 825000: total loss 0.0417, losses: [0.041650474071502686], learning rate: 0.0097029900
Iteration 35000: total loss 0.1030, losses: [0.10301432758569717], learning rate: 0.0100000000
Iteration 35000: total loss 0.1222, losses: [0.12222491204738617], learning rate: 0.0100000000
Iteration 830000: total loss 0.0451, losses: [0.04511387646198273], learning rate: 0.0096059601
Iteration 830000: total loss 0.0342, losses: [0.03424602746963501], learning rate: 0.0097029900
Val loss  tensor(0.9253)
Val loss  tensor(0.9137)
Iteration 40000: total loss 0.0975, losses: [0.09752732515335083], learning rate: 0.0100000000
Iteration 40000: total loss 0.0906, losses: [0.09060700237751007], learning rate: 0.0100000000
Val loss  tensor(0.9059)
Val loss  tensor(1.0495)
Iteration 835000: total loss 0.0476, losses: [0.047610003501176834], learning rate: 0.0096059601
Iteration 835000: total loss 0.0390, losses: [0.038984596729278564], learning rate: 0.0097029900
Iteration 45000: total loss 0.1000, losses: [0.09996873140335083], learning rate: 0.0100000000
Iteration 45000: total loss 0.0892, losses: [0.08922399580478668], learning rate: 0.0100000000
Iteration 840000: total loss 0.0510, losses: [0.050961464643478394], learning rate: 0.0096059601
Iteration 840000: total loss 0.0469, losses: [0.046907685697078705], learning rate: 0.0097029900
Val loss  tensor(0.9018)
Val loss  tensor(1.0297)
Iteration 50000: total loss 0.0993, losses: [0.09925340116024017], learning rate: 0.0100000000
Iteration 50000: total loss 0.1222, losses: [0.12221811711788177], learning rate: 0.0100000000
Val loss  tensor(0.8584)
Val loss  tensor(1.0234)
Iteration 845000: total loss 0.0627, losses: [0.06265044212341309], learning rate: 0.0096059601
Iteration 845000: total loss 0.0413, losses: [0.041317641735076904], learning rate: 0.0097029900
Iteration 55000: total loss 0.0983, losses: [0.09828247129917145], learning rate: 0.0100000000
Iteration 55000: total loss 0.1122, losses: [0.11215075850486755], learning rate: 0.0100000000
Iteration 60000: total loss 0.0919, losses: [0.09193554520606995], learning rate: 0.0100000000
Iteration 60000: total loss 0.0833, losses: [0.08332804590463638], learning rate: 0.0100000000
Val loss  tensor(0.7870)
Val loss  tensor(0.9633)
Iteration 850000: total loss 0.0413, losses: [0.041280776262283325], learning rate: 0.0096059601
Iteration 850000: total loss 0.0460, losses: [0.045969750732183456], learning rate: 0.0097029900
Val loss  tensor(0.8548)
Val loss  tensor(0.9500)
Iteration 65000: total loss 0.0819, losses: [0.08185285329818726], learning rate: 0.0100000000
Iteration 65000: total loss 0.0919, losses: [0.09192223846912384], learning rate: 0.0100000000
Iteration 855000: total loss 0.0469, losses: [0.04694480448961258], learning rate: 0.0096059601
Iteration 855000: total loss 0.0463, losses: [0.046262212097644806], learning rate: 0.0097029900
Iteration 70000: total loss 0.0787, losses: [0.07866118848323822], learning rate: 0.0100000000
Iteration 70000: total loss 0.0736, losses: [0.07358917593955994], learning rate: 0.0100000000
Val loss  tensor(0.8555)
Val loss  tensor(0.9791)
Iteration 860000: total loss 0.0458, losses: [0.045815590769052505], learning rate: 0.0096059601
Iteration 860000: total loss 0.0448, losses: [0.04476756602525711], learning rate: 0.0097029900
Val loss  tensor(0.8537)
Val loss  tensor(1.0393)
Iteration 75000: total loss 0.0710, losses: [0.07100408524274826], learning rate: 0.0100000000
Iteration 75000: total loss 0.0758, losses: [0.07580976188182831], learning rate: 0.0100000000
Iteration 865000: total loss 0.0492, losses: [0.049240730702877045], learning rate: 0.0096059601
Iteration 865000: total loss 0.0367, losses: [0.03669236972928047], learning rate: 0.0097029900
Iteration 80000: total loss 0.0780, losses: [0.07796443998813629], learning rate: 0.0100000000
Iteration 80000: total loss 0.0859, losses: [0.08593665063381195], learning rate: 0.0100000000
Val loss  tensor(0.8774)
Val loss  tensor(0.9299)
Iteration 870000: total loss 0.0414, losses: [0.041355423629283905], learning rate: 0.0096059601
Iteration 870000: total loss 0.0421, losses: [0.04208381474018097], learning rate: 0.0097029900
Val loss  tensor(0.8341)
Val loss  tensor(0.9228)
Iteration 85000: total loss 0.0524, losses: [0.05238489434123039], learning rate: 0.0100000000
Iteration 85000: total loss 0.0975, losses: [0.09747093915939331], learning rate: 0.0100000000
Iteration 875000: total loss 0.0470, losses: [0.046971265226602554], learning rate: 0.0096059601
Iteration 875000: total loss 0.0462, losses: [0.04617432877421379], learning rate: 0.0097029900
Iteration 90000: total loss 0.0760, losses: [0.07604566216468811], learning rate: 0.0100000000
Iteration 90000: total loss 0.0721, losses: [0.07212921231985092], learning rate: 0.0100000000
Val loss  tensor(0.8193)
Val loss  tensor(1.0114)
Iteration 880000: total loss 0.0569, losses: [0.05685793235898018], learning rate: 0.0096059601
Iteration 880000: total loss 0.0398, losses: [0.03975860774517059], learning rate: 0.0097029900
Iteration 95000: total loss 0.0643, losses: [0.06426072120666504], learning rate: 0.0100000000
Iteration 95000: total loss 0.0931, losses: [0.0931389331817627], learning rate: 0.0100000000
Val loss  tensor(0.9254)
Val loss  tensor(0.9064)
Iteration 100000: total loss 0.0628, losses: [0.06279201805591583], learning rate: 0.0100000000
Iteration 100000: total loss 0.0786, losses: [0.0785779356956482], learning rate: 0.0100000000
Val loss  tensor(0.7850)
Val loss  tensor(1.0239)
Iteration 885000: total loss 0.0570, losses: [0.05700289085507393], learning rate: 0.0095099005
Iteration 885000: total loss 0.0399, losses: [0.03993500396609306], learning rate: 0.0097029900
Iteration 105000: total loss 0.0758, losses: [0.0757557824254036], learning rate: 0.0100000000
Iteration 105000: total loss 0.0597, losses: [0.05968363583087921], learning rate: 0.0100000000
Iteration 890000: total loss 0.0521, losses: [0.052069395780563354], learning rate: 0.0095099005
Iteration 890000: total loss 0.0375, losses: [0.03750722110271454], learning rate: 0.0097029900
Val loss  tensor(0.9291)
Val loss  tensor(1.0474)
Iteration 110000: total loss 0.0713, losses: [0.071340411901474], learning rate: 0.0100000000
Iteration 110000: total loss 0.0848, losses: [0.08477117121219635], learning rate: 0.0100000000
Val loss  tensor(0.8395)
Val loss  tensor(1.0065)
Iteration 895000: total loss 0.0461, losses: [0.046064771711826324], learning rate: 0.0095099005
Iteration 895000: total loss 0.0436, losses: [0.04359188675880432], learning rate: 0.0097029900
Iteration 115000: total loss 0.0611, losses: [0.06110110878944397], learning rate: 0.0100000000
Iteration 115000: total loss 0.0738, losses: [0.07376528531312943], learning rate: 0.0100000000
Iteration 900000: total loss 0.0483, losses: [0.04830954968929291], learning rate: 0.0095099005
Iteration 900000: total loss 0.0468, losses: [0.04677462577819824], learning rate: 0.0097029900
Val loss  tensor(0.8556)
Val loss  tensor(0.9256)
Iteration 120000: total loss 0.0580, losses: [0.05795087665319443], learning rate: 0.0100000000
Iteration 120000: total loss 0.0754, losses: [0.07541781663894653], learning rate: 0.0100000000
Val loss  tensor(0.7968)
Val loss  tensor(1.0814)
Iteration 905000: total loss 0.0490, losses: [0.04901279881596565], learning rate: 0.0095099005
Iteration 905000: total loss 0.0437, losses: [0.04370551183819771], learning rate: 0.0097029900
Iteration 125000: total loss 0.0663, losses: [0.06629051268100739], learning rate: 0.0100000000
Iteration 125000: total loss 0.0788, losses: [0.07879266142845154], learning rate: 0.0100000000
Iteration 910000: total loss 0.0430, losses: [0.04301761835813522], learning rate: 0.0095099005
Iteration 910000: total loss 0.0399, losses: [0.03993842750787735], learning rate: 0.0097029900
Val loss  tensor(0.9225)
Val loss  tensor(0.8837)
Iteration 130000: total loss 0.0525, losses: [0.052488405257463455], learning rate: 0.0100000000
Iteration 130000: total loss 0.0704, losses: [0.07036732137203217], learning rate: 0.0100000000
Val loss  tensor(0.7784)
Val loss  tensor(1.0375)
Iteration 135000: total loss 0.0421, losses: [0.04207010939717293], learning rate: 0.0100000000
Iteration 135000: total loss 0.0818, losses: [0.0817633718252182], learning rate: 0.0100000000
Iteration 915000: total loss 0.0521, losses: [0.05208524316549301], learning rate: 0.0095099005
Iteration 915000: total loss 0.0461, losses: [0.04605748504400253], learning rate: 0.0096059601
Iteration 140000: total loss 0.0639, losses: [0.06392335891723633], learning rate: 0.0100000000
Iteration 140000: total loss 0.0743, losses: [0.07431602478027344], learning rate: 0.0100000000
Val loss  tensor(0.7470)
Val loss  tensor(1.0096)
Iteration 920000: total loss 0.0501, losses: [0.0501403734087944], learning rate: 0.0095099005
Iteration 920000: total loss 0.0383, losses: [0.03825724124908447], learning rate: 0.0096059601
Val loss  tensor(0.8983)
Val loss  tensor(0.9672)
Iteration 145000: total loss 0.0630, losses: [0.06295524537563324], learning rate: 0.0100000000
Iteration 145000: total loss 0.0655, losses: [0.06551377475261688], learning rate: 0.0100000000
Iteration 925000: total loss 0.0429, losses: [0.04287922382354736], learning rate: 0.0095099005
Iteration 925000: total loss 0.0385, losses: [0.03848308324813843], learning rate: 0.0096059601
Iteration 150000: total loss 0.0597, losses: [0.059654463082551956], learning rate: 0.0100000000
Iteration 150000: total loss 0.0607, losses: [0.06069377809762955], learning rate: 0.0100000000
Val loss  tensor(0.7927)
Val loss  tensor(0.9745)
Iteration 930000: total loss 0.0517, losses: [0.051723264157772064], learning rate: 0.0095099005
Iteration 930000: total loss 0.0419, losses: [0.04186088219285011], learning rate: 0.0096059601
Val loss  tensor(0.8282)
Val loss  tensor(0.9831)
Iteration 155000: total loss 0.0676, losses: [0.06758598983287811], learning rate: 0.0100000000
Iteration 155000: total loss 0.0597, losses: [0.05969487503170967], learning rate: 0.0100000000
Iteration 935000: total loss 0.0506, losses: [0.05055835098028183], learning rate: 0.0095099005
Iteration 935000: total loss 0.0391, losses: [0.03906194865703583], learning rate: 0.0096059601
Iteration 160000: total loss 0.0491, losses: [0.049127161502838135], learning rate: 0.0100000000
Iteration 160000: total loss 0.0532, losses: [0.053191717714071274], learning rate: 0.0100000000
Val loss  tensor(0.8160)
Val loss  tensor(1.0807)
Iteration 940000: total loss 0.0421, losses: [0.04211828112602234], learning rate: 0.0095099005
Iteration 940000: total loss 0.0386, losses: [0.03857046365737915], learning rate: 0.0096059601
Val loss  tensor(0.8198)
Val loss  tensor(1.0047)
Iteration 165000: total loss 0.0517, losses: [0.05170450359582901], learning rate: 0.0100000000
Iteration 165000: total loss 0.0538, losses: [0.05384445935487747], learning rate: 0.0100000000
Iteration 945000: total loss 0.0479, losses: [0.047854527831077576], learning rate: 0.0095099005
Iteration 945000: total loss 0.0496, losses: [0.049579937011003494], learning rate: 0.0096059601
Iteration 170000: total loss 0.0544, losses: [0.05436436086893082], learning rate: 0.0100000000
Iteration 170000: total loss 0.0530, losses: [0.052965544164180756], learning rate: 0.0100000000
Val loss  tensor(0.7851)
Val loss  tensor(0.9063)
Iteration 175000: total loss 0.0629, losses: [0.06287512183189392], learning rate: 0.0100000000
Iteration 175000: total loss 0.0538, losses: [0.05379410833120346], learning rate: 0.0100000000
Iteration 950000: total loss 0.0513, losses: [0.05132881924510002], learning rate: 0.0095099005
Iteration 950000: total loss 0.0361, losses: [0.03607035428285599], learning rate: 0.0096059601
Val loss  tensor(0.8695)
Val loss  tensor(1.0209)
Iteration 180000: total loss 0.0460, losses: [0.0460231751203537], learning rate: 0.0100000000
Iteration 180000: total loss 0.0583, losses: [0.05827592685818672], learning rate: 0.0100000000
Val loss  tensor(0.8179)
Val loss  tensor(0.8920)
Iteration 955000: total loss 0.0474, losses: [0.04740782827138901], learning rate: 0.0095099005
Iteration 955000: total loss 0.0424, losses: [0.042449332773685455], learning rate: 0.0096059601
Iteration 185000: total loss 0.0408, losses: [0.040783584117889404], learning rate: 0.0100000000
Iteration 185000: total loss 0.0563, losses: [0.0562722273170948], learning rate: 0.0100000000
Iteration 960000: total loss 0.0497, losses: [0.04968412220478058], learning rate: 0.0095099005
Iteration 960000: total loss 0.0360, losses: [0.03600411117076874], learning rate: 0.0096059601
Val loss  tensor(0.9025)
Val loss  tensor(0.9453)
Iteration 190000: total loss 0.0508, losses: [0.05077902972698212], learning rate: 0.0100000000
Iteration 190000: total loss 0.0581, losses: [0.058091457933187485], learning rate: 0.0100000000
Val loss  tensor(0.8046)
Val loss  tensor(1.0155)
Iteration 965000: total loss 0.0456, losses: [0.045600391924381256], learning rate: 0.0095099005
Iteration 965000: total loss 0.0430, losses: [0.043044447898864746], learning rate: 0.0096059601
Iteration 195000: total loss 0.0543, losses: [0.05425027012825012], learning rate: 0.0100000000
Iteration 195000: total loss 0.0645, losses: [0.0645410493016243], learning rate: 0.0100000000
Iteration 970000: total loss 0.0499, losses: [0.049876224249601364], learning rate: 0.0095099005
Iteration 970000: total loss 0.0551, losses: [0.05509071797132492], learning rate: 0.0096059601
Val loss  tensor(0.9114)
Val loss  tensor(1.0996)
Iteration 200000: total loss 0.0372, losses: [0.03724460303783417], learning rate: 0.0100000000
Iteration 200000: total loss 0.0578, losses: [0.057808149605989456], learning rate: 0.0100000000
Val loss  tensor(0.7672)
Val loss  tensor(1.2050)
Iteration 975000: total loss 0.0383, losses: [0.03830463066697121], learning rate: 0.0095099005
Iteration 975000: total loss 0.0529, losses: [0.05294426903128624], learning rate: 0.0096059601
Iteration 205000: total loss 0.0624, losses: [0.06238870322704315], learning rate: 0.0100000000
Iteration 205000: total loss 0.0613, losses: [0.06129775196313858], learning rate: 0.0100000000
Iteration 980000: total loss 0.0429, losses: [0.04293276369571686], learning rate: 0.0095099005
Iteration 980000: total loss 0.0382, losses: [0.0382147952914238], learning rate: 0.0096059601
Iteration 210000: total loss 0.0510, losses: [0.050953663885593414], learning rate: 0.0100000000
Iteration 210000: total loss 0.0580, losses: [0.057969704270362854], learning rate: 0.0100000000
Val loss  tensor(0.8738)
Val loss  tensor(0.9926)
Val loss  tensor(0.8591)
Val loss  tensor(1.1156)
Iteration 215000: total loss 0.0499, losses: [0.049936674535274506], learning rate: 0.0100000000
Iteration 215000: total loss 0.0668, losses: [0.06682418286800385], learning rate: 0.0100000000
Iteration 985000: total loss 0.0420, losses: [0.041989877820014954], learning rate: 0.0095099005
Iteration 985000: total loss 0.0456, losses: [0.04556932672858238], learning rate: 0.0096059601
Iteration 220000: total loss 0.0501, losses: [0.050067052245140076], learning rate: 0.0100000000
Iteration 220000: total loss 0.0588, losses: [0.05880323052406311], learning rate: 0.0100000000
Val loss  tensor(0.8636)
Val loss  tensor(1.1294)
Iteration 990000: total loss 0.0415, losses: [0.04147663712501526], learning rate: 0.0095099005
Iteration 990000: total loss 0.0468, losses: [0.046782489866018295], learning rate: 0.0096059601
Val loss  tensor(0.8563)
Val loss  tensor(1.0143)
Iteration 225000: total loss 0.0514, losses: [0.05144375562667847], learning rate: 0.0100000000
Iteration 225000: total loss 0.0535, losses: [0.05345318466424942], learning rate: 0.0100000000
Iteration 995000: total loss 0.0411, losses: [0.04107695817947388], learning rate: 0.0094148015
Iteration 995000: total loss 0.0411, losses: [0.04106058180332184], learning rate: 0.0096059601
Iteration 230000: total loss 0.0498, losses: [0.04982345551252365], learning rate: 0.0100000000
Iteration 230000: total loss 0.0583, losses: [0.05828462541103363], learning rate: 0.0100000000
Val loss  tensor(0.8451)
Val loss  tensor(1.0287)
Iteration 235000: total loss 0.0524, losses: [0.05241280794143677], learning rate: 0.0100000000
Iteration 235000: total loss 0.0614, losses: [0.061442211270332336], learning rate: 0.0100000000
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=32, bias=True)
    (1): SiLU()
    (2): Linear(in_features=32, out_features=32, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=32, out_features=2, bias=True)
  )
)
cuda:1
Folder already there
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=32, bias=True)
    (1): SiLU()
    (2): Linear(in_features=32, out_features=32, bias=True)
    (3): SiLU()
    (4): Linear(in_features=32, out_features=2, bias=True)
  )
)
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=64, bias=True)
    (1): SiLU()
    (2): Linear(in_features=64, out_features=32, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=32, out_features=2, bias=True)
  )
)
cuda:1
Folder already there
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=32, bias=True)
    (1): SiLU()
    (2): Linear(in_features=32, out_features=64, bias=True)
    (3): SiLU()
    (4): Linear(in_features=64, out_features=2, bias=True)
  )
)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
(6879732,)
Iteration 0: total loss 2.4979, losses: [2.4978668689727783], learning rate: 0.0100000000
Iteration 0: total loss 2.6806, losses: [2.6805970668792725], learning rate: 0.0100000000
Val loss  tensor(1.5045)
Val loss  tensor(1.5224)
Iteration 240000: total loss 0.0452, losses: [0.045171745121479034], learning rate: 0.0100000000
Iteration 240000: total loss 0.0618, losses: [0.06181599944829941], learning rate: 0.0100000000
Val loss  tensor(0.8757)
Val loss  tensor(0.9631)
Iteration 5000: total loss 0.2100, losses: [0.21003440022468567], learning rate: 0.0100000000
Iteration 5000: total loss 0.2413, losses: [0.24130180478096008], learning rate: 0.0100000000
Iteration 245000: total loss 0.0495, losses: [0.04952168092131615], learning rate: 0.0100000000
Iteration 245000: total loss 0.0592, losses: [0.0592307411134243], learning rate: 0.0100000000
Iteration 10000: total loss 0.1783, losses: [0.17826852202415466], learning rate: 0.0100000000
Iteration 10000: total loss 0.1368, losses: [0.13682273030281067], learning rate: 0.0100000000
Val loss  tensor(1.1033)
Val loss  tensor(1.2566)
Iteration 250000: total loss 0.0459, losses: [0.045894838869571686], learning rate: 0.0100000000
Iteration 250000: total loss 0.0589, losses: [0.058873891830444336], learning rate: 0.0100000000
Val loss  tensor(0.8291)
Val loss  tensor(0.9370)
Iteration 15000: total loss 0.1692, losses: [0.16918891668319702], learning rate: 0.0100000000
Iteration 15000: total loss 0.1377, losses: [0.1376984417438507], learning rate: 0.0100000000
Iteration 255000: total loss 0.0538, losses: [0.053828541189432144], learning rate: 0.0099000000
Iteration 255000: total loss 0.0665, losses: [0.06646884232759476], learning rate: 0.0100000000
Iteration 260000: total loss 0.0437, losses: [0.04367321357131004], learning rate: 0.0099000000
Iteration 260000: total loss 0.0573, losses: [0.05726819485425949], learning rate: 0.0100000000
Val loss  tensor(0.8455)
Val loss  tensor(0.9627)
Iteration 20000: total loss 0.1537, losses: [0.15371006727218628], learning rate: 0.0100000000
Iteration 20000: total loss 0.1096, losses: [0.10962876677513123], learning rate: 0.0100000000
Val loss  tensor(1.1582)
Val loss  tensor(1.0792)
Iteration 265000: total loss 0.0494, losses: [0.04937518388032913], learning rate: 0.0099000000
Iteration 265000: total loss 0.0593, losses: [0.059289075434207916], learning rate: 0.0100000000
Iteration 25000: total loss 0.1431, losses: [0.1430906057357788], learning rate: 0.0100000000
Iteration 25000: total loss 0.1286, losses: [0.1285959780216217], learning rate: 0.0100000000
Iteration 270000: total loss 0.0563, losses: [0.056314077228307724], learning rate: 0.0099000000
Iteration 270000: total loss 0.0600, losses: [0.05998718738555908], learning rate: 0.0100000000
Val loss  tensor(0.9211)
Val loss  tensor(0.7618)
Iteration 30000: total loss 0.1269, losses: [0.12693890929222107], learning rate: 0.0100000000
Iteration 30000: total loss 0.1004, losses: [0.10044290870428085], learning rate: 0.0100000000
Val loss  tensor(0.9714)
Val loss  tensor(0.9815)
Iteration 275000: total loss 0.0423, losses: [0.04228727146983147], learning rate: 0.0099000000
Iteration 275000: total loss 0.0561, losses: [0.056144680827856064], learning rate: 0.0100000000
Iteration 35000: total loss 0.1306, losses: [0.13061389327049255], learning rate: 0.0100000000
Iteration 35000: total loss 0.0994, losses: [0.09943274408578873], learning rate: 0.0100000000
Iteration 280000: total loss 0.0462, losses: [0.046214759349823], learning rate: 0.0099000000
Iteration 280000: total loss 0.0559, losses: [0.0559416264295578], learning rate: 0.0100000000
Val loss  tensor(0.8570)
Val loss  tensor(0.8079)
Iteration 40000: total loss 0.1291, losses: [0.12907642126083374], learning rate: 0.0100000000
Iteration 40000: total loss 0.0893, losses: [0.0893050879240036], learning rate: 0.0100000000
Val loss  tensor(1.1618)
Val loss  tensor(0.9446)
Iteration 285000: total loss 0.0447, losses: [0.04471861571073532], learning rate: 0.0099000000
Iteration 285000: total loss 0.0531, losses: [0.05307522043585777], learning rate: 0.0100000000
Iteration 290000: total loss 0.0337, losses: [0.03373263031244278], learning rate: 0.0099000000
Iteration 290000: total loss 0.0526, losses: [0.05255397409200668], learning rate: 0.0100000000
Val loss  tensor(0.8179)
Val loss  tensor(0.8692)
Iteration 45000: total loss 0.1038, losses: [0.10380616784095764], learning rate: 0.0100000000
Iteration 45000: total loss 0.0891, losses: [0.08912651240825653], learning rate: 0.0100000000
Iteration 295000: total loss 0.0401, losses: [0.04013616964221001], learning rate: 0.0099000000
Iteration 295000: total loss 0.0644, losses: [0.06437576562166214], learning rate: 0.0100000000
Iteration 50000: total loss 0.0949, losses: [0.0948876291513443], learning rate: 0.0100000000
Iteration 50000: total loss 0.0815, losses: [0.08146457374095917], learning rate: 0.0100000000
Val loss  tensor(1.1644)
Val loss  tensor(1.1236)
Iteration 300000: total loss 0.0478, losses: [0.04778756573796272], learning rate: 0.0099000000
Iteration 300000: total loss 0.0479, losses: [0.04785037785768509], learning rate: 0.0100000000
Val loss  tensor(0.7927)
Val loss  tensor(0.8967)
Iteration 55000: total loss 0.0981, losses: [0.09809364378452301], learning rate: 0.0100000000
Iteration 55000: total loss 0.0656, losses: [0.06562134623527527], learning rate: 0.0100000000
Iteration 305000: total loss 0.0377, losses: [0.037712253630161285], learning rate: 0.0099000000
Iteration 305000: total loss 0.0521, losses: [0.05205173417925835], learning rate: 0.0100000000
Iteration 60000: total loss 0.1135, losses: [0.11352016031742096], learning rate: 0.0100000000
Iteration 60000: total loss 0.0758, losses: [0.07578699290752411], learning rate: 0.0100000000
Val loss  tensor(1.1470)
Val loss  tensor(1.1944)
Iteration 310000: total loss 0.0419, losses: [0.04191136360168457], learning rate: 0.0099000000
Iteration 310000: total loss 0.0489, losses: [0.04891353100538254], learning rate: 0.0100000000
Val loss  tensor(0.7526)
Val loss  tensor(0.9519)
Iteration 65000: total loss 0.0980, losses: [0.09804441034793854], learning rate: 0.0100000000
Iteration 65000: total loss 0.0796, losses: [0.07958967983722687], learning rate: 0.0100000000
Iteration 315000: total loss 0.0428, losses: [0.0427815280854702], learning rate: 0.0099000000
Iteration 315000: total loss 0.0510, losses: [0.051030825823545456], learning rate: 0.0100000000
Iteration 70000: total loss 0.0915, losses: [0.09154359996318817], learning rate: 0.0100000000
Iteration 70000: total loss 0.0670, losses: [0.06696105748414993], learning rate: 0.0100000000
Val loss  tensor(1.1928)
Val loss  tensor(0.9415)
Iteration 320000: total loss 0.0585, losses: [0.05854060500860214], learning rate: 0.0099000000
Iteration 320000: total loss 0.0530, losses: [0.05295582115650177], learning rate: 0.0100000000
Val loss  tensor(0.8195)
Val loss  tensor(0.9220)
Iteration 325000: total loss 0.0450, losses: [0.04502083733677864], learning rate: 0.0099000000
Iteration 325000: total loss 0.0457, losses: [0.04567047208547592], learning rate: 0.0100000000
Iteration 75000: total loss 0.0900, losses: [0.08995987474918365], learning rate: 0.0100000000
Iteration 75000: total loss 0.0747, losses: [0.07469013333320618], learning rate: 0.0100000000
Iteration 330000: total loss 0.0508, losses: [0.05078066885471344], learning rate: 0.0099000000
Iteration 330000: total loss 0.0530, losses: [0.05299832299351692], learning rate: 0.0100000000
Val loss  tensor(0.6793)
Val loss  tensor(0.9373)
Iteration 80000: total loss 0.0925, losses: [0.09251223504543304], learning rate: 0.0100000000
Iteration 80000: total loss 0.0768, losses: [0.07680832594633102], learning rate: 0.0100000000
Val loss  tensor(1.0990)
Val loss  tensor(1.2224)
Iteration 335000: total loss 0.0450, losses: [0.04500659927725792], learning rate: 0.0099000000
Iteration 335000: total loss 0.0515, losses: [0.05150413513183594], learning rate: 0.0100000000
Iteration 85000: total loss 0.0797, losses: [0.07970882207155228], learning rate: 0.0100000000
Iteration 85000: total loss 0.0585, losses: [0.058489806950092316], learning rate: 0.0100000000
Iteration 340000: total loss 0.0388, losses: [0.038809604942798615], learning rate: 0.0099000000
Iteration 340000: total loss 0.0463, losses: [0.04631165415048599], learning rate: 0.0100000000
Val loss  tensor(0.8100)
Val loss  tensor(0.7893)
Iteration 90000: total loss 0.0793, losses: [0.07929709553718567], learning rate: 0.0100000000
Iteration 90000: total loss 0.0770, losses: [0.0769549086689949], learning rate: 0.0100000000
Val loss  tensor(1.0133)
Val loss  tensor(0.9306)
Iteration 345000: total loss 0.0447, losses: [0.04473082721233368], learning rate: 0.0099000000
Iteration 345000: total loss 0.0419, losses: [0.04189684987068176], learning rate: 0.0100000000
Iteration 95000: total loss 0.0822, losses: [0.08222290128469467], learning rate: 0.0100000000
Iteration 95000: total loss 0.0641, losses: [0.06407752633094788], learning rate: 0.0100000000
Iteration 350000: total loss 0.0414, losses: [0.04139607399702072], learning rate: 0.0099000000
Iteration 350000: total loss 0.0479, losses: [0.0479050874710083], learning rate: 0.0100000000
Val loss  tensor(0.7973)
Val loss  tensor(0.7896)
Iteration 100000: total loss 0.0933, losses: [0.09327029436826706], learning rate: 0.0100000000
Iteration 100000: total loss 0.0714, losses: [0.07144437730312347], learning rate: 0.0100000000
Val loss  tensor(1.0335)
Val loss  tensor(0.9536)
Iteration 355000: total loss 0.0428, losses: [0.04280555993318558], learning rate: 0.0099000000
Iteration 355000: total loss 0.0524, losses: [0.052393220365047455], learning rate: 0.0100000000
Iteration 360000: total loss 0.0452, losses: [0.04521305859088898], learning rate: 0.0099000000
Iteration 360000: total loss 0.0566, losses: [0.05656242370605469], learning rate: 0.0100000000
Val loss  tensor(0.7381)
Val loss  tensor(0.8746)
Iteration 105000: total loss 0.0862, losses: [0.08618796616792679], learning rate: 0.0100000000
Iteration 105000: total loss 0.0641, losses: [0.06410305947065353], learning rate: 0.0100000000
Iteration 365000: total loss 0.0423, losses: [0.04233287647366524], learning rate: 0.0099000000
Iteration 365000: total loss 0.0498, losses: [0.04976474493741989], learning rate: 0.0100000000
Iteration 110000: total loss 0.0711, losses: [0.07108412683010101], learning rate: 0.0100000000
Iteration 110000: total loss 0.0700, losses: [0.06999240815639496], learning rate: 0.0100000000
Val loss  tensor(1.0488)
Val loss  tensor(0.9881)
Iteration 370000: total loss 0.0433, losses: [0.04326333478093147], learning rate: 0.0099000000
Iteration 370000: total loss 0.0456, losses: [0.04560350626707077], learning rate: 0.0100000000
Val loss  tensor(0.7249)
Val loss  tensor(0.7953)
Iteration 115000: total loss 0.0710, losses: [0.07096660137176514], learning rate: 0.0100000000
Iteration 115000: total loss 0.0632, losses: [0.06322532892227173], learning rate: 0.0100000000
Iteration 375000: total loss 0.0521, losses: [0.05209220200777054], learning rate: 0.0099000000
Iteration 375000: total loss 0.0439, losses: [0.0438537560403347], learning rate: 0.0100000000
Iteration 120000: total loss 0.0663, losses: [0.06628727167844772], learning rate: 0.0100000000
Iteration 120000: total loss 0.0636, losses: [0.06359478831291199], learning rate: 0.0100000000
Val loss  tensor(1.0758)
Val loss  tensor(0.9344)
Iteration 380000: total loss 0.0406, losses: [0.04055473953485489], learning rate: 0.0099000000
Iteration 380000: total loss 0.0442, losses: [0.04416453838348389], learning rate: 0.0100000000
Val loss  tensor(0.7133)
Val loss  tensor(0.8267)
Iteration 125000: total loss 0.0735, losses: [0.07351259887218475], learning rate: 0.0100000000
Iteration 125000: total loss 0.0684, losses: [0.06836692243814468], learning rate: 0.0100000000
Iteration 385000: total loss 0.0359, losses: [0.03586375713348389], learning rate: 0.0099000000
Iteration 385000: total loss 0.0484, losses: [0.04844556003808975], learning rate: 0.0100000000
Iteration 390000: total loss 0.0433, losses: [0.04325125366449356], learning rate: 0.0099000000
Iteration 390000: total loss 0.0428, losses: [0.04279091954231262], learning rate: 0.0100000000
Iteration 130000: total loss 0.0686, losses: [0.06856134533882141], learning rate: 0.0100000000
Iteration 130000: total loss 0.0612, losses: [0.061220284551382065], learning rate: 0.0100000000
Val loss  tensor(0.7027)
Val loss  tensor(0.8015)
Val loss  tensor(1.0667)
Val loss  tensor(0.9298)
Iteration 395000: total loss 0.0400, losses: [0.03995596989989281], learning rate: 0.0099000000
Iteration 395000: total loss 0.0440, losses: [0.04397150129079819], learning rate: 0.0100000000
Iteration 135000: total loss 0.0724, losses: [0.07238420844078064], learning rate: 0.0100000000
Iteration 135000: total loss 0.0595, losses: [0.059460848569869995], learning rate: 0.0100000000
Iteration 400000: total loss 0.0339, losses: [0.033933013677597046], learning rate: 0.0099000000
Iteration 400000: total loss 0.0464, losses: [0.046390045434236526], learning rate: 0.0100000000
Val loss  tensor(0.8271)
Val loss  tensor(0.7510)
Iteration 140000: total loss 0.0687, losses: [0.06874407082796097], learning rate: 0.0100000000
Iteration 140000: total loss 0.0600, losses: [0.06000704690814018], learning rate: 0.0100000000
Val loss  tensor(1.0569)
Val loss  tensor(0.9285)
Iteration 405000: total loss 0.0410, losses: [0.04101167991757393], learning rate: 0.0099000000
Iteration 405000: total loss 0.0472, losses: [0.047204311937093735], learning rate: 0.0100000000
Iteration 145000: total loss 0.0660, losses: [0.0660477951169014], learning rate: 0.0099000000
Iteration 145000: total loss 0.0528, losses: [0.05284666642546654], learning rate: 0.0100000000
Iteration 410000: total loss 0.0348, losses: [0.034808624535799026], learning rate: 0.0099000000
Iteration 410000: total loss 0.0453, losses: [0.04534663259983063], learning rate: 0.0100000000
Val loss  tensor(0.7429)
Val loss  tensor(0.8157)
Iteration 150000: total loss 0.0632, losses: [0.06321842968463898], learning rate: 0.0099000000
Iteration 150000: total loss 0.0585, losses: [0.05854922533035278], learning rate: 0.0100000000
Val loss  tensor(0.9981)
Val loss  tensor(0.9249)
Iteration 415000: total loss 0.0322, losses: [0.03222791105508804], learning rate: 0.0099000000
Iteration 415000: total loss 0.0505, losses: [0.05054137483239174], learning rate: 0.0100000000
Iteration 155000: total loss 0.0718, losses: [0.07183045148849487], learning rate: 0.0099000000
Iteration 155000: total loss 0.0601, losses: [0.06013362854719162], learning rate: 0.0100000000
Iteration 420000: total loss 0.0360, losses: [0.03604768216609955], learning rate: 0.0099000000
Iteration 420000: total loss 0.0387, losses: [0.03874872624874115], learning rate: 0.0100000000
Val loss  tensor(0.6948)
Val loss  tensor(0.7888)
Iteration 425000: total loss 0.0388, losses: [0.03881986439228058], learning rate: 0.0099000000
Iteration 425000: total loss 0.0564, losses: [0.05643455684185028], learning rate: 0.0100000000
Iteration 160000: total loss 0.0689, losses: [0.06886233389377594], learning rate: 0.0099000000
Iteration 160000: total loss 0.0639, losses: [0.06391020119190216], learning rate: 0.0100000000
Val loss  tensor(0.9846)
Val loss  tensor(0.9074)
Iteration 430000: total loss 0.0391, losses: [0.03908812999725342], learning rate: 0.0099000000
Iteration 430000: total loss 0.0492, losses: [0.04920949786901474], learning rate: 0.0100000000
Val loss  tensor(0.7172)
Val loss  tensor(0.8252)
Iteration 165000: total loss 0.0681, losses: [0.06814100593328476], learning rate: 0.0099000000
Iteration 165000: total loss 0.0555, losses: [0.0554959699511528], learning rate: 0.0100000000
Iteration 435000: total loss 0.0423, losses: [0.04228094220161438], learning rate: 0.0099000000
Iteration 435000: total loss 0.0494, losses: [0.049384988844394684], learning rate: 0.0100000000
Iteration 170000: total loss 0.0554, losses: [0.055360790342092514], learning rate: 0.0099000000
Iteration 170000: total loss 0.0480, losses: [0.04800233244895935], learning rate: 0.0100000000
Val loss  tensor(1.0461)
Val loss  tensor(0.8650)
Iteration 440000: total loss 0.0378, losses: [0.03775494545698166], learning rate: 0.0099000000
Iteration 440000: total loss 0.0563, losses: [0.056256718933582306], learning rate: 0.0100000000
Val loss  tensor(0.7281)
Val loss  tensor(0.7737)
Iteration 175000: total loss 0.0569, losses: [0.05686184763908386], learning rate: 0.0099000000
Iteration 175000: total loss 0.0537, losses: [0.05367215722799301], learning rate: 0.0100000000
Iteration 445000: total loss 0.0474, losses: [0.047410354018211365], learning rate: 0.0100000000
Iteration 445000: total loss 0.0336, losses: [0.03363953158259392], learning rate: 0.0098010000
Iteration 180000: total loss 0.0506, losses: [0.05059291049838066], learning rate: 0.0099000000
Iteration 180000: total loss 0.0539, losses: [0.053869202733039856], learning rate: 0.0100000000
Val loss  tensor(1.1047)
Val loss  tensor(0.8710)
Iteration 450000: total loss 0.0422, losses: [0.04221479967236519], learning rate: 0.0100000000
Iteration 450000: total loss 0.0421, losses: [0.042085032910108566], learning rate: 0.0098010000
Val loss  tensor(0.7902)
Val loss  tensor(0.7351)
Iteration 185000: total loss 0.0600, losses: [0.060005441308021545], learning rate: 0.0099000000
Iteration 185000: total loss 0.0658, losses: [0.0657600462436676], learning rate: 0.0100000000
Iteration 455000: total loss 0.0421, losses: [0.04205688089132309], learning rate: 0.0098010000
Iteration 455000: total loss 0.0480, losses: [0.0480254702270031], learning rate: 0.0100000000
Iteration 460000: total loss 0.0373, losses: [0.03730747103691101], learning rate: 0.0098010000
Iteration 460000: total loss 0.0402, losses: [0.040193505585193634], learning rate: 0.0100000000
Val loss  tensor(0.7946)
Val loss  tensor(0.6810)
Iteration 190000: total loss 0.0650, losses: [0.06495796144008636], learning rate: 0.0099000000
Iteration 190000: total loss 0.0453, losses: [0.04531538859009743], learning rate: 0.0100000000
Val loss  tensor(1.0449)
Val loss  tensor(0.8498)
Iteration 465000: total loss 0.0326, losses: [0.03255189210176468], learning rate: 0.0098010000
Iteration 465000: total loss 0.0447, losses: [0.044654957950115204], learning rate: 0.0100000000
Iteration 195000: total loss 0.0731, losses: [0.07308486104011536], learning rate: 0.0099000000
Iteration 195000: total loss 0.0491, losses: [0.04907862842082977], learning rate: 0.0100000000
Iteration 470000: total loss 0.0396, losses: [0.039592351764440536], learning rate: 0.0098010000
Iteration 470000: total loss 0.0517, losses: [0.0517132505774498], learning rate: 0.0100000000
Val loss  tensor(0.6420)
Val loss  tensor(0.8064)
Iteration 200000: total loss 0.0662, losses: [0.06621986627578735], learning rate: 0.0099000000
Iteration 200000: total loss 0.0506, losses: [0.050634320825338364], learning rate: 0.0100000000
Val loss  tensor(1.0301)
Val loss  tensor(0.8805)
Iteration 475000: total loss 0.0325, losses: [0.03246583044528961], learning rate: 0.0098010000
Iteration 475000: total loss 0.0436, losses: [0.043568842113018036], learning rate: 0.0100000000
Iteration 205000: total loss 0.0671, losses: [0.06707435101270676], learning rate: 0.0099000000
Iteration 205000: total loss 0.0633, losses: [0.06331658363342285], learning rate: 0.0100000000
Iteration 480000: total loss 0.0334, losses: [0.03337254747748375], learning rate: 0.0098010000
Iteration 480000: total loss 0.0461, losses: [0.04612250626087189], learning rate: 0.0100000000
Val loss  tensor(0.6811)
Val loss  tensor(0.7914)
Iteration 210000: total loss 0.0550, losses: [0.054991766810417175], learning rate: 0.0099000000
Iteration 210000: total loss 0.0686, losses: [0.06856752932071686], learning rate: 0.0100000000
Val loss  tensor(1.1008)
Val loss  tensor(0.8865)
Iteration 485000: total loss 0.0347, losses: [0.03473151475191116], learning rate: 0.0098010000
Iteration 485000: total loss 0.0513, losses: [0.05131521821022034], learning rate: 0.0100000000
Iteration 215000: total loss 0.0656, losses: [0.06558965891599655], learning rate: 0.0099000000
Iteration 215000: total loss 0.0518, losses: [0.051776763051748276], learning rate: 0.0100000000
Iteration 490000: total loss 0.0335, losses: [0.03347838670015335], learning rate: 0.0098010000
Iteration 490000: total loss 0.0344, losses: [0.03443969786167145], learning rate: 0.0100000000
Val loss  tensor(0.6665)
Val loss  tensor(0.7805)
Iteration 495000: total loss 0.0331, losses: [0.033147428184747696], learning rate: 0.0098010000
Iteration 495000: total loss 0.0468, losses: [0.0468280091881752], learning rate: 0.0100000000
Iteration 220000: total loss 0.0632, losses: [0.0632161796092987], learning rate: 0.0099000000
Iteration 220000: total loss 0.0466, losses: [0.046567924320697784], learning rate: 0.0100000000
Val loss  tensor(1.0221)
Val loss  tensor(0.8414)
Iteration 500000: total loss 0.0407, losses: [0.04073936492204666], learning rate: 0.0098010000
Iteration 500000: total loss 0.0470, losses: [0.04702576622366905], learning rate: 0.0100000000
Val loss  tensor(0.7052)
Val loss  tensor(0.7788)
Iteration 225000: total loss 0.0526, losses: [0.05264165252447128], learning rate: 0.0099000000
Iteration 225000: total loss 0.0736, losses: [0.07363177090883255], learning rate: 0.0100000000
Iteration 505000: total loss 0.0353, losses: [0.035324838012456894], learning rate: 0.0098010000
Iteration 505000: total loss 0.0544, losses: [0.05435096472501755], learning rate: 0.0100000000
Iteration 230000: total loss 0.0532, losses: [0.05318333953619003], learning rate: 0.0099000000
Iteration 230000: total loss 0.0415, losses: [0.04148080572485924], learning rate: 0.0100000000
Val loss  tensor(0.9977)
Val loss  tensor(0.7905)
Iteration 510000: total loss 0.0361, losses: [0.036078620702028275], learning rate: 0.0098010000
Iteration 510000: total loss 0.0503, losses: [0.05025198310613632], learning rate: 0.0100000000
Val loss  tensor(0.6241)
Val loss  tensor(0.8137)
Iteration 235000: total loss 0.0669, losses: [0.0668741837143898], learning rate: 0.0099000000
Iteration 235000: total loss 0.0455, losses: [0.04548771306872368], learning rate: 0.0100000000
Iteration 515000: total loss 0.0400, losses: [0.0399991050362587], learning rate: 0.0098010000
Iteration 515000: total loss 0.0484, losses: [0.048351310193538666], learning rate: 0.0100000000
Iteration 240000: total loss 0.0630, losses: [0.06301991641521454], learning rate: 0.0099000000
Iteration 240000: total loss 0.0420, losses: [0.04204180836677551], learning rate: 0.0100000000
Val loss  tensor(1.0440)
Val loss  tensor(0.7699)
Iteration 520000: total loss 0.0331, losses: [0.03314993530511856], learning rate: 0.0098010000
Iteration 520000: total loss 0.0485, losses: [0.04848965257406235], learning rate: 0.0100000000
Val loss  tensor(0.6457)
Val loss  tensor(0.7135)
Iteration 525000: total loss 0.0486, losses: [0.04856792092323303], learning rate: 0.0100000000
Iteration 525000: total loss 0.0285, losses: [0.028543122112751007], learning rate: 0.0098010000
Iteration 245000: total loss 0.0520, losses: [0.05202380195260048], learning rate: 0.0099000000
Iteration 245000: total loss 0.0563, losses: [0.05634969100356102], learning rate: 0.0100000000
Iteration 530000: total loss 0.0370, losses: [0.036970190703868866], learning rate: 0.0098010000
Iteration 530000: total loss 0.0502, losses: [0.05019968003034592], learning rate: 0.0100000000
Val loss  tensor(0.7978)
Val loss  tensor(0.6355)
Iteration 250000: total loss 0.0514, losses: [0.05143040046095848], learning rate: 0.0099000000
Iteration 250000: total loss 0.0509, losses: [0.05089109018445015], learning rate: 0.0100000000
Val loss  tensor(0.9251)
Val loss  tensor(0.7809)
Iteration 535000: total loss 0.0341, losses: [0.03408866375684738], learning rate: 0.0098010000
Iteration 535000: total loss 0.0376, losses: [0.037577878683805466], learning rate: 0.0100000000
Iteration 255000: total loss 0.0507, losses: [0.05071858689188957], learning rate: 0.0099000000
Iteration 255000: total loss 0.0498, losses: [0.04981602728366852], learning rate: 0.0100000000
Iteration 540000: total loss 0.0302, losses: [0.030218161642551422], learning rate: 0.0098010000
Iteration 540000: total loss 0.0449, losses: [0.04487428441643715], learning rate: 0.0100000000
Val loss  tensor(0.6286)
Val loss  tensor(0.7630)
Iteration 260000: total loss 0.0476, losses: [0.04757425934076309], learning rate: 0.0099000000
Iteration 260000: total loss 0.0452, losses: [0.045207731425762177], learning rate: 0.0100000000
Val loss  tensor(0.9678)
Val loss  tensor(0.8094)
Iteration 545000: total loss 0.0371, losses: [0.037110041826963425], learning rate: 0.0098010000
Iteration 545000: total loss 0.0463, losses: [0.046324484050273895], learning rate: 0.0100000000
Iteration 265000: total loss 0.0581, losses: [0.05807727575302124], learning rate: 0.0099000000
Iteration 265000: total loss 0.0524, losses: [0.05238235741853714], learning rate: 0.0100000000
Iteration 550000: total loss 0.0273, losses: [0.02730049565434456], learning rate: 0.0098010000
Iteration 550000: total loss 0.0544, losses: [0.05442008748650551], learning rate: 0.0100000000
Val loss  tensor(0.6039)
Val loss  tensor(0.8159)
Iteration 270000: total loss 0.0584, losses: [0.05837533622980118], learning rate: 0.0099000000
Iteration 270000: total loss 0.0465, losses: [0.04653218016028404], learning rate: 0.0100000000
Val loss  tensor(0.8986)
Val loss  tensor(0.8416)
Iteration 555000: total loss 0.0361, losses: [0.03613977134227753], learning rate: 0.0098010000
Iteration 555000: total loss 0.0429, losses: [0.04293639957904816], learning rate: 0.0100000000
Iteration 275000: total loss 0.0820, losses: [0.08200736343860626], learning rate: 0.0099000000
Iteration 275000: total loss 0.0680, losses: [0.06797537207603455], learning rate: 0.0100000000
Iteration 560000: total loss 0.0335, losses: [0.03353644162416458], learning rate: 0.0098010000
Val loss  tensor(0.6510)
Iteration 560000: total loss 0.0432, losses: [0.043210308998823166], learning rate: 0.0100000000
Val loss  tensor(0.7359)
Iteration 280000: total loss 0.0618, losses: [0.061799753457307816], learning rate: 0.0099000000
Iteration 280000: total loss 0.0631, losses: [0.063099205493927], learning rate: 0.0100000000
Val loss  tensor(0.9597)
Val loss  tensor(0.8973)
Iteration 565000: total loss 0.0351, losses: [0.03506779670715332], learning rate: 0.0098010000
Iteration 565000: total loss 0.0464, losses: [0.04639267176389694], learning rate: 0.0100000000
Iteration 285000: total loss 0.0665, losses: [0.06645974516868591], learning rate: 0.0099000000
Iteration 285000: total loss 0.0504, losses: [0.05036187171936035], learning rate: 0.0100000000
Iteration 570000: total loss 0.0386, losses: [0.0385989174246788], learning rate: 0.0098010000
Iteration 570000: total loss 0.0375, losses: [0.03752198442816734], learning rate: 0.0100000000
Val loss  tensor(0.6343)
Val loss  tensor(0.7730)
Iteration 290000: total loss 0.0673, losses: [0.06728076189756393], learning rate: 0.0099000000
Iteration 290000: total loss 0.0617, losses: [0.06166943162679672], learning rate: 0.0100000000
Val loss  tensor(0.8426)
Val loss  tensor(0.7933)
Iteration 295000: total loss 0.0721, losses: [0.07206016033887863], learning rate: 0.0099000000
Iteration 295000: total loss 0.0485, losses: [0.048467181622982025], learning rate: 0.0100000000
Iteration 575000: total loss 0.0317, losses: [0.03165709599852562], learning rate: 0.0098010000
Iteration 575000: total loss 0.0455, losses: [0.04547325521707535], learning rate: 0.0100000000
Iteration 300000: total loss 0.0511, losses: [0.051084283739328384], learning rate: 0.0099000000
Iteration 300000: total loss 0.0548, losses: [0.054776713252067566], learning rate: 0.0100000000
Val loss  tensor(0.9658)
Val loss  tensor(0.7839)
Iteration 580000: total loss 0.0294, losses: [0.02941109426319599], learning rate: 0.0098010000
Iteration 580000: total loss 0.0403, losses: [0.04026007652282715], learning rate: 0.0100000000
Val loss  tensor(0.6604)
Val loss  tensor(0.8654)
Iteration 305000: total loss 0.0546, losses: [0.054613418877124786], learning rate: 0.0099000000
Iteration 305000: total loss 0.0533, losses: [0.053332552313804626], learning rate: 0.0100000000
Iteration 585000: total loss 0.0311, losses: [0.0311370100826025], learning rate: 0.0098010000
Iteration 585000: total loss 0.0502, losses: [0.050204239785671234], learning rate: 0.0100000000
Iteration 310000: total loss 0.0571, losses: [0.05706619471311569], learning rate: 0.0099000000
Iteration 310000: total loss 0.0523, losses: [0.05225815251469612], learning rate: 0.0100000000
Val loss  tensor(0.9387)
Val loss  tensor(0.8813)
Iteration 590000: total loss 0.0314, losses: [0.031446825712919235], learning rate: 0.0098010000
Iteration 590000: total loss 0.0463, losses: [0.046274375170469284], learning rate: 0.0100000000
Val loss  tensor(0.6298)
Val loss  tensor(0.7572)
Iteration 315000: total loss 0.0566, losses: [0.05655689537525177], learning rate: 0.0099000000
Iteration 315000: total loss 0.0471, losses: [0.04706186801195145], learning rate: 0.0100000000
Iteration 595000: total loss 0.0283, losses: [0.028316909447312355], learning rate: 0.0098010000
Iteration 595000: total loss 0.0481, losses: [0.048051998019218445], learning rate: 0.0100000000
Iteration 320000: total loss 0.0520, losses: [0.051954757422208786], learning rate: 0.0099000000
Iteration 320000: total loss 0.0576, losses: [0.05756991356611252], learning rate: 0.0100000000
Val loss  tensor(0.8699)
Val loss  tensor(0.8200)
Iteration 325000: total loss 0.0415, losses: [0.04149385169148445], learning rate: 0.0100000000
Iteration 325000: total loss 0.0577, losses: [0.057682402431964874], learning rate: 0.0099000000
Iteration 600000: total loss 0.0303, losses: [0.030285587534308434], learning rate: 0.0098010000
Iteration 600000: total loss 0.0424, losses: [0.042408786714076996], learning rate: 0.0100000000
Val loss  tensor(0.5854)
Val loss  tensor(0.7187)
Iteration 330000: total loss 0.0573, losses: [0.05726108327507973], learning rate: 0.0099000000
Iteration 330000: total loss 0.0438, losses: [0.04377394914627075], learning rate: 0.0100000000
Val loss  tensor(0.8440)
Val loss  tensor(0.8035)
Iteration 605000: total loss 0.0305, losses: [0.030459679663181305], learning rate: 0.0098010000
Iteration 605000: total loss 0.0415, losses: [0.04148443788290024], learning rate: 0.0100000000
Iteration 335000: total loss 0.0522, losses: [0.052178919315338135], learning rate: 0.0099000000
Iteration 335000: total loss 0.0418, losses: [0.041779421269893646], learning rate: 0.0100000000
Iteration 610000: total loss 0.0298, losses: [0.02984493598341942], learning rate: 0.0098010000
Iteration 610000: total loss 0.0382, losses: [0.038224849849939346], learning rate: 0.0100000000
Val loss  tensor(0.5661)
Val loss  tensor(0.8258)
Iteration 340000: total loss 0.0554, losses: [0.05535168945789337], learning rate: 0.0099000000
Iteration 340000: total loss 0.0448, losses: [0.0447518527507782], learning rate: 0.0100000000
Val loss  tensor(0.9148)
Val loss  tensor(0.8116)
Iteration 615000: total loss 0.0364, losses: [0.03644309565424919], learning rate: 0.0098010000
Iteration 615000: total loss 0.0472, losses: [0.047157589346170425], learning rate: 0.0100000000
Iteration 345000: total loss 0.0501, losses: [0.05014606565237045], learning rate: 0.0099000000
Iteration 345000: total loss 0.0486, losses: [0.048585161566734314], learning rate: 0.0100000000
Iteration 620000: total loss 0.0305, losses: [0.03048449382185936], learning rate: 0.0098010000
Iteration 620000: total loss 0.0515, losses: [0.05151342228055], learning rate: 0.0100000000
Val loss  tensor(0.6624)
Val loss  tensor(0.7956)
Iteration 350000: total loss 0.0522, losses: [0.0522330142557621], learning rate: 0.0099000000
Iteration 350000: total loss 0.0444, losses: [0.04438076168298721], learning rate: 0.0100000000
Val loss  tensor(0.8998)
Val loss  tensor(0.8248)
Iteration 625000: total loss 0.0259, losses: [0.025921303778886795], learning rate: 0.0098010000
Iteration 625000: total loss 0.0483, losses: [0.048326276242733], learning rate: 0.0100000000
Iteration 355000: total loss 0.0647, losses: [0.06469910591840744], learning rate: 0.0099000000
Iteration 355000: total loss 0.0633, losses: [0.06334000825881958], learning rate: 0.0099000000
Iteration 630000: total loss 0.0343, losses: [0.03427596390247345], learning rate: 0.0098010000
Iteration 630000: total loss 0.0388, losses: [0.038812533020973206], learning rate: 0.0100000000
Val loss  tensor(0.5744)
Val loss  tensor(0.9167)
Iteration 360000: total loss 0.0452, losses: [0.045229941606521606], learning rate: 0.0099000000
Iteration 360000: total loss 0.0553, losses: [0.05528351664543152], learning rate: 0.0099000000
Val loss  tensor(0.9169)
Val loss  tensor(0.8324)
Iteration 635000: total loss 0.0326, losses: [0.03256498649716377], learning rate: 0.0098010000
Iteration 635000: total loss 0.0418, losses: [0.041798025369644165], learning rate: 0.0099000000
Iteration 365000: total loss 0.0590, losses: [0.05904778838157654], learning rate: 0.0099000000
Iteration 365000: total loss 0.0468, losses: [0.046778179705142975], learning rate: 0.0099000000
Iteration 370000: total loss 0.0532, losses: [0.053190410137176514], learning rate: 0.0099000000
Iteration 370000: total loss 0.0440, losses: [0.043974369764328], learning rate: 0.0099000000
Val loss  tensor(0.8316)
Val loss  tensor(0.8964)
Iteration 640000: total loss 0.0323, losses: [0.03226364403963089], learning rate: 0.0098010000
Iteration 640000: total loss 0.0473, losses: [0.04726085811853409], learning rate: 0.0099000000
Val loss  tensor(0.6743)
Val loss  tensor(0.7221)
Iteration 375000: total loss 0.0614, losses: [0.06144723296165466], learning rate: 0.0099000000
Iteration 375000: total loss 0.0503, losses: [0.050267722457647324], learning rate: 0.0099000000
Iteration 380000: total loss 0.0492, losses: [0.049227699637413025], learning rate: 0.0099000000
Iteration 380000: total loss 0.0444, losses: [0.04438765347003937], learning rate: 0.0099000000
Val loss  tensor(0.8328)
Val loss  tensor(0.8506)
Iteration 645000: total loss 0.0308, losses: [0.03082435205578804], learning rate: 0.0098010000
Iteration 645000: total loss 0.0474, losses: [0.047420185059309006], learning rate: 0.0099000000
Iteration 385000: total loss 0.0454, losses: [0.045430902391672134], learning rate: 0.0099000000
Iteration 385000: total loss 0.0434, losses: [0.04343049228191376], learning rate: 0.0099000000
Iteration 650000: total loss 0.0290, losses: [0.02901066467165947], learning rate: 0.0098010000
Iteration 650000: total loss 0.0355, losses: [0.03550112992525101], learning rate: 0.0099000000
Val loss  tensor(0.6552)
Val loss  tensor(0.7681)
Iteration 390000: total loss 0.0542, losses: [0.05416044220328331], learning rate: 0.0099000000
Iteration 390000: total loss 0.0512, losses: [0.05124089866876602], learning rate: 0.0099000000
Val loss  tensor(0.9194)
Val loss  tensor(0.8413)
Iteration 655000: total loss 0.0285, losses: [0.02848423831164837], learning rate: 0.0098010000
Iteration 655000: total loss 0.0387, losses: [0.038718681782484055], learning rate: 0.0099000000
Iteration 395000: total loss 0.0513, losses: [0.05128638446331024], learning rate: 0.0099000000
Iteration 395000: total loss 0.0457, losses: [0.04569031670689583], learning rate: 0.0099000000
Iteration 660000: total loss 0.0413, losses: [0.041332125663757324], learning rate: 0.0099000000
Iteration 660000: total loss 0.0343, losses: [0.03429069742560387], learning rate: 0.0098010000
Iteration 400000: total loss 0.0537, losses: [0.05366332828998566], learning rate: 0.0099000000
Iteration 400000: total loss 0.0539, losses: [0.05393127351999283], learning rate: 0.0099000000
Val loss  tensor(0.7371)
Val loss  tensor(0.5715)
Val loss  tensor(0.9370)
Val loss  tensor(0.8849)
Iteration 665000: total loss 0.0446, losses: [0.04456888139247894], learning rate: 0.0099000000
Iteration 665000: total loss 0.0306, losses: [0.0306241475045681], learning rate: 0.0098010000
Iteration 405000: total loss 0.0564, losses: [0.05641642212867737], learning rate: 0.0098010000
Iteration 405000: total loss 0.0518, losses: [0.0518491268157959], learning rate: 0.0099000000
Iteration 670000: total loss 0.0513, losses: [0.05131088197231293], learning rate: 0.0099000000
Iteration 670000: total loss 0.0357, losses: [0.03573410585522652], learning rate: 0.0098010000
Val loss  tensor(0.7481)
Val loss  tensor(0.5927)
Iteration 410000: total loss 0.0447, losses: [0.0446709543466568], learning rate: 0.0099000000
Iteration 410000: total loss 0.0536, losses: [0.05355168133974075], learning rate: 0.0098010000
Val loss  tensor(0.8504)
Val loss  tensor(0.9460)
Iteration 675000: total loss 0.0402, losses: [0.04017312824726105], learning rate: 0.0099000000
Iteration 675000: total loss 0.0290, losses: [0.028977051377296448], learning rate: 0.0098010000
Iteration 415000: total loss 0.0510, losses: [0.0510408990085125], learning rate: 0.0099000000
Iteration 415000: total loss 0.0436, losses: [0.043583713471889496], learning rate: 0.0098010000
Iteration 680000: total loss 0.0513, losses: [0.051307015120983124], learning rate: 0.0099000000
Iteration 680000: total loss 0.0281, losses: [0.028128284960985184], learning rate: 0.0098010000
Val loss  tensor(0.7915)
Val loss  tensor(0.5622)
Iteration 420000: total loss 0.0462, losses: [0.046174656599760056], learning rate: 0.0098010000
Iteration 420000: total loss 0.0404, losses: [0.04038868844509125], learning rate: 0.0099000000
Val loss  tensor(0.9487)
Val loss  tensor(0.8549)
Iteration 685000: total loss 0.0273, losses: [0.027289029210805893], learning rate: 0.0098010000
Iteration 685000: total loss 0.0435, losses: [0.043496739119291306], learning rate: 0.0099000000
Iteration 425000: total loss 0.0416, losses: [0.04161093384027481], learning rate: 0.0098010000
Iteration 425000: total loss 0.0485, losses: [0.048468217253685], learning rate: 0.0099000000
Iteration 690000: total loss 0.0282, losses: [0.02817336469888687], learning rate: 0.0098010000
Val loss  tensor(0.5805)
Iteration 690000: total loss 0.0380, losses: [0.037956345826387405], learning rate: 0.0099000000
Val loss  tensor(1.1430)
Iteration 430000: total loss 0.0477, losses: [0.04768705368041992], learning rate: 0.0099000000
Iteration 430000: total loss 0.0449, losses: [0.0449017696082592], learning rate: 0.0098010000
Val loss  tensor(0.8439)
Val loss  tensor(0.8787)
Iteration 695000: total loss 0.0292, losses: [0.02917749062180519], learning rate: 0.0098010000
Iteration 695000: total loss 0.0449, losses: [0.04494498670101166], learning rate: 0.0099000000
Iteration 435000: total loss 0.0555, losses: [0.055488504469394684], learning rate: 0.0098010000
Iteration 435000: total loss 0.0532, losses: [0.05318837985396385], learning rate: 0.0099000000
Iteration 700000: total loss 0.0321, losses: [0.03212135285139084], learning rate: 0.0098010000
Iteration 700000: total loss 0.0442, losses: [0.044246233999729156], learning rate: 0.0099000000
Val loss  tensor(0.6217)
Val loss  tensor(0.7871)
Iteration 440000: total loss 0.0496, losses: [0.04957908019423485], learning rate: 0.0099000000
Iteration 440000: total loss 0.0407, losses: [0.040696509182453156], learning rate: 0.0098010000
Val loss  tensor(0.9607)
Val loss  tensor(0.8395)
Iteration 705000: total loss 0.0303, losses: [0.030268382281064987], learning rate: 0.0098010000
Iteration 705000: total loss 0.0468, losses: [0.04680619388818741], learning rate: 0.0099000000
Iteration 445000: total loss 0.0524, losses: [0.05241957679390907], learning rate: 0.0098010000
Iteration 445000: total loss 0.0465, losses: [0.04649784043431282], learning rate: 0.0099000000
Iteration 710000: total loss 0.0389, losses: [0.0388960987329483], learning rate: 0.0099000000
Iteration 710000: total loss 0.0331, losses: [0.03309372812509537], learning rate: 0.0098010000
Val loss  tensor(1.1322)
Val loss  tensor(0.6096)
Iteration 450000: total loss 0.0488, losses: [0.04875868558883667], learning rate: 0.0098010000
Iteration 450000: total loss 0.0434, losses: [0.04336310923099518], learning rate: 0.0099000000
Val loss  tensor(0.9897)
Val loss  tensor(0.9355)
Iteration 715000: total loss 0.0409, losses: [0.04086025059223175], learning rate: 0.0099000000
Iteration 715000: total loss 0.0262, losses: [0.0262458436191082], learning rate: 0.0098010000
Iteration 455000: total loss 0.0603, losses: [0.06025347486138344], learning rate: 0.0098010000
Iteration 455000: total loss 0.0424, losses: [0.04242657870054245], learning rate: 0.0099000000
Iteration 720000: total loss 0.0430, losses: [0.042990513145923615], learning rate: 0.0099000000
Iteration 720000: total loss 0.0350, losses: [0.0349678099155426], learning rate: 0.0098010000
Val loss  tensor(0.8584)
Val loss  tensor(0.6026)
Iteration 460000: total loss 0.0544, losses: [0.05437256395816803], learning rate: 0.0098010000
Iteration 460000: total loss 0.0373, losses: [0.03733065724372864], learning rate: 0.0099000000
Val loss  tensor(0.9088)
Val loss  tensor(0.9195)
Iteration 725000: total loss 0.0405, losses: [0.04054860770702362], learning rate: 0.0099000000
Iteration 725000: total loss 0.0328, losses: [0.03280286490917206], learning rate: 0.0098010000
Iteration 465000: total loss 0.0451, losses: [0.04509875178337097], learning rate: 0.0098010000
Iteration 465000: total loss 0.0552, losses: [0.05518270283937454], learning rate: 0.0098010000
Iteration 470000: total loss 0.0431, losses: [0.04307708889245987], learning rate: 0.0098010000
Iteration 470000: total loss 0.0488, losses: [0.04875020682811737], learning rate: 0.0098010000
Val loss  tensor(0.9349)
Val loss  tensor(0.8295)
Iteration 730000: total loss 0.0390, losses: [0.03903828561306], learning rate: 0.0099000000
Val loss  tensor(0.8025)
Iteration 730000: total loss 0.0308, losses: [0.030772818252444267], learning rate: 0.0098010000
Val loss  tensor(0.6039)
Iteration 475000: total loss 0.0470, losses: [0.04696730524301529], learning rate: 0.0098010000
Iteration 475000: total loss 0.0644, losses: [0.06443902850151062], learning rate: 0.0098010000
Iteration 735000: total loss 0.0401, losses: [0.040061015635728836], learning rate: 0.0099000000
Iteration 735000: total loss 0.0329, losses: [0.032908085733652115], learning rate: 0.0098010000
Iteration 480000: total loss 0.0529, losses: [0.0528949610888958], learning rate: 0.0098010000
Iteration 480000: total loss 0.0424, losses: [0.04244145750999451], learning rate: 0.0098010000
Val loss  tensor(0.9322)
Val loss  tensor(0.8014)
Iteration 740000: total loss 0.0492, losses: [0.04919549822807312], learning rate: 0.0099000000
Val loss  tensor(0.8022)
Iteration 740000: total loss 0.0307, losses: [0.030693721026182175], learning rate: 0.0098010000
Val loss  tensor(0.6500)
Iteration 485000: total loss 0.0488, losses: [0.04881379008293152], learning rate: 0.0098010000
Iteration 485000: total loss 0.0495, losses: [0.04953615739941597], learning rate: 0.0098010000
Iteration 745000: total loss 0.0409, losses: [0.04093949496746063], learning rate: 0.0098010000
Iteration 745000: total loss 0.0296, losses: [0.029551582410931587], learning rate: 0.0098010000
Iteration 490000: total loss 0.0513, losses: [0.05129445344209671], learning rate: 0.0098010000
Iteration 490000: total loss 0.0368, losses: [0.036838971078395844], learning rate: 0.0098010000
Val loss  tensor(0.7902)
Val loss  tensor(0.8674)
Iteration 750000: total loss 0.0444, losses: [0.04437924548983574], learning rate: 0.0098010000
Val loss  tensor(0.7662)
Iteration 750000: total loss 0.0326, losses: [0.03258911892771721], learning rate: 0.0098010000
Val loss  tensor(0.6574)
Iteration 495000: total loss 0.0459, losses: [0.04585392773151398], learning rate: 0.0098010000
Iteration 495000: total loss 0.0379, losses: [0.03791283071041107], learning rate: 0.0098010000
Iteration 755000: total loss 0.0465, losses: [0.04649614542722702], learning rate: 0.0098010000
Iteration 755000: total loss 0.0306, losses: [0.030635779723525047], learning rate: 0.0098010000
Iteration 500000: total loss 0.0455, losses: [0.04547248035669327], learning rate: 0.0098010000
Iteration 500000: total loss 0.0479, losses: [0.04789504408836365], learning rate: 0.0098010000
Val loss  tensor(0.9010)
Val loss  tensor(0.9465)
Iteration 760000: total loss 0.0470, losses: [0.046975456178188324], learning rate: 0.0098010000
Val loss  tensor(0.7807)
Iteration 760000: total loss 0.0319, losses: [0.0319414883852005], learning rate: 0.0098010000
Val loss  tensor(0.6366)
Iteration 505000: total loss 0.0461, losses: [0.046123139560222626], learning rate: 0.0098010000
Iteration 505000: total loss 0.0512, losses: [0.05122543126344681], learning rate: 0.0098010000
Iteration 765000: total loss 0.0424, losses: [0.04241536930203438], learning rate: 0.0098010000
Iteration 510000: total loss 0.0516, losses: [0.051609598100185394], learning rate: 0.0098010000
Iteration 510000: total loss 0.0365, losses: [0.03650149703025818], learning rate: 0.0098010000
Val loss  tensor(0.9246)
Val loss  tensor(0.8126)
Iteration 765000: total loss 0.0361, losses: [0.0361136794090271], learning rate: 0.0098010000
Iteration 515000: total loss 0.0499, losses: [0.049863774329423904], learning rate: 0.0097029900
Iteration 515000: total loss 0.0487, losses: [0.04871243238449097], learning rate: 0.0098010000
Iteration 770000: total loss 0.0429, losses: [0.04292886331677437], learning rate: 0.0098010000
Val loss  tensor(0.8536)
Iteration 520000: total loss 0.0550, losses: [0.054978884756565094], learning rate: 0.0097029900
Iteration 520000: total loss 0.0447, losses: [0.044669799506664276], learning rate: 0.0098010000
Val loss  tensor(0.9548)
Val loss  tensor(0.7653)
Iteration 770000: total loss 0.0298, losses: [0.029787475243210793], learning rate: 0.0098010000
Val loss  tensor(0.6418)
Iteration 775000: total loss 0.0499, losses: [0.0498897023499012], learning rate: 0.0098010000
Iteration 525000: total loss 0.0481, losses: [0.048090413212776184], learning rate: 0.0097029900
Iteration 525000: total loss 0.0431, losses: [0.0431370735168457], learning rate: 0.0098010000
Iteration 775000: total loss 0.0344, losses: [0.03439939767122269], learning rate: 0.0098010000
Iteration 780000: total loss 0.0439, losses: [0.04391878843307495], learning rate: 0.0098010000
Val loss  tensor(0.8113)
Iteration 530000: total loss 0.0447, losses: [0.04474310576915741], learning rate: 0.0097029900
Iteration 530000: total loss 0.0479, losses: [0.047867342829704285], learning rate: 0.0098010000
Val loss  tensor(0.7983)
Val loss  tensor(0.7440)
Iteration 780000: total loss 0.0263, losses: [0.02633839100599289], learning rate: 0.0098010000
Val loss  tensor(0.6305)
Iteration 785000: total loss 0.0379, losses: [0.0378732830286026], learning rate: 0.0098010000
Iteration 535000: total loss 0.0405, losses: [0.040470778942108154], learning rate: 0.0097029900
Iteration 535000: total loss 0.0459, losses: [0.04594441503286362], learning rate: 0.0098010000
Iteration 785000: total loss 0.0293, losses: [0.029299378395080566], learning rate: 0.0098010000
Iteration 790000: total loss 0.0465, losses: [0.04647736996412277], learning rate: 0.0098010000
Val loss  tensor(0.8376)
Iteration 540000: total loss 0.0466, losses: [0.04660212993621826], learning rate: 0.0097029900
Iteration 540000: total loss 0.0454, losses: [0.04541659355163574], learning rate: 0.0098010000
Val loss  tensor(0.9641)
Val loss  tensor(0.8171)
Iteration 790000: total loss 0.0339, losses: [0.03387223556637764], learning rate: 0.0098010000
Val loss  tensor(0.6725)
Iteration 795000: total loss 0.0392, losses: [0.039184436202049255], learning rate: 0.0098010000
Iteration 795000: total loss 0.0269, losses: [0.026938216760754585], learning rate: 0.0097029900
Iteration 545000: total loss 0.0437, losses: [0.04366954416036606], learning rate: 0.0098010000
Iteration 545000: total loss 0.0441, losses: [0.04407137632369995], learning rate: 0.0097029900
Iteration 800000: total loss 0.0455, losses: [0.04549136757850647], learning rate: 0.0098010000
Val loss  tensor(0.7778)
Iteration 800000: total loss 0.0329, losses: [0.03294889256358147], learning rate: 0.0097029900
Val loss  tensor(0.6645)
Iteration 550000: total loss 0.0624, losses: [0.06235280632972717], learning rate: 0.0097029900
Iteration 550000: total loss 0.0473, losses: [0.04730196297168732], learning rate: 0.0098010000
Val loss  tensor(0.8603)
Val loss  tensor(0.7634)
Iteration 805000: total loss 0.0493, losses: [0.049323808401823044], learning rate: 0.0098010000
Iteration 805000: total loss 0.0260, losses: [0.02603508159518242], learning rate: 0.0097029900
Iteration 555000: total loss 0.0446, losses: [0.04457883536815643], learning rate: 0.0097029900
Iteration 555000: total loss 0.0383, losses: [0.038263123482465744], learning rate: 0.0098010000
Iteration 810000: total loss 0.0443, losses: [0.04430340602993965], learning rate: 0.0098010000
Val loss  tensor(0.8304)
Iteration 810000: total loss 0.0316, losses: [0.0315893292427063], learning rate: 0.0097029900
Val loss  tensor(0.6669)
Iteration 815000: total loss 0.0375, losses: [0.03751063346862793], learning rate: 0.0098010000
Iteration 560000: total loss 0.0518, losses: [0.05178585276007652], learning rate: 0.0097029900
Iteration 560000: total loss 0.0511, losses: [0.05107959359884262], learning rate: 0.0098010000
Val loss  tensor(0.8477)
Val loss  tensor(0.7670)
Iteration 815000: total loss 0.0251, losses: [0.025058481842279434], learning rate: 0.0097029900
Iteration 820000: total loss 0.0409, losses: [0.04088087007403374], learning rate: 0.0098010000
Val loss  tensor(0.7617)
Iteration 565000: total loss 0.0467, losses: [0.04673264920711517], learning rate: 0.0097029900
Iteration 565000: total loss 0.0430, losses: [0.04302120953798294], learning rate: 0.0098010000
Iteration 820000: total loss 0.0298, losses: [0.02984275296330452], learning rate: 0.0097029900
Val loss  tensor(0.6861)
Iteration 825000: total loss 0.0450, losses: [0.045008059591054916], learning rate: 0.0098010000
Iteration 570000: total loss 0.0440, losses: [0.04397403448820114], learning rate: 0.0097029900
Iteration 570000: total loss 0.0521, losses: [0.052122920751571655], learning rate: 0.0098010000
Val loss  tensor(0.8837)
Val loss  tensor(0.7659)
Iteration 825000: total loss 0.0264, losses: [0.026410695165395737], learning rate: 0.0097029900
Iteration 575000: total loss 0.0448, losses: [0.04481828585267067], learning rate: 0.0097029900
Iteration 575000: total loss 0.0450, losses: [0.04504625126719475], learning rate: 0.0098010000
Iteration 830000: total loss 0.0406, losses: [0.04061387479305267], learning rate: 0.0098010000
Val loss  tensor(0.8126)
Iteration 580000: total loss 0.0398, losses: [0.03982296213507652], learning rate: 0.0097029900
Iteration 580000: total loss 0.0402, losses: [0.04022779315710068], learning rate: 0.0098010000
Val loss  tensor(0.8593)
Val loss  tensor(0.7814)
Iteration 830000: total loss 0.0296, losses: [0.029649514704942703], learning rate: 0.0097029900
Val loss  tensor(0.6820)
Iteration 835000: total loss 0.0387, losses: [0.038658469915390015], learning rate: 0.0098010000
Iteration 585000: total loss 0.0536, losses: [0.053624678403139114], learning rate: 0.0097029900
Iteration 585000: total loss 0.0386, losses: [0.0385863371193409], learning rate: 0.0098010000
Iteration 590000: total loss 0.0521, losses: [0.05210781842470169], learning rate: 0.0097029900
Iteration 590000: total loss 0.0409, losses: [0.04088222235441208], learning rate: 0.0098010000
Val loss  tensor(0.7837)
Val loss  tensor(0.8600)
Iteration 835000: total loss 0.0295, losses: [0.029475606977939606], learning rate: 0.0097029900
Iteration 840000: total loss 0.0439, losses: [0.043925076723098755], learning rate: 0.0098010000
Val loss  tensor(0.7782)
Iteration 595000: total loss 0.0472, losses: [0.04723414406180382], learning rate: 0.0098010000
Iteration 595000: total loss 0.0521, losses: [0.052109334617853165], learning rate: 0.0097029900
Iteration 845000: total loss 0.0454, losses: [0.04540131986141205], learning rate: 0.0098010000
Iteration 840000: total loss 0.0304, losses: [0.0303519107401371], learning rate: 0.0097029900
Iteration 600000: total loss 0.0449, losses: [0.044894129037857056], learning rate: 0.0097029900
Iteration 600000: total loss 0.0330, losses: [0.03304475173354149], learning rate: 0.0098010000
Val loss  tensor(0.8535)
Val loss  tensor(0.8241)
Val loss  tensor(0.7047)
Iteration 605000: total loss 0.0397, losses: [0.03968426585197449], learning rate: 0.0097029900
Iteration 605000: total loss 0.0399, losses: [0.03985116630792618], learning rate: 0.0098010000
Iteration 850000: total loss 0.0391, losses: [0.03908596560359001], learning rate: 0.0098010000
Val loss  tensor(0.8088)
Iteration 845000: total loss 0.0282, losses: [0.02816910296678543], learning rate: 0.0097029900
Iteration 610000: total loss 0.0374, losses: [0.037372052669525146], learning rate: 0.0097029900
Iteration 610000: total loss 0.0375, losses: [0.037540897727012634], learning rate: 0.0098010000
Val loss  tensor(0.8055)
Val loss  tensor(0.8363)
Iteration 855000: total loss 0.0397, losses: [0.03974151611328125], learning rate: 0.0097029900
Iteration 615000: total loss 0.0398, losses: [0.03980698063969612], learning rate: 0.0097029900
Iteration 615000: total loss 0.0440, losses: [0.043971262872219086], learning rate: 0.0098010000
Iteration 850000: total loss 0.0309, losses: [0.030928045511245728], learning rate: 0.0097029900
Val loss  tensor(0.6632)
Iteration 860000: total loss 0.0386, losses: [0.038559287786483765], learning rate: 0.0097029900
Val loss  tensor(0.7326)
Iteration 620000: total loss 0.0472, losses: [0.047227032482624054], learning rate: 0.0097029900
Iteration 620000: total loss 0.0401, losses: [0.04007267206907272], learning rate: 0.0098010000
Val loss  tensor(0.9000)
Val loss  tensor(0.8835)
Iteration 855000: total loss 0.0249, losses: [0.02488008141517639], learning rate: 0.0097029900
Iteration 865000: total loss 0.0398, losses: [0.03984588757157326], learning rate: 0.0097029900
Iteration 625000: total loss 0.0589, losses: [0.058922503143548965], learning rate: 0.0097029900
Iteration 625000: total loss 0.0445, losses: [0.04453430324792862], learning rate: 0.0098010000
Iteration 860000: total loss 0.0296, losses: [0.029600847512483597], learning rate: 0.0097029900
Val loss  tensor(0.6912)
Iteration 630000: total loss 0.0518, losses: [0.05181116983294487], learning rate: 0.0097029900
Iteration 630000: total loss 0.0383, losses: [0.03828864544630051], learning rate: 0.0098010000
Val loss  tensor(0.8776)
Val loss  tensor(0.8309)
Iteration 870000: total loss 0.0425, losses: [0.0425146110355854], learning rate: 0.0097029900
Val loss  tensor(0.7823)
Iteration 865000: total loss 0.0333, losses: [0.03333680331707001], learning rate: 0.0097029900
Iteration 635000: total loss 0.0404, losses: [0.040364429354667664], learning rate: 0.0097029900
Iteration 635000: total loss 0.0317, losses: [0.031746089458465576], learning rate: 0.0098010000
Iteration 875000: total loss 0.0382, losses: [0.038249675184488297], learning rate: 0.0097029900
Iteration 870000: total loss 0.0273, losses: [0.027318190783262253], learning rate: 0.0097029900
Val loss  tensor(0.6323)
Iteration 640000: total loss 0.0495, losses: [0.04946453869342804], learning rate: 0.0097029900
Iteration 640000: total loss 0.0428, losses: [0.042783867567777634], learning rate: 0.0098010000
Val loss  tensor(0.8031)
Val loss  tensor(0.8090)
Iteration 880000: total loss 0.0411, losses: [0.04107343405485153], learning rate: 0.0097029900
Val loss  tensor(0.7894)
Iteration 875000: total loss 0.0287, losses: [0.02870001643896103], learning rate: 0.0097029900
Iteration 645000: total loss 0.0441, losses: [0.04407258331775665], learning rate: 0.0096059601
Iteration 645000: total loss 0.0379, losses: [0.0379173681139946], learning rate: 0.0097029900
Iteration 885000: total loss 0.0384, losses: [0.03836747258901596], learning rate: 0.0097029900
Iteration 880000: total loss 0.0265, losses: [0.02648455649614334], learning rate: 0.0097029900
Val loss  tensor(0.6580)
Iteration 650000: total loss 0.0454, losses: [0.0454055517911911], learning rate: 0.0096059601
Iteration 650000: total loss 0.0414, losses: [0.04142561927437782], learning rate: 0.0097029900
Iteration 890000: total loss 0.0459, losses: [0.04587968438863754], learning rate: 0.0097029900
Val loss  tensor(0.8563)
Val loss  tensor(0.8477)
Val loss  tensor(0.7577)
Iteration 885000: total loss 0.0274, losses: [0.02741219289600849], learning rate: 0.0097029900
Iteration 895000: total loss 0.0453, losses: [0.0453319326043129], learning rate: 0.0097029900
Iteration 655000: total loss 0.0384, losses: [0.03838936239480972], learning rate: 0.0097029900
Iteration 655000: total loss 0.0436, losses: [0.04355819150805473], learning rate: 0.0096059601
Iteration 890000: total loss 0.0332, losses: [0.033247604966163635], learning rate: 0.0097029900
Val loss  tensor(0.6717)
Iteration 900000: total loss 0.0360, losses: [0.035953499376773834], learning rate: 0.0097029900
Val loss  tensor(0.7344)
Iteration 660000: total loss 0.0464, losses: [0.04641955345869064], learning rate: 0.0096059601
Iteration 660000: total loss 0.0462, losses: [0.046198539435863495], learning rate: 0.0097029900
Val loss  tensor(0.8605)
Val loss  tensor(0.8041)
Iteration 895000: total loss 0.0246, losses: [0.024621419608592987], learning rate: 0.0097029900
Iteration 905000: total loss 0.0406, losses: [0.04062220826745033], learning rate: 0.0097029900
Iteration 900000: total loss 0.0310, losses: [0.030954288318753242], learning rate: 0.0097029900
Val loss  tensor(0.6320)
Iteration 665000: total loss 0.0454, losses: [0.04542351886630058], learning rate: 0.0096059601
Iteration 665000: total loss 0.0365, losses: [0.03648367524147034], learning rate: 0.0097029900
Iteration 910000: total loss 0.0427, losses: [0.04273860156536102], learning rate: 0.0097029900
Val loss  tensor(0.8468)
Iteration 905000: total loss 0.0339, losses: [0.033898185938596725], learning rate: 0.0096059601
Iteration 670000: total loss 0.0517, losses: [0.051708199083805084], learning rate: 0.0096059601
Iteration 670000: total loss 0.0411, losses: [0.041128307580947876], learning rate: 0.0097029900
Val loss  tensor(0.8647)
Val loss  tensor(0.8344)
Iteration 915000: total loss 0.0367, losses: [0.036682866513729095], learning rate: 0.0097029900
Iteration 910000: total loss 0.0270, losses: [0.02703201398253441], learning rate: 0.0096059601
Val loss  tensor(0.6264)
Iteration 675000: total loss 0.0444, losses: [0.04436066746711731], learning rate: 0.0096059601
Iteration 675000: total loss 0.0356, losses: [0.0355544313788414], learning rate: 0.0097029900
Iteration 920000: total loss 0.0378, losses: [0.03780932351946831], learning rate: 0.0097029900
Val loss  tensor(0.8016)
Iteration 915000: total loss 0.0284, losses: [0.028373951092362404], learning rate: 0.0096059601
Iteration 680000: total loss 0.0391, losses: [0.03914773836731911], learning rate: 0.0097029900
Iteration 680000: total loss 0.0403, losses: [0.04030703008174896], learning rate: 0.0096059601
Iteration 925000: total loss 0.0294, losses: [0.029394997283816338], learning rate: 0.0097029900
Val loss  tensor(0.8896)
Val loss  tensor(0.7913)
Iteration 920000: total loss 0.0296, losses: [0.02960388734936714], learning rate: 0.0096059601
Val loss  tensor(0.6434)
Iteration 930000: total loss 0.0384, losses: [0.03841991350054741], learning rate: 0.0097029900
Val loss  tensor(0.7883)
Iteration 685000: total loss 0.0420, losses: [0.04203101992607117], learning rate: 0.0096059601
Iteration 685000: total loss 0.0412, losses: [0.041235167533159256], learning rate: 0.0097029900
Iteration 925000: total loss 0.0290, losses: [0.02899063378572464], learning rate: 0.0096059601
Iteration 935000: total loss 0.0413, losses: [0.04130955785512924], learning rate: 0.0097029900
Iteration 690000: total loss 0.0361, losses: [0.03614238649606705], learning rate: 0.0096059601
Iteration 690000: total loss 0.0422, losses: [0.042205531150102615], learning rate: 0.0097029900
Iteration 930000: total loss 0.0256, losses: [0.025550076737999916], learning rate: 0.0096059601
Val loss  tensor(0.8211)
Val loss  tensor(0.8255)
Val loss  tensor(0.5710)
Iteration 940000: total loss 0.0386, losses: [0.03859492763876915], learning rate: 0.0097029900
Val loss  tensor(0.8017)
Iteration 935000: total loss 0.0274, losses: [0.027365896850824356], learning rate: 0.0096059601
Iteration 695000: total loss 0.0406, losses: [0.04062992334365845], learning rate: 0.0097029900
Iteration 695000: total loss 0.0559, losses: [0.05589709430932999], learning rate: 0.0096059601
Iteration 945000: total loss 0.0379, losses: [0.03794245794415474], learning rate: 0.0097029900
Iteration 940000: total loss 0.0323, losses: [0.03230425715446472], learning rate: 0.0096059601
Val loss  tensor(0.6478)
Iteration 700000: total loss 0.0471, losses: [0.04708966985344887], learning rate: 0.0097029900
Iteration 700000: total loss 0.0445, losses: [0.04448343813419342], learning rate: 0.0096059601
Val loss  tensor(0.8949)
Val loss  tensor(0.7843)
Iteration 950000: total loss 0.0427, losses: [0.042668893933296204], learning rate: 0.0097029900
Val loss  tensor(0.7733)
Iteration 945000: total loss 0.0350, losses: [0.03495189547538757], learning rate: 0.0096059601
Iteration 705000: total loss 0.0515, losses: [0.05151339992880821], learning rate: 0.0096059601
Iteration 705000: total loss 0.0384, losses: [0.03843483701348305], learning rate: 0.0097029900
Iteration 955000: total loss 0.0314, losses: [0.031363993883132935], learning rate: 0.0097029900
Iteration 710000: total loss 0.0413, losses: [0.041268739849328995], learning rate: 0.0096059601
Iteration 710000: total loss 0.0422, losses: [0.04222865030169487], learning rate: 0.0097029900
Val loss  tensor(0.8902)
Val loss  tensor(0.8203)
Iteration 950000: total loss 0.0280, losses: [0.027988091111183167], learning rate: 0.0096059601
Val loss  tensor(0.6240)
Iteration 715000: total loss 0.0312, losses: [0.031154977157711983], learning rate: 0.0096059601
Iteration 715000: total loss 0.0486, losses: [0.04859371855854988], learning rate: 0.0097029900
Iteration 960000: total loss 0.0404, losses: [0.04038305580615997], learning rate: 0.0097029900
Val loss  tensor(0.7654)
Iteration 955000: total loss 0.0333, losses: [0.03325173631310463], learning rate: 0.0096059601
Iteration 720000: total loss 0.0442, losses: [0.044242966920137405], learning rate: 0.0096059601
Iteration 720000: total loss 0.0395, losses: [0.039465803653001785], learning rate: 0.0097029900
Val loss  tensor(0.8642)
Val loss  tensor(0.9019)
Iteration 965000: total loss 0.0438, losses: [0.043848104774951935], learning rate: 0.0096059601
Iteration 725000: total loss 0.0460, losses: [0.04595816880464554], learning rate: 0.0096059601
Iteration 725000: total loss 0.0450, losses: [0.044961344450712204], learning rate: 0.0097029900
Iteration 960000: total loss 0.0291, losses: [0.029104499146342278], learning rate: 0.0096059601
Val loss  tensor(0.6490)
Iteration 730000: total loss 0.0487, losses: [0.048677489161491394], learning rate: 0.0096059601
Iteration 730000: total loss 0.0379, losses: [0.03788633644580841], learning rate: 0.0097029900
Val loss  tensor(0.9208)
Val loss  tensor(0.8416)
Iteration 970000: total loss 0.0436, losses: [0.04361415654420853], learning rate: 0.0096059601
Val loss  tensor(0.7930)
Iteration 965000: total loss 0.0272, losses: [0.027150386944413185], learning rate: 0.0096059601
Iteration 735000: total loss 0.0413, losses: [0.04134875163435936], learning rate: 0.0096059601
Iteration 735000: total loss 0.0342, losses: [0.03418629989027977], learning rate: 0.0097029900
Iteration 975000: total loss 0.0315, losses: [0.03146551549434662], learning rate: 0.0096059601
Iteration 740000: total loss 0.0476, losses: [0.04760316014289856], learning rate: 0.0096059601
Iteration 740000: total loss 0.0450, losses: [0.045036617666482925], learning rate: 0.0097029900
Val loss  tensor(0.9116)
Val loss  tensor(0.8397)
Iteration 970000: total loss 0.0291, losses: [0.029056400060653687], learning rate: 0.0096059601
Val loss  tensor(0.6353)
Iteration 745000: total loss 0.0485, losses: [0.04850663244724274], learning rate: 0.0096059601
Iteration 745000: total loss 0.0419, losses: [0.041874922811985016], learning rate: 0.0097029900
Iteration 980000: total loss 0.0375, losses: [0.037542715668678284], learning rate: 0.0096059601
Val loss  tensor(0.7806)
Iteration 750000: total loss 0.0493, losses: [0.049341194331645966], learning rate: 0.0096059601
Iteration 750000: total loss 0.0329, losses: [0.0328931026160717], learning rate: 0.0097029900
Val loss  tensor(0.8178)
Val loss  tensor(0.8813)
Iteration 975000: total loss 0.0302, losses: [0.030183611437678337], learning rate: 0.0096059601
Iteration 985000: total loss 0.0425, losses: [0.04250892251729965], learning rate: 0.0096059601
Iteration 755000: total loss 0.0391, losses: [0.039143841713666916], learning rate: 0.0095099005
Iteration 755000: total loss 0.0364, losses: [0.03635736554861069], learning rate: 0.0096059601
Iteration 980000: total loss 0.0314, losses: [0.03136886656284332], learning rate: 0.0096059601
Val loss  tensor(0.6469)
Iteration 760000: total loss 0.0487, losses: [0.04870481789112091], learning rate: 0.0095099005
Iteration 760000: total loss 0.0424, losses: [0.042407695204019547], learning rate: 0.0096059601
Val loss  tensor(0.8796)
Val loss  tensor(0.9080)
Iteration 990000: total loss 0.0377, losses: [0.037704937160015106], learning rate: 0.0096059601
Val loss  tensor(0.8201)
Iteration 765000: total loss 0.0363, losses: [0.03626585379242897], learning rate: 0.0096059601
Iteration 765000: total loss 0.0518, losses: [0.0517699271440506], learning rate: 0.0095099005
Iteration 985000: total loss 0.0304, losses: [0.030357934534549713], learning rate: 0.0096059601
Iteration 995000: total loss 0.0331, losses: [0.033095452934503555], learning rate: 0.0096059601
Iteration 770000: total loss 0.0452, losses: [0.04523590952157974], learning rate: 0.0095099005
Iteration 770000: total loss 0.0328, losses: [0.03284361958503723], learning rate: 0.0096059601
Val loss  tensor(0.8962)
Val loss  tensor(0.8996)
Iteration 990000: total loss 0.0307, losses: [0.03065393678843975], learning rate: 0.0096059601
Val loss  tensor(0.6091)
Iteration 775000: total loss 0.0370, losses: [0.03704363852739334], learning rate: 0.0096059601
Iteration 775000: total loss 0.0421, losses: [0.042116984724998474], learning rate: 0.0095099005
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=32, bias=True)
    (1): SiLU()
    (2): Linear(in_features=32, out_features=32, bias=True)
    (3): SiLU()
    (4): Linear(in_features=32, out_features=2, bias=True)
  )
)
Iteration 780000: total loss 0.0477, losses: [0.04771757870912552], learning rate: 0.0095099005
Iteration 780000: total loss 0.0295, losses: [0.029464855790138245], learning rate: 0.0096059601
Val loss  tensor(0.8429)
Val loss  tensor(0.8787)
Iteration 995000: total loss 0.0273, losses: [0.027326636016368866], learning rate: 0.0096059601
Iteration 785000: total loss 0.0473, losses: [0.047291915863752365], learning rate: 0.0096059601
Iteration 785000: total loss 0.0440, losses: [0.04403802007436752], learning rate: 0.0095099005
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=64, bias=True)
    (1): SiLU()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): SiLU()
    (4): Linear(in_features=64, out_features=2, bias=True)
  )
)
Iteration 790000: total loss 0.0458, losses: [0.04575127363204956], learning rate: 0.0096059601
Iteration 790000: total loss 0.0522, losses: [0.05222673714160919], learning rate: 0.0095099005
Val loss  tensor(0.8177)
Val loss  tensor(0.9006)
Iteration 795000: total loss 0.0387, losses: [0.03868432715535164], learning rate: 0.0096059601
Iteration 795000: total loss 0.0457, losses: [0.045715805143117905], learning rate: 0.0095099005
Iteration 800000: total loss 0.0484, losses: [0.04835386201739311], learning rate: 0.0095099005
Iteration 800000: total loss 0.0465, losses: [0.04645900800824165], learning rate: 0.0096059601
Val loss  tensor(0.9286)
Val loss  tensor(0.9147)
Iteration 805000: total loss 0.0342, losses: [0.03424185514450073], learning rate: 0.0095099005
Iteration 805000: total loss 0.0361, losses: [0.036098793148994446], learning rate: 0.0096059601
Iteration 810000: total loss 0.0420, losses: [0.04200278967618942], learning rate: 0.0095099005
Iteration 810000: total loss 0.0384, losses: [0.038397468626499176], learning rate: 0.0096059601
Val loss  tensor(0.8166)
Val loss  tensor(0.9017)
Iteration 815000: total loss 0.0395, losses: [0.03951423242688179], learning rate: 0.0095099005
Iteration 815000: total loss 0.0388, losses: [0.0388011559844017], learning rate: 0.0096059601
Iteration 820000: total loss 0.0405, losses: [0.040546707808971405], learning rate: 0.0095099005
Iteration 820000: total loss 0.0380, losses: [0.03799804300069809], learning rate: 0.0096059601
Val loss  tensor(0.8201)
Val loss  tensor(0.9408)
Iteration 825000: total loss 0.0398, losses: [0.03980979323387146], learning rate: 0.0096059601
Iteration 825000: total loss 0.0419, losses: [0.04188304767012596], learning rate: 0.0095099005
Iteration 830000: total loss 0.0472, losses: [0.04723441228270531], learning rate: 0.0095099005
Iteration 830000: total loss 0.0342, losses: [0.0341588631272316], learning rate: 0.0096059601
Val loss  tensor(0.8755)
Val loss  tensor(0.9528)
Iteration 835000: total loss 0.0379, losses: [0.03793355077505112], learning rate: 0.0095099005
Iteration 835000: total loss 0.0454, losses: [0.04538091644644737], learning rate: 0.0096059601
Iteration 840000: total loss 0.0448, losses: [0.04479721933603287], learning rate: 0.0095099005
Iteration 840000: total loss 0.0407, losses: [0.040689144283533096], learning rate: 0.0096059601
Val loss  tensor(0.9528)
Val loss  tensor(0.9344)
Iteration 845000: total loss 0.0416, losses: [0.04162079095840454], learning rate: 0.0095099005
Iteration 845000: total loss 0.0311, losses: [0.0311049185693264], learning rate: 0.0096059601
Iteration 850000: total loss 0.0390, losses: [0.03900330513715744], learning rate: 0.0095099005
Iteration 850000: total loss 0.0423, losses: [0.042299784719944], learning rate: 0.0096059601
Val loss  tensor(0.8499)
Val loss  tensor(0.9575)
Iteration 855000: total loss 0.0376, losses: [0.037567101418972015], learning rate: 0.0096059601
Iteration 855000: total loss 0.0542, losses: [0.054198503494262695], learning rate: 0.0095099005
Iteration 860000: total loss 0.0476, losses: [0.04761558771133423], learning rate: 0.0095099005
Iteration 860000: total loss 0.0426, losses: [0.042578019201755524], learning rate: 0.0096059601
Val loss  tensor(0.8260)
Val loss  tensor(0.9838)
Iteration 865000: total loss 0.0410, losses: [0.04102340340614319], learning rate: 0.0094148015
Iteration 865000: total loss 0.0376, losses: [0.03755558282136917], learning rate: 0.0095099005
Iteration 870000: total loss 0.0478, losses: [0.047785356640815735], learning rate: 0.0094148015
Iteration 870000: total loss 0.0323, losses: [0.03227854520082474], learning rate: 0.0095099005
Val loss  tensor(0.8478)
Val loss  tensor(0.9409)
Iteration 875000: total loss 0.0413, losses: [0.04132852703332901], learning rate: 0.0094148015
Iteration 875000: total loss 0.0295, losses: [0.029545512050390244], learning rate: 0.0095099005
Iteration 880000: total loss 0.0491, losses: [0.0490894541144371], learning rate: 0.0094148015
Iteration 880000: total loss 0.0307, losses: [0.03068336471915245], learning rate: 0.0095099005
Val loss  tensor(0.8793)
Val loss  tensor(0.9584)
Iteration 885000: total loss 0.0374, losses: [0.03738789260387421], learning rate: 0.0095099005
Iteration 885000: total loss 0.0431, losses: [0.04311342537403107], learning rate: 0.0094148015
Iteration 890000: total loss 0.0394, losses: [0.039358239620923996], learning rate: 0.0094148015
Iteration 890000: total loss 0.0497, losses: [0.04966380447149277], learning rate: 0.0095099005
Val loss  tensor(0.8783)
Val loss  tensor(0.9342)
Iteration 895000: total loss 0.0373, losses: [0.03727058321237564], learning rate: 0.0094148015
Iteration 895000: total loss 0.0380, losses: [0.03804220259189606], learning rate: 0.0095099005
Iteration 900000: total loss 0.0414, losses: [0.041414037346839905], learning rate: 0.0094148015
Iteration 900000: total loss 0.0255, losses: [0.025511112064123154], learning rate: 0.0095099005
Val loss  tensor(0.8341)
Val loss  tensor(0.9347)
Iteration 905000: total loss 0.0462, losses: [0.04619413614273071], learning rate: 0.0094148015
Iteration 905000: total loss 0.0350, losses: [0.03498862683773041], learning rate: 0.0095099005
Iteration 910000: total loss 0.0433, losses: [0.04331895709037781], learning rate: 0.0094148015
Iteration 910000: total loss 0.0378, losses: [0.03778422623872757], learning rate: 0.0095099005
Val loss  tensor(0.9589)
Val loss  tensor(0.8433)
Iteration 915000: total loss 0.0472, losses: [0.04720044136047363], learning rate: 0.0094148015
Iteration 915000: total loss 0.0434, losses: [0.04337700456380844], learning rate: 0.0095099005
Iteration 920000: total loss 0.0434, losses: [0.04336031526327133], learning rate: 0.0094148015
Iteration 920000: total loss 0.0437, losses: [0.04374399036169052], learning rate: 0.0095099005
Val loss  tensor(0.9396)
Val loss  tensor(0.8800)
Iteration 925000: total loss 0.0450, losses: [0.04496169090270996], learning rate: 0.0094148015
Iteration 925000: total loss 0.0328, losses: [0.03276597708463669], learning rate: 0.0095099005
Iteration 930000: total loss 0.0392, losses: [0.03922578692436218], learning rate: 0.0094148015
Iteration 930000: total loss 0.0381, losses: [0.038133349269628525], learning rate: 0.0095099005
Val loss  tensor(0.9147)
Val loss  tensor(0.8784)
Iteration 935000: total loss 0.0412, losses: [0.041191235184669495], learning rate: 0.0094148015
Iteration 935000: total loss 0.0287, losses: [0.02867000177502632], learning rate: 0.0095099005
Iteration 940000: total loss 0.0460, losses: [0.04599104821681976], learning rate: 0.0094148015
Iteration 940000: total loss 0.0384, losses: [0.0384056493639946], learning rate: 0.0095099005
Val loss  tensor(0.9194)
Val loss  tensor(0.8381)
Iteration 945000: total loss 0.0431, losses: [0.04313069209456444], learning rate: 0.0094148015
Iteration 945000: total loss 0.0417, losses: [0.04168631136417389], learning rate: 0.0095099005
Iteration 950000: total loss 0.0495, losses: [0.04945649579167366], learning rate: 0.0094148015
Iteration 950000: total loss 0.0380, losses: [0.03798249736428261], learning rate: 0.0095099005
Val loss  tensor(0.9319)
Val loss  tensor(0.9074)
Iteration 955000: total loss 0.0482, losses: [0.04819510132074356], learning rate: 0.0094148015
Iteration 955000: total loss 0.0350, losses: [0.03499744087457657], learning rate: 0.0095099005
Iteration 960000: total loss 0.0453, losses: [0.045272346585989], learning rate: 0.0094148015
Iteration 960000: total loss 0.0347, losses: [0.03465769439935684], learning rate: 0.0095099005
Val loss  tensor(0.8324)
Val loss  tensor(0.9543)
Iteration 965000: total loss 0.0468, losses: [0.04683968052268028], learning rate: 0.0094148015
Iteration 965000: total loss 0.0388, losses: [0.038751646876335144], learning rate: 0.0095099005
Iteration 970000: total loss 0.0384, losses: [0.038369469344615936], learning rate: 0.0095099005
Iteration 970000: total loss 0.0412, losses: [0.04119248315691948], learning rate: 0.0094148015
Val loss  tensor(0.8903)
Val loss  tensor(0.8697)
Iteration 975000: total loss 0.0415, losses: [0.04145585745573044], learning rate: 0.0093206535
Iteration 975000: total loss 0.0362, losses: [0.03620403632521629], learning rate: 0.0094148015
Iteration 980000: total loss 0.0363, losses: [0.03627428039908409], learning rate: 0.0093206535
Iteration 980000: total loss 0.0338, losses: [0.03380382061004639], learning rate: 0.0094148015
Val loss  tensor(0.8768)
Val loss  tensor(0.8677)
Iteration 985000: total loss 0.0399, losses: [0.03990183770656586], learning rate: 0.0093206535
Iteration 985000: total loss 0.0370, losses: [0.037014514207839966], learning rate: 0.0094148015
Iteration 990000: total loss 0.0490, losses: [0.04901228845119476], learning rate: 0.0093206535
Iteration 990000: total loss 0.0364, losses: [0.036439456045627594], learning rate: 0.0094148015
Val loss  tensor(0.8639)
Val loss  tensor(0.8641)
Iteration 995000: total loss 0.0453, losses: [0.04526647552847862], learning rate: 0.0093206535
Iteration 995000: total loss 0.0329, losses: [0.03287268429994583], learning rate: 0.0094148015
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=32, bias=True)
    (1): SiLU()
    (2): Linear(in_features=32, out_features=32, bias=True)
    (3): SiLU()
    (4): Linear(in_features=32, out_features=2, bias=True)
  )
)
FullyConnectedNetworkMod(
  (layers): ModuleList(
    (0): Linear(in_features=4, out_features=32, bias=True)
    (1): SiLU()
    (2): Linear(in_features=32, out_features=64, bias=True)
    (3): SiLU()
    (4): Linear(in_features=64, out_features=2, bias=True)
  )
)
